{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOuvVLhbthKOr8uBNzQrLwL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWO1vAVp7HkG","executionInfo":{"status":"ok","timestamp":1717524731840,"user_tz":-60,"elapsed":27510,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"0e02cf86-1be2-4ce8-a66b-1a8442f0b1d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.layers import Input, Flatten, Dense\n","from tensorflow.keras.models import Model"],"metadata":{"id":"6I2s5Q0iDpDE","executionInfo":{"status":"ok","timestamp":1717524738378,"user_tz":-60,"elapsed":6565,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load data\n","data = pd.read_csv('/content/drive/My Drive/M2 GL/PFE/Data/hisb_60_and_Al_fatihah_audio_with_transcript_and_MFCC_and_ahkam_indexing_v3.csv')\n","safa_data = pd.read_csv('/content/drive/My Drive/M2 GL/PFE/Data/safa_hisb_60_and_Al_fatihah_audio_with_transcript_and_MFCC_and_ahkam_indexing.csv')"],"metadata":{"id":"WtJVQemz7klg","executionInfo":{"status":"ok","timestamp":1717524751942,"user_tz":-60,"elapsed":13575,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["export_dir = '/content/drive/My Drive/M2 GL/PFE/new Tajweed rule model/AI models/v5'"],"metadata":{"id":"7A9PSizPHQos","executionInfo":{"status":"ok","timestamp":1717524751943,"user_tz":-60,"elapsed":31,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["abdul_basit = data[data['recitor_en'] == 'Abdul Basit']\n","yassin_aljazaery = data[data['recitor_en'] == 'Yassin Al Jazaery']\n","ibrahim_aldosary = data[data['recitor_en'] == 'Ibrahim_Aldosary']\n","al_husary = data[data['recitor_en'] == 'Al husary']"],"metadata":{"id":"KoKbTBQr7nY8","executionInfo":{"status":"ok","timestamp":1717524751944,"user_tz":-60,"elapsed":27,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["splitted_data_info_np = np.empty((0, 6))\n","models_information_np = np.empty((0, 5))"],"metadata":{"id":"_CenkKQf-AXc","executionInfo":{"status":"ok","timestamp":1717524751945,"user_tz":-60,"elapsed":26,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["max_Y = {'madd_6_Lazim': 2, 'madd_246': 3, 'madd_6': 6, 'madd_2': 5, 'Ikhfaa': 9, 'Idgham': 13, 'tafkhim': 24, 'qalqala': 6, 'imala': 7}\n","max_X = 8000"],"metadata":{"id":"H950tSVTMxlL","executionInfo":{"status":"ok","timestamp":1717524751946,"user_tz":-60,"elapsed":23,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def data_preparation(reciter_data, tajweed_rule):\n","  data_filtered = reciter_data[reciter_data[tajweed_rule].apply(lambda x: x != '[-1]')]\n","\n","  # Extract 'mfcc' and tajweed_rule columns as lists of strings\n","  X_raw = data_filtered['mfcc'].astype(str).tolist()\n","  Y_raw = data_filtered[tajweed_rule].astype(str).tolist()\n","\n","  # Preprocess the input data\n","  X = [tf.constant(eval(x)) for x in X_raw]\n","  Y = [tf.constant(eval(x)) for x in Y_raw]\n","\n","  # Pad sequences in Y and in X to ensure all have the same length\n","  Y_padded = tf.keras.preprocessing.sequence.pad_sequences(Y, maxlen=max_Y[tajweed_rule], padding='post', dtype='int32', value=-1)\n","  X_padded = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_X, padding='post', dtype='float32')\n","\n","  # Split the data into training and testing sets\n","  X_train, X_test, Y_train, Y_test = train_test_split(X_padded, Y_padded, test_size=0.2, random_state=10)\n","  return X_train, X_test, Y_train, Y_test"],"metadata":{"id":"pVbn5z76-K4O","executionInfo":{"status":"ok","timestamp":1717524751947,"user_tz":-60,"elapsed":20,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def tajweed_rule_model(reciter1, reciter2, reciter3, reciter4, not_exp, tajweed_rule):\n","  global splitted_data_info_np, models_information_np, data\n","\n","  # data preparation\n","  reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test = data_preparation(reciter1, tajweed_rule)\n","  reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test = data_preparation(reciter2, tajweed_rule)\n","  reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test = data_preparation(reciter3, tajweed_rule)\n","  reciter4_X_train, reciter4_X_test, reciter4_Y_train, reciter4_Y_test = data_preparation(reciter4, tajweed_rule)\n","  not_exp_X_train, not_exp_X_test, not_exp_Y_train, not_exp_Y_test = data_preparation(not_exp, tajweed_rule)\n","\n","  # Update splitted_data_info with information about each reciter\n","  for reciter_X_train, reciter_X_test, reciter_Y_train, reciter_Y_test, reciter_data in [\n","      (reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test, reciter1),\n","      (reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test, reciter2),\n","      (reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test, reciter3),\n","      (reciter4_X_train, reciter4_X_test, reciter4_Y_train, reciter4_Y_test, reciter4),\n","      (not_exp_X_train, not_exp_X_test, not_exp_Y_train, not_exp_Y_test, not_exp)]:\n","\n","      splitted_data_info_np = np.append(splitted_data_info_np, [[\n","              tajweed_rule,\n","              reciter_data.iloc[0]['recitor_en'],\n","              len(reciter_X_train),\n","              len(reciter_X_test),\n","              len(reciter_Y_train),\n","              len(reciter_Y_test)\n","              ]], axis=0)\n","\n","  # concatenate data\n","  # training data\n","  X_train = np.concatenate([reciter1_X_train, reciter2_X_train, reciter3_X_train, reciter4_X_train, not_exp_X_train], axis=0)\n","  Y_train = np.concatenate([reciter1_Y_train, reciter2_Y_train, reciter3_Y_train, reciter4_Y_train, not_exp_Y_train], axis=0)\n","\n","  # testing data\n","  X_test = np.concatenate([reciter1_X_test, reciter2_X_test, reciter3_X_test, reciter4_X_test, not_exp_X_test], axis=0)\n","  Y_test = np.concatenate([reciter1_Y_test, reciter2_Y_test, reciter3_Y_test, reciter4_Y_test, not_exp_Y_test], axis=0)\n","\n","  splitted_data_info_np = np.append(splitted_data_info_np, [[\n","          tajweed_rule,\n","          'all reciters',\n","          len(X_train),\n","          len(X_test),\n","          len(Y_train),\n","          len(Y_test)\n","          ]], axis=0)\n","\n","  # Normalize input data by scaling each sequence individually\n","  scaler = StandardScaler()\n","  X_train_scaled = np.array([scaler.fit_transform(seq) for seq in X_train])\n","  X_test_scaled = np.array([scaler.transform(seq) for seq in X_test])\n","\n","  # Define a simple neural network model\n","  input_shape = X_train_scaled[0].shape  # Shape of each mfcc sequence\n","  output_shape = Y_train.shape[1]  # Dimension of output (number of units in output layer)\n","\n","  input_layer = Input(shape=input_shape)\n","  flatten_layer = Flatten()(input_layer)  # Flatten the sequence to a 1D vector\n","  hidden_layer = Dense(64, activation='relu')(flatten_layer)\n","  output_layer = Dense(output_shape, activation='linear')(hidden_layer)  # Define the output layer with the correct units\n","\n","  model = Model(inputs=input_layer, outputs=output_layer)\n","\n","  # Compile the model\n","  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","\n","  # Train the model\n","  model.fit(X_train_scaled, Y_train, epochs=50, batch_size=32, validation_split=0.1)\n","\n","  #export the model\n","  model_filename = f'{tajweed_rule}_tajweed_rule_model'\n","  model_path = os.path.join(export_dir, model_filename)\n","  keras.models.save_model(model, model_path)\n","\n","  # Make predictions on test data\n","  predictions = model.predict(X_test_scaled)\n","\n","  # Evaluate the model with adjusted predictions\n","  predictions[predictions < 0] = -1\n","  predictions = np.round(predictions).astype('int32')\n","  loss, accuracy = model.evaluate(X_test_scaled, predictions)\n","\n","  print(f\"Test Loss: {loss:.4f}, Test accuracy : {accuracy:.4f}\")\n","  models_information_np = np.append(models_information_np, [[\n","          model_filename,\n","          \"{:.4f}\".format(loss),\n","          \"{:.4f}\".format(accuracy),\n","          \"{:.2f}\".format(accuracy*100),\n","          model_path]], axis=0)"],"metadata":{"id":"n3ycP8uz8zp8","executionInfo":{"status":"ok","timestamp":1717524751949,"user_tz":-60,"elapsed":21,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["for rule in max_Y.keys():\n","  tajweed_rule_model(abdul_basit, yassin_aljazaery, ibrahim_aldosary, al_husary, safa_data, rule)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n6qxa6hWLAeZ","executionInfo":{"status":"ok","timestamp":1717525954105,"user_tz":-60,"elapsed":1202176,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"6796e3d4-deef-425a-b136-76e9a8ffa6df"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1/1 [==============================] - 1s 1s/step - loss: 189.3658 - accuracy: 0.5000 - val_loss: 1468.3739 - val_accuracy: 1.0000\n","Epoch 2/50\n","1/1 [==============================] - 0s 161ms/step - loss: 4483.3213 - accuracy: 1.0000 - val_loss: 69.5942 - val_accuracy: 0.0000e+00\n","Epoch 3/50\n","1/1 [==============================] - 0s 130ms/step - loss: 644.0039 - accuracy: 0.5000 - val_loss: 260.9345 - val_accuracy: 0.0000e+00\n","Epoch 4/50\n","1/1 [==============================] - 0s 135ms/step - loss: 355.1581 - accuracy: 0.0000e+00 - val_loss: 240.2511 - val_accuracy: 0.0000e+00\n","Epoch 5/50\n","1/1 [==============================] - 0s 131ms/step - loss: 308.6852 - accuracy: 0.0000e+00 - val_loss: 228.7530 - val_accuracy: 0.0000e+00\n","Epoch 6/50\n","1/1 [==============================] - 0s 123ms/step - loss: 209.5018 - accuracy: 0.0000e+00 - val_loss: 215.0124 - val_accuracy: 0.0000e+00\n","Epoch 7/50\n","1/1 [==============================] - 0s 167ms/step - loss: 147.5570 - accuracy: 0.2500 - val_loss: 201.5523 - val_accuracy: 0.0000e+00\n","Epoch 8/50\n","1/1 [==============================] - 0s 115ms/step - loss: 133.2028 - accuracy: 0.5000 - val_loss: 191.8604 - val_accuracy: 0.0000e+00\n","Epoch 9/50\n","1/1 [==============================] - 0s 141ms/step - loss: 152.4876 - accuracy: 1.0000 - val_loss: 184.1741 - val_accuracy: 0.0000e+00\n","Epoch 10/50\n","1/1 [==============================] - 0s 129ms/step - loss: 170.3597 - accuracy: 1.0000 - val_loss: 183.6650 - val_accuracy: 0.0000e+00\n","Epoch 11/50\n","1/1 [==============================] - 0s 159ms/step - loss: 169.3965 - accuracy: 1.0000 - val_loss: 189.1907 - val_accuracy: 0.0000e+00\n","Epoch 12/50\n","1/1 [==============================] - 0s 140ms/step - loss: 153.8049 - accuracy: 1.0000 - val_loss: 194.2305 - val_accuracy: 0.0000e+00\n","Epoch 13/50\n","1/1 [==============================] - 0s 123ms/step - loss: 135.2274 - accuracy: 0.7500 - val_loss: 203.4367 - val_accuracy: 0.0000e+00\n","Epoch 14/50\n","1/1 [==============================] - 0s 118ms/step - loss: 118.9085 - accuracy: 0.5000 - val_loss: 216.5261 - val_accuracy: 0.0000e+00\n","Epoch 15/50\n","1/1 [==============================] - 0s 128ms/step - loss: 105.3035 - accuracy: 0.2500 - val_loss: 231.3245 - val_accuracy: 0.0000e+00\n","Epoch 16/50\n","1/1 [==============================] - 0s 168ms/step - loss: 96.1680 - accuracy: 0.2500 - val_loss: 244.5790 - val_accuracy: 0.0000e+00\n","Epoch 17/50\n","1/1 [==============================] - 0s 133ms/step - loss: 90.2118 - accuracy: 0.0000e+00 - val_loss: 253.5360 - val_accuracy: 0.0000e+00\n","Epoch 18/50\n","1/1 [==============================] - 0s 123ms/step - loss: 86.2734 - accuracy: 0.2500 - val_loss: 257.2403 - val_accuracy: 0.0000e+00\n","Epoch 19/50\n","1/1 [==============================] - 0s 132ms/step - loss: 83.8260 - accuracy: 0.2500 - val_loss: 256.7816 - val_accuracy: 0.0000e+00\n","Epoch 20/50\n","1/1 [==============================] - 0s 147ms/step - loss: 82.0888 - accuracy: 0.2500 - val_loss: 254.5518 - val_accuracy: 0.0000e+00\n","Epoch 21/50\n","1/1 [==============================] - 0s 129ms/step - loss: 79.6116 - accuracy: 0.7500 - val_loss: 253.1788 - val_accuracy: 0.0000e+00\n","Epoch 22/50\n","1/1 [==============================] - 0s 167ms/step - loss: 75.1929 - accuracy: 0.7500 - val_loss: 254.7979 - val_accuracy: 0.0000e+00\n","Epoch 23/50\n","1/1 [==============================] - 0s 130ms/step - loss: 69.0760 - accuracy: 0.7500 - val_loss: 260.8653 - val_accuracy: 0.0000e+00\n","Epoch 24/50\n","1/1 [==============================] - 0s 151ms/step - loss: 63.0749 - accuracy: 0.7500 - val_loss: 272.1603 - val_accuracy: 0.0000e+00\n","Epoch 25/50\n","1/1 [==============================] - 0s 132ms/step - loss: 59.3123 - accuracy: 0.7500 - val_loss: 288.6635 - val_accuracy: 0.0000e+00\n","Epoch 26/50\n","1/1 [==============================] - 0s 130ms/step - loss: 58.4510 - accuracy: 0.7500 - val_loss: 309.2629 - val_accuracy: 0.0000e+00\n","Epoch 27/50\n","1/1 [==============================] - 0s 138ms/step - loss: 58.9569 - accuracy: 0.7500 - val_loss: 331.6859 - val_accuracy: 0.0000e+00\n","Epoch 28/50\n","1/1 [==============================] - 0s 118ms/step - loss: 58.2322 - accuracy: 0.2500 - val_loss: 353.0650 - val_accuracy: 0.0000e+00\n","Epoch 29/50\n","1/1 [==============================] - 0s 139ms/step - loss: 54.6628 - accuracy: 0.2500 - val_loss: 370.9248 - val_accuracy: 0.0000e+00\n","Epoch 30/50\n","1/1 [==============================] - 0s 131ms/step - loss: 48.7306 - accuracy: 0.2500 - val_loss: 384.0116 - val_accuracy: 0.0000e+00\n","Epoch 31/50\n","1/1 [==============================] - 0s 144ms/step - loss: 42.3763 - accuracy: 0.2500 - val_loss: 392.5432 - val_accuracy: 0.0000e+00\n","Epoch 32/50\n","1/1 [==============================] - 0s 157ms/step - loss: 37.3732 - accuracy: 0.5000 - val_loss: 397.9734 - val_accuracy: 0.0000e+00\n","Epoch 33/50\n","1/1 [==============================] - 0s 108ms/step - loss: 34.1179 - accuracy: 0.5000 - val_loss: 402.3998 - val_accuracy: 0.0000e+00\n","Epoch 34/50\n","1/1 [==============================] - 0s 117ms/step - loss: 31.6983 - accuracy: 0.5000 - val_loss: 407.9034 - val_accuracy: 0.0000e+00\n","Epoch 35/50\n","1/1 [==============================] - 0s 152ms/step - loss: 28.9556 - accuracy: 0.7500 - val_loss: 415.9398 - val_accuracy: 0.0000e+00\n","Epoch 36/50\n","1/1 [==============================] - 0s 143ms/step - loss: 25.4739 - accuracy: 0.7500 - val_loss: 427.0019 - val_accuracy: 0.0000e+00\n","Epoch 37/50\n","1/1 [==============================] - 0s 134ms/step - loss: 21.6711 - accuracy: 0.5000 - val_loss: 440.5670 - val_accuracy: 0.0000e+00\n","Epoch 38/50\n","1/1 [==============================] - 0s 127ms/step - loss: 18.1539 - accuracy: 0.5000 - val_loss: 455.2777 - val_accuracy: 0.0000e+00\n","Epoch 39/50\n","1/1 [==============================] - 0s 132ms/step - loss: 15.1588 - accuracy: 0.2500 - val_loss: 469.3511 - val_accuracy: 0.0000e+00\n","Epoch 40/50\n","1/1 [==============================] - 0s 140ms/step - loss: 12.5847 - accuracy: 0.5000 - val_loss: 481.1132 - val_accuracy: 0.0000e+00\n","Epoch 41/50\n","1/1 [==============================] - 0s 109ms/step - loss: 10.3590 - accuracy: 0.2500 - val_loss: 489.5405 - val_accuracy: 0.0000e+00\n","Epoch 42/50\n","1/1 [==============================] - 0s 157ms/step - loss: 8.5760 - accuracy: 0.5000 - val_loss: 494.5608 - val_accuracy: 0.0000e+00\n","Epoch 43/50\n","1/1 [==============================] - 0s 139ms/step - loss: 7.2632 - accuracy: 0.7500 - val_loss: 497.0103 - val_accuracy: 0.0000e+00\n","Epoch 44/50\n","1/1 [==============================] - 0s 155ms/step - loss: 6.1591 - accuracy: 0.7500 - val_loss: 498.2778 - val_accuracy: 0.0000e+00\n","Epoch 45/50\n","1/1 [==============================] - 0s 188ms/step - loss: 4.8784 - accuracy: 0.7500 - val_loss: 499.8471 - val_accuracy: 0.0000e+00\n","Epoch 46/50\n","1/1 [==============================] - 0s 193ms/step - loss: 3.3352 - accuracy: 0.7500 - val_loss: 502.8449 - val_accuracy: 0.0000e+00\n","Epoch 47/50\n","1/1 [==============================] - 0s 178ms/step - loss: 1.9131 - accuracy: 1.0000 - val_loss: 507.8120 - val_accuracy: 0.0000e+00\n","Epoch 48/50\n","1/1 [==============================] - 0s 209ms/step - loss: 1.1216 - accuracy: 0.7500 - val_loss: 514.6177 - val_accuracy: 0.0000e+00\n","Epoch 49/50\n","1/1 [==============================] - 0s 166ms/step - loss: 1.0743 - accuracy: 0.7500 - val_loss: 522.6026 - val_accuracy: 0.0000e+00\n","Epoch 50/50\n","1/1 [==============================] - 0s 187ms/step - loss: 1.3599 - accuracy: 0.2500 - val_loss: 530.8563 - val_accuracy: 0.0000e+00\n","1/1 [==============================] - 0s 136ms/step\n","1/1 [==============================] - 0s 51ms/step - loss: 89.8238 - accuracy: 1.0000\n","Test Loss: 89.8238, Test accuracy : 1.0000\n","Epoch 1/50\n","9/9 [==============================] - 2s 145ms/step - loss: 682.1696 - accuracy: 0.4194 - val_loss: 237.7184 - val_accuracy: 0.8065\n","Epoch 2/50\n","9/9 [==============================] - 1s 147ms/step - loss: 266.6971 - accuracy: 0.7670 - val_loss: 208.6681 - val_accuracy: 0.8065\n","Epoch 3/50\n","9/9 [==============================] - 1s 165ms/step - loss: 202.6759 - accuracy: 0.7061 - val_loss: 223.6230 - val_accuracy: 0.8065\n","Epoch 4/50\n","9/9 [==============================] - 1s 148ms/step - loss: 166.5113 - accuracy: 0.8280 - val_loss: 195.9199 - val_accuracy: 0.8065\n","Epoch 5/50\n","9/9 [==============================] - 1s 124ms/step - loss: 120.0128 - accuracy: 0.8566 - val_loss: 193.1459 - val_accuracy: 0.8387\n","Epoch 6/50\n","9/9 [==============================] - 1s 106ms/step - loss: 83.8437 - accuracy: 0.8853 - val_loss: 204.4869 - val_accuracy: 0.8387\n","Epoch 7/50\n","9/9 [==============================] - 1s 106ms/step - loss: 62.0920 - accuracy: 0.8961 - val_loss: 191.8659 - val_accuracy: 0.8387\n","Epoch 8/50\n","9/9 [==============================] - 1s 107ms/step - loss: 49.0008 - accuracy: 0.9032 - val_loss: 185.0887 - val_accuracy: 0.8387\n","Epoch 9/50\n","9/9 [==============================] - 1s 100ms/step - loss: 42.3261 - accuracy: 0.8996 - val_loss: 193.7479 - val_accuracy: 0.8387\n","Epoch 10/50\n","9/9 [==============================] - 1s 107ms/step - loss: 37.4380 - accuracy: 0.9032 - val_loss: 187.4338 - val_accuracy: 0.8387\n","Epoch 11/50\n","9/9 [==============================] - 1s 107ms/step - loss: 31.5292 - accuracy: 0.8996 - val_loss: 187.4740 - val_accuracy: 0.8387\n","Epoch 12/50\n","9/9 [==============================] - 1s 107ms/step - loss: 27.1529 - accuracy: 0.9104 - val_loss: 186.1955 - val_accuracy: 0.8387\n","Epoch 13/50\n","9/9 [==============================] - 1s 110ms/step - loss: 24.7004 - accuracy: 0.9104 - val_loss: 188.6572 - val_accuracy: 0.8387\n","Epoch 14/50\n","9/9 [==============================] - 1s 107ms/step - loss: 22.0553 - accuracy: 0.9140 - val_loss: 186.6548 - val_accuracy: 0.8387\n","Epoch 15/50\n","9/9 [==============================] - 1s 100ms/step - loss: 19.8690 - accuracy: 0.9176 - val_loss: 188.6189 - val_accuracy: 0.8387\n","Epoch 16/50\n","9/9 [==============================] - 1s 152ms/step - loss: 17.8467 - accuracy: 0.9247 - val_loss: 187.5796 - val_accuracy: 0.8387\n","Epoch 17/50\n","9/9 [==============================] - 1s 155ms/step - loss: 16.4713 - accuracy: 0.9140 - val_loss: 186.8619 - val_accuracy: 0.8387\n","Epoch 18/50\n","9/9 [==============================] - 1s 142ms/step - loss: 15.2357 - accuracy: 0.9247 - val_loss: 187.4088 - val_accuracy: 0.8387\n","Epoch 19/50\n","9/9 [==============================] - 1s 156ms/step - loss: 14.2606 - accuracy: 0.9247 - val_loss: 189.8012 - val_accuracy: 0.8387\n","Epoch 20/50\n","9/9 [==============================] - 1s 122ms/step - loss: 12.3484 - accuracy: 0.9247 - val_loss: 185.7947 - val_accuracy: 0.8387\n","Epoch 21/50\n","9/9 [==============================] - 1s 105ms/step - loss: 11.2237 - accuracy: 0.9211 - val_loss: 188.8549 - val_accuracy: 0.8387\n","Epoch 22/50\n","9/9 [==============================] - 1s 105ms/step - loss: 11.9110 - accuracy: 0.9247 - val_loss: 185.0070 - val_accuracy: 0.8387\n","Epoch 23/50\n","9/9 [==============================] - 1s 94ms/step - loss: 12.5103 - accuracy: 0.9283 - val_loss: 188.3110 - val_accuracy: 0.8387\n","Epoch 24/50\n","9/9 [==============================] - 1s 139ms/step - loss: 15.1504 - accuracy: 0.9319 - val_loss: 186.2493 - val_accuracy: 0.8387\n","Epoch 25/50\n","9/9 [==============================] - 1s 110ms/step - loss: 12.1969 - accuracy: 0.9247 - val_loss: 187.5635 - val_accuracy: 0.8387\n","Epoch 26/50\n","9/9 [==============================] - 1s 110ms/step - loss: 10.8631 - accuracy: 0.9391 - val_loss: 188.0592 - val_accuracy: 0.8387\n","Epoch 27/50\n","9/9 [==============================] - 1s 117ms/step - loss: 15.0389 - accuracy: 0.9283 - val_loss: 186.3804 - val_accuracy: 0.8387\n","Epoch 28/50\n","9/9 [==============================] - 1s 105ms/step - loss: 18.5358 - accuracy: 0.9462 - val_loss: 184.6460 - val_accuracy: 0.8387\n","Epoch 29/50\n","9/9 [==============================] - 1s 105ms/step - loss: 10.2893 - accuracy: 0.9427 - val_loss: 186.4651 - val_accuracy: 0.8387\n","Epoch 30/50\n","9/9 [==============================] - 1s 123ms/step - loss: 18.4972 - accuracy: 0.9391 - val_loss: 185.2132 - val_accuracy: 0.8387\n","Epoch 31/50\n","9/9 [==============================] - 1s 168ms/step - loss: 14.5566 - accuracy: 0.9534 - val_loss: 187.0202 - val_accuracy: 0.8387\n","Epoch 32/50\n","9/9 [==============================] - 1s 146ms/step - loss: 12.4051 - accuracy: 0.9462 - val_loss: 184.0158 - val_accuracy: 0.8387\n","Epoch 33/50\n","9/9 [==============================] - 2s 167ms/step - loss: 9.2415 - accuracy: 0.9462 - val_loss: 190.8856 - val_accuracy: 0.8387\n","Epoch 34/50\n","9/9 [==============================] - 1s 124ms/step - loss: 8.4084 - accuracy: 0.9606 - val_loss: 186.1360 - val_accuracy: 0.8387\n","Epoch 35/50\n","9/9 [==============================] - 1s 109ms/step - loss: 7.9650 - accuracy: 0.9570 - val_loss: 189.5688 - val_accuracy: 0.8387\n","Epoch 36/50\n","9/9 [==============================] - 1s 105ms/step - loss: 6.9396 - accuracy: 0.9570 - val_loss: 186.5022 - val_accuracy: 0.8387\n","Epoch 37/50\n","9/9 [==============================] - 1s 109ms/step - loss: 6.3507 - accuracy: 0.9570 - val_loss: 188.3785 - val_accuracy: 0.8387\n","Epoch 38/50\n","9/9 [==============================] - 1s 99ms/step - loss: 5.9835 - accuracy: 0.9642 - val_loss: 185.6260 - val_accuracy: 0.8387\n","Epoch 39/50\n","9/9 [==============================] - 1s 104ms/step - loss: 5.5110 - accuracy: 0.9498 - val_loss: 188.9162 - val_accuracy: 0.8387\n","Epoch 40/50\n","9/9 [==============================] - 1s 103ms/step - loss: 5.2743 - accuracy: 0.9570 - val_loss: 186.2070 - val_accuracy: 0.8387\n","Epoch 41/50\n","9/9 [==============================] - 1s 108ms/step - loss: 5.0903 - accuracy: 0.9534 - val_loss: 188.1830 - val_accuracy: 0.8387\n","Epoch 42/50\n","9/9 [==============================] - 1s 103ms/step - loss: 4.8326 - accuracy: 0.9677 - val_loss: 185.4988 - val_accuracy: 0.8387\n","Epoch 43/50\n","9/9 [==============================] - 1s 108ms/step - loss: 4.6201 - accuracy: 0.9642 - val_loss: 189.9011 - val_accuracy: 0.8387\n","Epoch 44/50\n","9/9 [==============================] - 1s 125ms/step - loss: 4.7786 - accuracy: 0.9677 - val_loss: 184.3578 - val_accuracy: 0.8387\n","Epoch 45/50\n","9/9 [==============================] - 1s 157ms/step - loss: 5.1392 - accuracy: 0.9534 - val_loss: 188.3858 - val_accuracy: 0.8387\n","Epoch 46/50\n","9/9 [==============================] - 2s 167ms/step - loss: 4.7698 - accuracy: 0.9677 - val_loss: 186.0593 - val_accuracy: 0.8387\n","Epoch 47/50\n","9/9 [==============================] - 1s 155ms/step - loss: 5.3530 - accuracy: 0.9677 - val_loss: 203.1777 - val_accuracy: 0.8387\n","Epoch 48/50\n","9/9 [==============================] - 1s 128ms/step - loss: 5.7967 - accuracy: 0.9570 - val_loss: 179.8239 - val_accuracy: 0.8387\n","Epoch 49/50\n","9/9 [==============================] - 1s 110ms/step - loss: 6.8717 - accuracy: 0.9534 - val_loss: 213.1720 - val_accuracy: 0.8387\n","Epoch 50/50\n","9/9 [==============================] - 1s 101ms/step - loss: 7.7106 - accuracy: 0.9606 - val_loss: 177.2228 - val_accuracy: 0.8387\n","3/3 [==============================] - 0s 15ms/step\n","3/3 [==============================] - 0s 22ms/step - loss: 28.1466 - accuracy: 0.9875\n","Test Loss: 28.1466, Test accuracy : 0.9875\n","Epoch 1/50\n","7/7 [==============================] - 1s 135ms/step - loss: 468.1184 - accuracy: 0.3649 - val_loss: 369.7163 - val_accuracy: 0.1250\n","Epoch 2/50\n","7/7 [==============================] - 1s 101ms/step - loss: 236.1017 - accuracy: 0.2607 - val_loss: 348.2802 - val_accuracy: 0.1250\n","Epoch 3/50\n","7/7 [==============================] - 1s 101ms/step - loss: 117.3729 - accuracy: 0.3507 - val_loss: 316.2354 - val_accuracy: 0.0833\n","Epoch 4/50\n","7/7 [==============================] - 1s 119ms/step - loss: 77.9240 - accuracy: 0.3981 - val_loss: 299.7079 - val_accuracy: 0.0833\n","Epoch 5/50\n","7/7 [==============================] - 1s 111ms/step - loss: 60.5537 - accuracy: 0.5924 - val_loss: 303.1979 - val_accuracy: 0.1250\n","Epoch 6/50\n","7/7 [==============================] - 1s 116ms/step - loss: 43.3750 - accuracy: 0.4834 - val_loss: 307.9793 - val_accuracy: 0.2083\n","Epoch 7/50\n","7/7 [==============================] - 1s 113ms/step - loss: 32.4438 - accuracy: 0.5972 - val_loss: 302.0261 - val_accuracy: 0.1667\n","Epoch 8/50\n","7/7 [==============================] - 1s 117ms/step - loss: 27.7072 - accuracy: 0.6351 - val_loss: 292.1803 - val_accuracy: 0.0833\n","Epoch 9/50\n","7/7 [==============================] - 1s 106ms/step - loss: 21.0417 - accuracy: 0.5308 - val_loss: 289.5034 - val_accuracy: 0.1250\n","Epoch 10/50\n","7/7 [==============================] - 1s 150ms/step - loss: 18.3946 - accuracy: 0.5355 - val_loss: 292.1649 - val_accuracy: 0.1667\n","Epoch 11/50\n","7/7 [==============================] - 1s 175ms/step - loss: 15.7970 - accuracy: 0.6066 - val_loss: 288.9179 - val_accuracy: 0.1667\n","Epoch 12/50\n","7/7 [==============================] - 1s 177ms/step - loss: 14.0559 - accuracy: 0.5829 - val_loss: 289.4565 - val_accuracy: 0.2500\n","Epoch 13/50\n","7/7 [==============================] - 1s 164ms/step - loss: 11.6785 - accuracy: 0.6209 - val_loss: 292.2485 - val_accuracy: 0.2917\n","Epoch 14/50\n","7/7 [==============================] - 1s 158ms/step - loss: 10.1584 - accuracy: 0.5640 - val_loss: 291.0882 - val_accuracy: 0.2500\n","Epoch 15/50\n","7/7 [==============================] - 1s 120ms/step - loss: 9.2191 - accuracy: 0.5877 - val_loss: 292.2823 - val_accuracy: 0.2083\n","Epoch 16/50\n","7/7 [==============================] - 1s 112ms/step - loss: 7.7010 - accuracy: 0.5403 - val_loss: 293.9033 - val_accuracy: 0.2500\n","Epoch 17/50\n","7/7 [==============================] - 1s 109ms/step - loss: 7.0535 - accuracy: 0.6493 - val_loss: 291.7189 - val_accuracy: 0.2500\n","Epoch 18/50\n","7/7 [==============================] - 1s 106ms/step - loss: 6.2825 - accuracy: 0.5498 - val_loss: 293.4421 - val_accuracy: 0.2500\n","Epoch 19/50\n","7/7 [==============================] - 1s 115ms/step - loss: 6.0229 - accuracy: 0.6303 - val_loss: 295.4971 - val_accuracy: 0.2500\n","Epoch 20/50\n","7/7 [==============================] - 1s 117ms/step - loss: 5.4956 - accuracy: 0.6209 - val_loss: 290.6656 - val_accuracy: 0.2083\n","Epoch 21/50\n","7/7 [==============================] - 1s 114ms/step - loss: 5.0427 - accuracy: 0.5924 - val_loss: 295.1148 - val_accuracy: 0.2083\n","Epoch 22/50\n","7/7 [==============================] - 1s 111ms/step - loss: 5.0023 - accuracy: 0.6019 - val_loss: 293.0142 - val_accuracy: 0.3333\n","Epoch 23/50\n","7/7 [==============================] - 1s 103ms/step - loss: 4.3467 - accuracy: 0.6682 - val_loss: 292.3350 - val_accuracy: 0.3750\n","Epoch 24/50\n","7/7 [==============================] - 1s 103ms/step - loss: 4.2733 - accuracy: 0.6303 - val_loss: 294.6232 - val_accuracy: 0.3333\n","Epoch 25/50\n","7/7 [==============================] - 1s 107ms/step - loss: 4.6032 - accuracy: 0.6493 - val_loss: 291.2616 - val_accuracy: 0.2917\n","Epoch 26/50\n","7/7 [==============================] - 1s 111ms/step - loss: 5.8587 - accuracy: 0.6730 - val_loss: 297.7520 - val_accuracy: 0.4167\n","Epoch 27/50\n","7/7 [==============================] - 1s 121ms/step - loss: 4.1597 - accuracy: 0.6019 - val_loss: 290.5218 - val_accuracy: 0.2083\n","Epoch 28/50\n","7/7 [==============================] - 2s 256ms/step - loss: 4.1228 - accuracy: 0.6777 - val_loss: 298.7227 - val_accuracy: 0.4167\n","Epoch 29/50\n","7/7 [==============================] - 1s 166ms/step - loss: 4.0453 - accuracy: 0.6445 - val_loss: 291.7292 - val_accuracy: 0.2083\n","Epoch 30/50\n","7/7 [==============================] - 1s 157ms/step - loss: 4.9890 - accuracy: 0.6351 - val_loss: 308.0158 - val_accuracy: 0.4583\n","Epoch 31/50\n","7/7 [==============================] - 1s 154ms/step - loss: 6.1338 - accuracy: 0.6777 - val_loss: 278.6686 - val_accuracy: 0.2917\n","Epoch 32/50\n","7/7 [==============================] - 1s 109ms/step - loss: 8.5321 - accuracy: 0.6445 - val_loss: 311.0830 - val_accuracy: 0.4583\n","Epoch 33/50\n","7/7 [==============================] - 1s 109ms/step - loss: 13.2770 - accuracy: 0.5687 - val_loss: 290.6342 - val_accuracy: 0.2083\n","Epoch 34/50\n","7/7 [==============================] - 1s 104ms/step - loss: 10.6532 - accuracy: 0.6019 - val_loss: 300.2765 - val_accuracy: 0.5417\n","Epoch 35/50\n","7/7 [==============================] - 1s 104ms/step - loss: 9.4125 - accuracy: 0.5640 - val_loss: 298.1004 - val_accuracy: 0.3750\n","Epoch 36/50\n","7/7 [==============================] - 1s 107ms/step - loss: 11.9030 - accuracy: 0.6256 - val_loss: 287.0887 - val_accuracy: 0.4167\n","Epoch 37/50\n","7/7 [==============================] - 1s 109ms/step - loss: 8.1194 - accuracy: 0.5071 - val_loss: 288.8292 - val_accuracy: 0.4167\n","Epoch 38/50\n","7/7 [==============================] - 1s 106ms/step - loss: 92.6197 - accuracy: 0.6682 - val_loss: 277.0532 - val_accuracy: 0.2917\n","Epoch 39/50\n","7/7 [==============================] - 1s 104ms/step - loss: 21.2565 - accuracy: 0.5071 - val_loss: 309.7732 - val_accuracy: 0.2500\n","Epoch 40/50\n","7/7 [==============================] - 1s 109ms/step - loss: 21.0813 - accuracy: 0.5450 - val_loss: 316.1574 - val_accuracy: 0.4167\n","Epoch 41/50\n","7/7 [==============================] - 1s 111ms/step - loss: 21.7087 - accuracy: 0.7678 - val_loss: 321.6458 - val_accuracy: 0.4167\n","Epoch 42/50\n","7/7 [==============================] - 1s 115ms/step - loss: 12.7646 - accuracy: 0.6967 - val_loss: 319.4969 - val_accuracy: 0.2917\n","Epoch 43/50\n","7/7 [==============================] - 1s 103ms/step - loss: 10.5595 - accuracy: 0.4882 - val_loss: 313.5514 - val_accuracy: 0.3333\n","Epoch 44/50\n","7/7 [==============================] - 1s 103ms/step - loss: 11.4259 - accuracy: 0.6825 - val_loss: 306.2810 - val_accuracy: 0.3750\n","Epoch 45/50\n","7/7 [==============================] - 1s 158ms/step - loss: 8.4621 - accuracy: 0.5829 - val_loss: 316.6764 - val_accuracy: 0.4167\n","Epoch 46/50\n","7/7 [==============================] - 1s 164ms/step - loss: 9.5055 - accuracy: 0.7583 - val_loss: 320.0501 - val_accuracy: 0.3333\n","Epoch 47/50\n","7/7 [==============================] - 1s 140ms/step - loss: 7.3303 - accuracy: 0.6825 - val_loss: 308.8901 - val_accuracy: 0.3750\n","Epoch 48/50\n","7/7 [==============================] - 1s 148ms/step - loss: 6.2722 - accuracy: 0.6209 - val_loss: 312.8405 - val_accuracy: 0.3750\n","Epoch 49/50\n","7/7 [==============================] - 1s 146ms/step - loss: 6.1999 - accuracy: 0.7062 - val_loss: 316.4035 - val_accuracy: 0.4167\n","Epoch 50/50\n","7/7 [==============================] - 1s 100ms/step - loss: 6.0995 - accuracy: 0.6635 - val_loss: 311.1709 - val_accuracy: 0.2917\n","2/2 [==============================] - 0s 19ms/step\n","2/2 [==============================] - 0s 20ms/step - loss: 201.7663 - accuracy: 0.9333\n","Test Loss: 201.7663, Test accuracy : 0.9333\n","Epoch 1/50\n","12/12 [==============================] - 2s 112ms/step - loss: 489.7709 - accuracy: 0.6085 - val_loss: 365.2438 - val_accuracy: 0.3000\n","Epoch 2/50\n","12/12 [==============================] - 1s 94ms/step - loss: 236.9374 - accuracy: 0.7662 - val_loss: 370.5585 - val_accuracy: 0.3500\n","Epoch 3/50\n","12/12 [==============================] - 1s 108ms/step - loss: 155.6808 - accuracy: 0.7915 - val_loss: 331.4617 - val_accuracy: 0.4250\n","Epoch 4/50\n","12/12 [==============================] - 2s 137ms/step - loss: 155.0006 - accuracy: 0.8282 - val_loss: 350.1717 - val_accuracy: 0.6500\n","Epoch 5/50\n","12/12 [==============================] - 2s 138ms/step - loss: 139.8252 - accuracy: 0.8479 - val_loss: 305.3177 - val_accuracy: 0.4750\n","Epoch 6/50\n","12/12 [==============================] - 2s 144ms/step - loss: 121.6817 - accuracy: 0.8620 - val_loss: 309.6440 - val_accuracy: 0.6000\n","Epoch 7/50\n","12/12 [==============================] - 1s 103ms/step - loss: 72.2608 - accuracy: 0.8732 - val_loss: 314.4053 - val_accuracy: 0.6250\n","Epoch 8/50\n","12/12 [==============================] - 1s 98ms/step - loss: 76.0946 - accuracy: 0.8789 - val_loss: 302.5605 - val_accuracy: 0.7250\n","Epoch 9/50\n","12/12 [==============================] - 1s 93ms/step - loss: 75.4613 - accuracy: 0.9014 - val_loss: 293.6657 - val_accuracy: 0.7000\n","Epoch 10/50\n","12/12 [==============================] - 1s 98ms/step - loss: 69.3932 - accuracy: 0.8901 - val_loss: 298.7005 - val_accuracy: 0.7000\n","Epoch 11/50\n","12/12 [==============================] - 1s 123ms/step - loss: 56.2321 - accuracy: 0.9239 - val_loss: 275.9718 - val_accuracy: 0.7750\n","Epoch 12/50\n","12/12 [==============================] - 1s 102ms/step - loss: 42.6967 - accuracy: 0.9380 - val_loss: 277.2932 - val_accuracy: 0.7000\n","Epoch 13/50\n","12/12 [==============================] - 1s 102ms/step - loss: 35.7783 - accuracy: 0.9408 - val_loss: 280.7884 - val_accuracy: 0.8000\n","Epoch 14/50\n","12/12 [==============================] - 1s 100ms/step - loss: 28.9492 - accuracy: 0.9352 - val_loss: 266.8244 - val_accuracy: 0.7250\n","Epoch 15/50\n","12/12 [==============================] - 1s 119ms/step - loss: 26.4720 - accuracy: 0.9296 - val_loss: 277.8067 - val_accuracy: 0.8000\n","Epoch 16/50\n","12/12 [==============================] - 2s 131ms/step - loss: 24.5107 - accuracy: 0.9268 - val_loss: 264.9904 - val_accuracy: 0.8000\n","Epoch 17/50\n","12/12 [==============================] - 2s 140ms/step - loss: 18.4710 - accuracy: 0.9437 - val_loss: 272.2668 - val_accuracy: 0.8000\n","Epoch 18/50\n","12/12 [==============================] - 2s 140ms/step - loss: 15.1406 - accuracy: 0.9577 - val_loss: 262.3330 - val_accuracy: 0.8000\n","Epoch 19/50\n","12/12 [==============================] - 1s 98ms/step - loss: 18.6481 - accuracy: 0.9352 - val_loss: 279.0049 - val_accuracy: 0.7750\n","Epoch 20/50\n","12/12 [==============================] - 1s 96ms/step - loss: 23.3678 - accuracy: 0.9549 - val_loss: 278.6600 - val_accuracy: 0.7250\n","Epoch 21/50\n","12/12 [==============================] - 1s 102ms/step - loss: 29.8707 - accuracy: 0.9634 - val_loss: 269.2412 - val_accuracy: 0.8000\n","Epoch 22/50\n","12/12 [==============================] - 1s 102ms/step - loss: 29.2456 - accuracy: 0.9465 - val_loss: 298.5180 - val_accuracy: 0.7000\n","Epoch 23/50\n","12/12 [==============================] - 1s 96ms/step - loss: 43.4972 - accuracy: 0.9493 - val_loss: 257.7573 - val_accuracy: 0.8000\n","Epoch 24/50\n","12/12 [==============================] - 1s 101ms/step - loss: 66.7574 - accuracy: 0.9408 - val_loss: 297.8057 - val_accuracy: 0.7500\n","Epoch 25/50\n","12/12 [==============================] - 1s 97ms/step - loss: 42.2505 - accuracy: 0.9465 - val_loss: 265.8122 - val_accuracy: 0.8000\n","Epoch 26/50\n","12/12 [==============================] - 1s 98ms/step - loss: 25.2260 - accuracy: 0.9437 - val_loss: 282.7436 - val_accuracy: 0.7750\n","Epoch 27/50\n","12/12 [==============================] - 1s 114ms/step - loss: 18.1173 - accuracy: 0.9521 - val_loss: 265.9053 - val_accuracy: 0.8000\n","Epoch 28/50\n","12/12 [==============================] - 2s 139ms/step - loss: 9.1972 - accuracy: 0.9577 - val_loss: 260.9165 - val_accuracy: 0.8000\n","Epoch 29/50\n","12/12 [==============================] - 2s 140ms/step - loss: 24.1789 - accuracy: 0.9606 - val_loss: 287.1046 - val_accuracy: 0.8000\n","Epoch 30/50\n","12/12 [==============================] - 2s 134ms/step - loss: 19.5576 - accuracy: 0.9549 - val_loss: 258.0694 - val_accuracy: 0.8000\n","Epoch 31/50\n","12/12 [==============================] - 1s 95ms/step - loss: 11.6213 - accuracy: 0.9662 - val_loss: 265.6928 - val_accuracy: 0.8000\n","Epoch 32/50\n","12/12 [==============================] - 1s 101ms/step - loss: 9.3201 - accuracy: 0.9662 - val_loss: 259.6833 - val_accuracy: 0.8000\n","Epoch 33/50\n","12/12 [==============================] - 1s 101ms/step - loss: 6.1443 - accuracy: 0.9690 - val_loss: 263.2462 - val_accuracy: 0.8000\n","Epoch 34/50\n","12/12 [==============================] - 1s 98ms/step - loss: 5.9842 - accuracy: 0.9690 - val_loss: 262.3470 - val_accuracy: 0.8000\n","Epoch 35/50\n","12/12 [==============================] - 1s 93ms/step - loss: 4.8095 - accuracy: 0.9775 - val_loss: 263.8814 - val_accuracy: 0.8000\n","Epoch 36/50\n","12/12 [==============================] - 1s 104ms/step - loss: 3.3662 - accuracy: 0.9831 - val_loss: 261.2179 - val_accuracy: 0.8000\n","Epoch 37/50\n","12/12 [==============================] - 1s 100ms/step - loss: 3.5050 - accuracy: 0.9803 - val_loss: 264.7808 - val_accuracy: 0.8000\n","Epoch 38/50\n","12/12 [==============================] - 1s 97ms/step - loss: 3.2422 - accuracy: 0.9831 - val_loss: 261.1353 - val_accuracy: 0.8000\n","Epoch 39/50\n","12/12 [==============================] - 1s 121ms/step - loss: 2.6888 - accuracy: 0.9859 - val_loss: 262.7817 - val_accuracy: 0.8000\n","Epoch 40/50\n","12/12 [==============================] - 2s 138ms/step - loss: 2.3789 - accuracy: 0.9831 - val_loss: 262.2187 - val_accuracy: 0.8000\n","Epoch 41/50\n","12/12 [==============================] - 2s 144ms/step - loss: 2.8008 - accuracy: 0.9859 - val_loss: 263.5705 - val_accuracy: 0.8000\n","Epoch 42/50\n","12/12 [==============================] - 2s 124ms/step - loss: 2.4825 - accuracy: 0.9831 - val_loss: 260.6436 - val_accuracy: 0.8000\n","Epoch 43/50\n","12/12 [==============================] - 1s 99ms/step - loss: 2.2681 - accuracy: 0.9915 - val_loss: 264.0234 - val_accuracy: 0.8000\n","Epoch 44/50\n","12/12 [==============================] - 1s 97ms/step - loss: 2.1314 - accuracy: 0.9831 - val_loss: 260.9021 - val_accuracy: 0.8000\n","Epoch 45/50\n","12/12 [==============================] - 1s 103ms/step - loss: 2.2191 - accuracy: 0.9887 - val_loss: 265.3692 - val_accuracy: 0.8000\n","Epoch 46/50\n","12/12 [==============================] - 1s 98ms/step - loss: 2.1558 - accuracy: 0.9944 - val_loss: 260.7775 - val_accuracy: 0.8000\n","Epoch 47/50\n","12/12 [==============================] - 1s 95ms/step - loss: 2.1878 - accuracy: 0.9859 - val_loss: 265.2549 - val_accuracy: 0.8000\n","Epoch 48/50\n","12/12 [==============================] - 1s 98ms/step - loss: 2.1544 - accuracy: 0.9887 - val_loss: 261.0728 - val_accuracy: 0.8000\n","Epoch 49/50\n","12/12 [==============================] - 1s 99ms/step - loss: 2.3547 - accuracy: 0.9972 - val_loss: 266.8422 - val_accuracy: 0.8000\n","Epoch 50/50\n","12/12 [==============================] - 1s 101ms/step - loss: 2.0703 - accuracy: 0.9944 - val_loss: 258.8847 - val_accuracy: 0.8000\n","4/4 [==============================] - 0s 17ms/step\n","4/4 [==============================] - 0s 14ms/step - loss: 4.9547 - accuracy: 1.0000\n","Test Loss: 4.9547, Test accuracy : 1.0000\n","Epoch 1/50\n","17/17 [==============================] - 3s 152ms/step - loss: 189.2842 - accuracy: 0.2075 - val_loss: 100.2476 - val_accuracy: 0.1667\n","Epoch 2/50\n","17/17 [==============================] - 3s 154ms/step - loss: 157.8769 - accuracy: 0.2411 - val_loss: 109.4912 - val_accuracy: 0.1167\n","Epoch 3/50\n","17/17 [==============================] - 2s 143ms/step - loss: 118.7388 - accuracy: 0.2916 - val_loss: 104.3454 - val_accuracy: 0.1167\n","Epoch 4/50\n","17/17 [==============================] - 2s 102ms/step - loss: 90.3825 - accuracy: 0.3252 - val_loss: 104.1797 - val_accuracy: 0.1167\n","Epoch 5/50\n","17/17 [==============================] - 2s 98ms/step - loss: 72.7039 - accuracy: 0.3234 - val_loss: 103.7317 - val_accuracy: 0.1500\n","Epoch 6/50\n","17/17 [==============================] - 2s 101ms/step - loss: 62.2281 - accuracy: 0.3439 - val_loss: 104.1518 - val_accuracy: 0.1667\n","Epoch 7/50\n","17/17 [==============================] - 2s 100ms/step - loss: 52.8350 - accuracy: 0.3776 - val_loss: 100.5759 - val_accuracy: 0.1333\n","Epoch 8/50\n","17/17 [==============================] - 2s 100ms/step - loss: 46.6017 - accuracy: 0.3907 - val_loss: 100.1119 - val_accuracy: 0.1667\n","Epoch 9/50\n","17/17 [==============================] - 2s 120ms/step - loss: 44.0582 - accuracy: 0.3850 - val_loss: 102.6957 - val_accuracy: 0.1667\n","Epoch 10/50\n","17/17 [==============================] - 2s 142ms/step - loss: 43.4624 - accuracy: 0.3944 - val_loss: 99.3256 - val_accuracy: 0.1833\n","Epoch 11/50\n","17/17 [==============================] - 2s 142ms/step - loss: 41.2389 - accuracy: 0.3925 - val_loss: 113.6920 - val_accuracy: 0.1333\n","Epoch 12/50\n","17/17 [==============================] - 2s 99ms/step - loss: 36.1609 - accuracy: 0.3757 - val_loss: 100.8231 - val_accuracy: 0.2167\n","Epoch 13/50\n","17/17 [==============================] - 2s 106ms/step - loss: 32.0701 - accuracy: 0.3738 - val_loss: 107.0089 - val_accuracy: 0.1167\n","Epoch 14/50\n","17/17 [==============================] - 2s 99ms/step - loss: 29.1558 - accuracy: 0.4037 - val_loss: 99.7818 - val_accuracy: 0.2167\n","Epoch 15/50\n","17/17 [==============================] - 2s 101ms/step - loss: 26.5570 - accuracy: 0.4037 - val_loss: 103.0351 - val_accuracy: 0.2000\n","Epoch 16/50\n","17/17 [==============================] - 2s 101ms/step - loss: 25.2938 - accuracy: 0.4056 - val_loss: 100.3499 - val_accuracy: 0.2167\n","Epoch 17/50\n","17/17 [==============================] - 2s 110ms/step - loss: 23.3947 - accuracy: 0.3963 - val_loss: 107.2411 - val_accuracy: 0.1333\n","Epoch 18/50\n","17/17 [==============================] - 3s 148ms/step - loss: 23.0691 - accuracy: 0.3963 - val_loss: 107.0428 - val_accuracy: 0.2000\n","Epoch 19/50\n","17/17 [==============================] - 2s 143ms/step - loss: 26.4722 - accuracy: 0.3888 - val_loss: 105.0730 - val_accuracy: 0.1833\n","Epoch 20/50\n","17/17 [==============================] - 2s 101ms/step - loss: 23.6853 - accuracy: 0.3850 - val_loss: 105.3448 - val_accuracy: 0.2667\n","Epoch 21/50\n","17/17 [==============================] - 2s 103ms/step - loss: 27.8207 - accuracy: 0.3888 - val_loss: 106.1816 - val_accuracy: 0.2500\n","Epoch 22/50\n","17/17 [==============================] - 2s 97ms/step - loss: 27.7881 - accuracy: 0.3963 - val_loss: 104.6707 - val_accuracy: 0.2000\n","Epoch 23/50\n","17/17 [==============================] - 2s 103ms/step - loss: 25.7727 - accuracy: 0.3944 - val_loss: 109.6939 - val_accuracy: 0.2667\n","Epoch 24/50\n","17/17 [==============================] - 2s 104ms/step - loss: 25.1394 - accuracy: 0.4206 - val_loss: 108.9733 - val_accuracy: 0.2500\n","Epoch 25/50\n","17/17 [==============================] - 2s 116ms/step - loss: 22.3796 - accuracy: 0.3888 - val_loss: 104.0362 - val_accuracy: 0.2500\n","Epoch 26/50\n","17/17 [==============================] - 2s 144ms/step - loss: 19.7067 - accuracy: 0.3907 - val_loss: 105.7389 - val_accuracy: 0.2167\n","Epoch 27/50\n","17/17 [==============================] - 3s 151ms/step - loss: 18.3888 - accuracy: 0.3888 - val_loss: 105.4801 - val_accuracy: 0.2333\n","Epoch 28/50\n","17/17 [==============================] - 2s 101ms/step - loss: 18.0353 - accuracy: 0.3944 - val_loss: 108.2380 - val_accuracy: 0.2333\n","Epoch 29/50\n","17/17 [==============================] - 2s 105ms/step - loss: 18.5296 - accuracy: 0.3869 - val_loss: 108.1219 - val_accuracy: 0.2833\n","Epoch 30/50\n","17/17 [==============================] - 2s 104ms/step - loss: 18.4666 - accuracy: 0.4131 - val_loss: 116.8530 - val_accuracy: 0.2667\n","Epoch 31/50\n","17/17 [==============================] - 2s 99ms/step - loss: 20.1943 - accuracy: 0.4280 - val_loss: 106.6790 - val_accuracy: 0.2167\n","Epoch 32/50\n","17/17 [==============================] - 2s 99ms/step - loss: 20.2508 - accuracy: 0.3944 - val_loss: 109.9010 - val_accuracy: 0.2833\n","Epoch 33/50\n","17/17 [==============================] - 2s 113ms/step - loss: 20.0439 - accuracy: 0.4056 - val_loss: 105.3964 - val_accuracy: 0.2333\n","Epoch 34/50\n","17/17 [==============================] - 3s 152ms/step - loss: 18.2738 - accuracy: 0.4075 - val_loss: 110.1911 - val_accuracy: 0.2833\n","Epoch 35/50\n","17/17 [==============================] - 2s 142ms/step - loss: 17.2244 - accuracy: 0.3850 - val_loss: 109.6783 - val_accuracy: 0.2000\n","Epoch 36/50\n","17/17 [==============================] - 2s 106ms/step - loss: 16.9281 - accuracy: 0.4150 - val_loss: 107.7154 - val_accuracy: 0.2333\n","Epoch 37/50\n","17/17 [==============================] - 2s 105ms/step - loss: 17.0287 - accuracy: 0.4037 - val_loss: 109.4705 - val_accuracy: 0.2167\n","Epoch 38/50\n","17/17 [==============================] - 2s 105ms/step - loss: 17.2853 - accuracy: 0.4187 - val_loss: 108.7063 - val_accuracy: 0.2833\n","Epoch 39/50\n","17/17 [==============================] - 2s 101ms/step - loss: 17.0278 - accuracy: 0.3981 - val_loss: 108.5889 - val_accuracy: 0.2500\n","Epoch 40/50\n","17/17 [==============================] - 2s 104ms/step - loss: 17.0566 - accuracy: 0.4075 - val_loss: 107.8053 - val_accuracy: 0.2667\n","Epoch 41/50\n","17/17 [==============================] - 2s 101ms/step - loss: 15.9388 - accuracy: 0.4280 - val_loss: 104.8391 - val_accuracy: 0.2500\n","Epoch 42/50\n","17/17 [==============================] - 3s 151ms/step - loss: 18.3941 - accuracy: 0.3981 - val_loss: 103.2899 - val_accuracy: 0.2667\n","Epoch 43/50\n","17/17 [==============================] - 3s 152ms/step - loss: 19.0460 - accuracy: 0.4206 - val_loss: 114.9437 - val_accuracy: 0.2333\n","Epoch 44/50\n","17/17 [==============================] - 2s 104ms/step - loss: 19.7569 - accuracy: 0.4056 - val_loss: 112.4022 - val_accuracy: 0.2667\n","Epoch 45/50\n","17/17 [==============================] - 2s 99ms/step - loss: 17.7573 - accuracy: 0.4411 - val_loss: 107.9314 - val_accuracy: 0.2500\n","Epoch 46/50\n","17/17 [==============================] - 2s 106ms/step - loss: 18.6765 - accuracy: 0.4056 - val_loss: 108.0821 - val_accuracy: 0.2667\n","Epoch 47/50\n","17/17 [==============================] - 2s 101ms/step - loss: 18.6670 - accuracy: 0.3963 - val_loss: 106.5124 - val_accuracy: 0.2333\n","Epoch 48/50\n","17/17 [==============================] - 2s 113ms/step - loss: 16.0850 - accuracy: 0.4280 - val_loss: 105.6338 - val_accuracy: 0.3000\n","Epoch 49/50\n","17/17 [==============================] - 2s 117ms/step - loss: 15.7737 - accuracy: 0.4056 - val_loss: 109.2675 - val_accuracy: 0.2667\n","Epoch 50/50\n","17/17 [==============================] - 2s 145ms/step - loss: 15.5117 - accuracy: 0.4093 - val_loss: 106.0086 - val_accuracy: 0.2500\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7893a1bf3250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["5/5 [==============================] - 0s 17ms/step\n","5/5 [==============================] - 0s 16ms/step - loss: 1.7859 - accuracy: 0.9333\n","Test Loss: 1.7859, Test accuracy : 0.9333\n","Epoch 1/50\n","17/17 [==============================] - 3s 128ms/step - loss: 231.4670 - accuracy: 0.3723 - val_loss: 248.7605 - val_accuracy: 0.4386\n","Epoch 2/50\n","17/17 [==============================] - 3s 155ms/step - loss: 195.6420 - accuracy: 0.3489 - val_loss: 273.4591 - val_accuracy: 0.5088\n","Epoch 3/50\n","17/17 [==============================] - 2s 138ms/step - loss: 145.0264 - accuracy: 0.4269 - val_loss: 256.2285 - val_accuracy: 0.2807\n","Epoch 4/50\n","17/17 [==============================] - 2s 106ms/step - loss: 107.0957 - accuracy: 0.5848 - val_loss: 252.5235 - val_accuracy: 0.4035\n","Epoch 5/50\n","17/17 [==============================] - 2s 103ms/step - loss: 90.7646 - accuracy: 0.6179 - val_loss: 255.7717 - val_accuracy: 0.1579\n","Epoch 6/50\n","17/17 [==============================] - 2s 104ms/step - loss: 78.0461 - accuracy: 0.6140 - val_loss: 248.9142 - val_accuracy: 0.5088\n","Epoch 7/50\n","17/17 [==============================] - 2s 95ms/step - loss: 67.4114 - accuracy: 0.6628 - val_loss: 249.6153 - val_accuracy: 0.5614\n","Epoch 8/50\n","17/17 [==============================] - 2s 102ms/step - loss: 64.0345 - accuracy: 0.6608 - val_loss: 259.8053 - val_accuracy: 0.1579\n","Epoch 9/50\n","17/17 [==============================] - 2s 112ms/step - loss: 68.6882 - accuracy: 0.5166 - val_loss: 256.4552 - val_accuracy: 0.5614\n","Epoch 10/50\n","17/17 [==============================] - 3s 163ms/step - loss: 59.3189 - accuracy: 0.6296 - val_loss: 252.5126 - val_accuracy: 0.4737\n","Epoch 11/50\n","17/17 [==============================] - 3s 154ms/step - loss: 51.6135 - accuracy: 0.6511 - val_loss: 253.1748 - val_accuracy: 0.5439\n","Epoch 12/50\n","17/17 [==============================] - 2s 103ms/step - loss: 49.0381 - accuracy: 0.6784 - val_loss: 253.9641 - val_accuracy: 0.4737\n","Epoch 13/50\n","17/17 [==============================] - 2s 103ms/step - loss: 48.2223 - accuracy: 0.7232 - val_loss: 254.4545 - val_accuracy: 0.5614\n","Epoch 14/50\n","17/17 [==============================] - 2s 104ms/step - loss: 49.6996 - accuracy: 0.7271 - val_loss: 253.2441 - val_accuracy: 0.4912\n","Epoch 15/50\n","17/17 [==============================] - 2s 106ms/step - loss: 55.9696 - accuracy: 0.7018 - val_loss: 249.1694 - val_accuracy: 0.5263\n","Epoch 16/50\n","17/17 [==============================] - 2s 104ms/step - loss: 56.2847 - accuracy: 0.6842 - val_loss: 256.3320 - val_accuracy: 0.5614\n","Epoch 17/50\n","17/17 [==============================] - 2s 122ms/step - loss: 47.3498 - accuracy: 0.7135 - val_loss: 250.6945 - val_accuracy: 0.5088\n","Epoch 18/50\n","17/17 [==============================] - 3s 155ms/step - loss: 41.4255 - accuracy: 0.7232 - val_loss: 254.2034 - val_accuracy: 0.5263\n","Epoch 19/50\n","17/17 [==============================] - 2s 137ms/step - loss: 40.0791 - accuracy: 0.7349 - val_loss: 253.7879 - val_accuracy: 0.5088\n","Epoch 20/50\n","17/17 [==============================] - 2s 101ms/step - loss: 36.8640 - accuracy: 0.7388 - val_loss: 254.0938 - val_accuracy: 0.4561\n","Epoch 21/50\n","17/17 [==============================] - 2s 103ms/step - loss: 31.5909 - accuracy: 0.7407 - val_loss: 255.0319 - val_accuracy: 0.5263\n","Epoch 22/50\n","17/17 [==============================] - 2s 98ms/step - loss: 28.0618 - accuracy: 0.7524 - val_loss: 254.0401 - val_accuracy: 0.4912\n","Epoch 23/50\n","17/17 [==============================] - 2s 95ms/step - loss: 28.4595 - accuracy: 0.7641 - val_loss: 259.8291 - val_accuracy: 0.4912\n","Epoch 24/50\n","17/17 [==============================] - 2s 102ms/step - loss: 28.3057 - accuracy: 0.7563 - val_loss: 253.9033 - val_accuracy: 0.4561\n","Epoch 25/50\n","17/17 [==============================] - 2s 108ms/step - loss: 25.3736 - accuracy: 0.7758 - val_loss: 255.8807 - val_accuracy: 0.4386\n","Epoch 26/50\n","17/17 [==============================] - 2s 145ms/step - loss: 25.1102 - accuracy: 0.7778 - val_loss: 257.4044 - val_accuracy: 0.4561\n","Epoch 27/50\n","17/17 [==============================] - 3s 156ms/step - loss: 24.9820 - accuracy: 0.7992 - val_loss: 252.8765 - val_accuracy: 0.4912\n","Epoch 28/50\n","17/17 [==============================] - 2s 104ms/step - loss: 24.9807 - accuracy: 0.7817 - val_loss: 259.9659 - val_accuracy: 0.5088\n","Epoch 29/50\n","17/17 [==============================] - 2s 105ms/step - loss: 26.1652 - accuracy: 0.7836 - val_loss: 255.4896 - val_accuracy: 0.4561\n","Epoch 30/50\n","17/17 [==============================] - 2s 102ms/step - loss: 32.0209 - accuracy: 0.7505 - val_loss: 252.9828 - val_accuracy: 0.5263\n","Epoch 31/50\n","17/17 [==============================] - 2s 106ms/step - loss: 33.9470 - accuracy: 0.7797 - val_loss: 263.7902 - val_accuracy: 0.4737\n","Epoch 32/50\n","17/17 [==============================] - 2s 97ms/step - loss: 29.4190 - accuracy: 0.7934 - val_loss: 251.0199 - val_accuracy: 0.4912\n","Epoch 33/50\n","17/17 [==============================] - 2s 122ms/step - loss: 25.5118 - accuracy: 0.7973 - val_loss: 260.4190 - val_accuracy: 0.4912\n","Epoch 34/50\n","17/17 [==============================] - 3s 156ms/step - loss: 22.2762 - accuracy: 0.8168 - val_loss: 250.2005 - val_accuracy: 0.4912\n","Epoch 35/50\n","17/17 [==============================] - 2s 147ms/step - loss: 20.1741 - accuracy: 0.8031 - val_loss: 261.9938 - val_accuracy: 0.4912\n","Epoch 36/50\n","17/17 [==============================] - 2s 103ms/step - loss: 19.4880 - accuracy: 0.8129 - val_loss: 242.5759 - val_accuracy: 0.4737\n","Epoch 37/50\n","17/17 [==============================] - 2s 102ms/step - loss: 18.8328 - accuracy: 0.8129 - val_loss: 261.6655 - val_accuracy: 0.4737\n","Epoch 38/50\n","17/17 [==============================] - 2s 100ms/step - loss: 19.6340 - accuracy: 0.8031 - val_loss: 242.1448 - val_accuracy: 0.4912\n","Epoch 39/50\n","17/17 [==============================] - 2s 104ms/step - loss: 22.3434 - accuracy: 0.8070 - val_loss: 259.5970 - val_accuracy: 0.4912\n","Epoch 40/50\n","17/17 [==============================] - 2s 107ms/step - loss: 20.8660 - accuracy: 0.8109 - val_loss: 249.2867 - val_accuracy: 0.4737\n","Epoch 41/50\n","17/17 [==============================] - 2s 119ms/step - loss: 19.4476 - accuracy: 0.8109 - val_loss: 259.8499 - val_accuracy: 0.4912\n","Epoch 42/50\n","17/17 [==============================] - 3s 157ms/step - loss: 19.0972 - accuracy: 0.8148 - val_loss: 258.5128 - val_accuracy: 0.4912\n","Epoch 43/50\n","17/17 [==============================] - 2s 133ms/step - loss: 20.4460 - accuracy: 0.8109 - val_loss: 259.2226 - val_accuracy: 0.4561\n","Epoch 44/50\n","17/17 [==============================] - 2s 104ms/step - loss: 19.4197 - accuracy: 0.7992 - val_loss: 258.1186 - val_accuracy: 0.4561\n","Epoch 45/50\n","17/17 [==============================] - 2s 93ms/step - loss: 16.7950 - accuracy: 0.8031 - val_loss: 257.8776 - val_accuracy: 0.5088\n","Epoch 46/50\n","17/17 [==============================] - 2s 103ms/step - loss: 16.1341 - accuracy: 0.8187 - val_loss: 258.5300 - val_accuracy: 0.4737\n","Epoch 47/50\n","17/17 [==============================] - 2s 108ms/step - loss: 20.1571 - accuracy: 0.8226 - val_loss: 261.3338 - val_accuracy: 0.4561\n","Epoch 48/50\n","17/17 [==============================] - 2s 101ms/step - loss: 16.6453 - accuracy: 0.8129 - val_loss: 254.0997 - val_accuracy: 0.4737\n","Epoch 49/50\n","17/17 [==============================] - 2s 142ms/step - loss: 16.0905 - accuracy: 0.8343 - val_loss: 258.0817 - val_accuracy: 0.4912\n","Epoch 50/50\n","17/17 [==============================] - 3s 150ms/step - loss: 16.3159 - accuracy: 0.8265 - val_loss: 252.4740 - val_accuracy: 0.4912\n","5/5 [==============================] - 0s 17ms/step\n","5/5 [==============================] - 0s 16ms/step - loss: 0.9408 - accuracy: 0.9172\n","Test Loss: 0.9408, Test accuracy : 0.9172\n","Epoch 1/50\n","26/26 [==============================] - 3s 105ms/step - loss: 170.2446 - accuracy: 0.1379 - val_loss: 241.7018 - val_accuracy: 0.1556\n","Epoch 2/50\n","26/26 [==============================] - 3s 99ms/step - loss: 128.6746 - accuracy: 0.1925 - val_loss: 230.0881 - val_accuracy: 0.0889\n","Epoch 3/50\n","26/26 [==============================] - 3s 124ms/step - loss: 105.4667 - accuracy: 0.2360 - val_loss: 224.4323 - val_accuracy: 0.0444\n","Epoch 4/50\n","26/26 [==============================] - 4s 143ms/step - loss: 101.0906 - accuracy: 0.2571 - val_loss: 214.0779 - val_accuracy: 0.0667\n","Epoch 5/50\n","26/26 [==============================] - 3s 99ms/step - loss: 94.4089 - accuracy: 0.2932 - val_loss: 214.3397 - val_accuracy: 0.0778\n","Epoch 6/50\n","26/26 [==============================] - 3s 107ms/step - loss: 82.5261 - accuracy: 0.2907 - val_loss: 214.5555 - val_accuracy: 0.1444\n","Epoch 7/50\n","26/26 [==============================] - 3s 109ms/step - loss: 73.6517 - accuracy: 0.3143 - val_loss: 210.7048 - val_accuracy: 0.1000\n","Epoch 8/50\n","26/26 [==============================] - 4s 151ms/step - loss: 69.2740 - accuracy: 0.3739 - val_loss: 210.0361 - val_accuracy: 0.1333\n","Epoch 9/50\n","26/26 [==============================] - 4s 142ms/step - loss: 59.5854 - accuracy: 0.3963 - val_loss: 209.0866 - val_accuracy: 0.1889\n","Epoch 10/50\n","26/26 [==============================] - 3s 107ms/step - loss: 52.2335 - accuracy: 0.4236 - val_loss: 206.0258 - val_accuracy: 0.1444\n","Epoch 11/50\n","26/26 [==============================] - 3s 98ms/step - loss: 51.4806 - accuracy: 0.4472 - val_loss: 216.1519 - val_accuracy: 0.1778\n","Epoch 12/50\n","26/26 [==============================] - 2s 96ms/step - loss: 44.7204 - accuracy: 0.4348 - val_loss: 211.6694 - val_accuracy: 0.0889\n","Epoch 13/50\n","26/26 [==============================] - 2s 95ms/step - loss: 37.3597 - accuracy: 0.4050 - val_loss: 212.7016 - val_accuracy: 0.1000\n","Epoch 14/50\n","26/26 [==============================] - 3s 127ms/step - loss: 34.5680 - accuracy: 0.4199 - val_loss: 212.1012 - val_accuracy: 0.2000\n","Epoch 15/50\n","26/26 [==============================] - 3s 131ms/step - loss: 32.2107 - accuracy: 0.4298 - val_loss: 212.2632 - val_accuracy: 0.1000\n","Epoch 16/50\n","26/26 [==============================] - 2s 93ms/step - loss: 29.3112 - accuracy: 0.4584 - val_loss: 210.4136 - val_accuracy: 0.1667\n","Epoch 17/50\n","26/26 [==============================] - 2s 95ms/step - loss: 28.0651 - accuracy: 0.4571 - val_loss: 209.5582 - val_accuracy: 0.1000\n","Epoch 18/50\n","26/26 [==============================] - 3s 100ms/step - loss: 27.5718 - accuracy: 0.4373 - val_loss: 207.9787 - val_accuracy: 0.1000\n","Epoch 19/50\n","26/26 [==============================] - 3s 112ms/step - loss: 27.5993 - accuracy: 0.4509 - val_loss: 207.5945 - val_accuracy: 0.0889\n","Epoch 20/50\n","26/26 [==============================] - 4s 146ms/step - loss: 27.0628 - accuracy: 0.4770 - val_loss: 207.7301 - val_accuracy: 0.0889\n","Epoch 21/50\n","26/26 [==============================] - 3s 104ms/step - loss: 25.9992 - accuracy: 0.4919 - val_loss: 208.3360 - val_accuracy: 0.1333\n","Epoch 22/50\n","26/26 [==============================] - 3s 103ms/step - loss: 25.6863 - accuracy: 0.4932 - val_loss: 208.4466 - val_accuracy: 0.1444\n","Epoch 23/50\n","26/26 [==============================] - 3s 101ms/step - loss: 27.2876 - accuracy: 0.4733 - val_loss: 209.2912 - val_accuracy: 0.1222\n","Epoch 24/50\n","26/26 [==============================] - 3s 108ms/step - loss: 28.4315 - accuracy: 0.4621 - val_loss: 210.0820 - val_accuracy: 0.1444\n","Epoch 25/50\n","26/26 [==============================] - 4s 146ms/step - loss: 34.0162 - accuracy: 0.4671 - val_loss: 211.0622 - val_accuracy: 0.1111\n","Epoch 26/50\n","26/26 [==============================] - 3s 129ms/step - loss: 40.4980 - accuracy: 0.4522 - val_loss: 214.5219 - val_accuracy: 0.1333\n","Epoch 27/50\n","26/26 [==============================] - 3s 106ms/step - loss: 34.1900 - accuracy: 0.4683 - val_loss: 213.9769 - val_accuracy: 0.0778\n","Epoch 28/50\n","26/26 [==============================] - 3s 99ms/step - loss: 28.4742 - accuracy: 0.4261 - val_loss: 216.0029 - val_accuracy: 0.1889\n","Epoch 29/50\n","26/26 [==============================] - 3s 99ms/step - loss: 25.7778 - accuracy: 0.4335 - val_loss: 211.9990 - val_accuracy: 0.1556\n","Epoch 30/50\n","26/26 [==============================] - 4s 139ms/step - loss: 23.9739 - accuracy: 0.4360 - val_loss: 214.3185 - val_accuracy: 0.1556\n","Epoch 31/50\n","26/26 [==============================] - 3s 133ms/step - loss: 23.8896 - accuracy: 0.4472 - val_loss: 218.1926 - val_accuracy: 0.1667\n","Epoch 32/50\n","26/26 [==============================] - 3s 101ms/step - loss: 25.3435 - accuracy: 0.4025 - val_loss: 217.5747 - val_accuracy: 0.1778\n","Epoch 33/50\n","26/26 [==============================] - 3s 99ms/step - loss: 27.2478 - accuracy: 0.3938 - val_loss: 216.3160 - val_accuracy: 0.1000\n","Epoch 34/50\n","26/26 [==============================] - 3s 99ms/step - loss: 25.8079 - accuracy: 0.3863 - val_loss: 216.7296 - val_accuracy: 0.1556\n","Epoch 35/50\n","26/26 [==============================] - 3s 113ms/step - loss: 26.3984 - accuracy: 0.3901 - val_loss: 210.2818 - val_accuracy: 0.1444\n","Epoch 36/50\n","26/26 [==============================] - 4s 140ms/step - loss: 21.3829 - accuracy: 0.3590 - val_loss: 215.3011 - val_accuracy: 0.1222\n","Epoch 37/50\n","26/26 [==============================] - 3s 105ms/step - loss: 22.7977 - accuracy: 0.3516 - val_loss: 213.8592 - val_accuracy: 0.1333\n","Epoch 38/50\n","26/26 [==============================] - 3s 103ms/step - loss: 22.6792 - accuracy: 0.2870 - val_loss: 217.2544 - val_accuracy: 0.0667\n","Epoch 39/50\n","26/26 [==============================] - 3s 97ms/step - loss: 20.5661 - accuracy: 0.3255 - val_loss: 215.0221 - val_accuracy: 0.1333\n","Epoch 40/50\n","26/26 [==============================] - 3s 100ms/step - loss: 17.1220 - accuracy: 0.3130 - val_loss: 212.5581 - val_accuracy: 0.1333\n","Epoch 41/50\n","26/26 [==============================] - 4s 144ms/step - loss: 15.2385 - accuracy: 0.2646 - val_loss: 212.2732 - val_accuracy: 0.1111\n","Epoch 42/50\n","26/26 [==============================] - 3s 119ms/step - loss: 14.7903 - accuracy: 0.2981 - val_loss: 211.9456 - val_accuracy: 0.1111\n","Epoch 43/50\n","26/26 [==============================] - 3s 99ms/step - loss: 13.4241 - accuracy: 0.2658 - val_loss: 212.5909 - val_accuracy: 0.1444\n","Epoch 44/50\n","26/26 [==============================] - 3s 100ms/step - loss: 12.7432 - accuracy: 0.2621 - val_loss: 213.2553 - val_accuracy: 0.1222\n","Epoch 45/50\n","26/26 [==============================] - 3s 100ms/step - loss: 12.2265 - accuracy: 0.2460 - val_loss: 211.6776 - val_accuracy: 0.1222\n","Epoch 46/50\n","26/26 [==============================] - 4s 136ms/step - loss: 12.0080 - accuracy: 0.2596 - val_loss: 212.8451 - val_accuracy: 0.1333\n","Epoch 47/50\n","26/26 [==============================] - 4s 146ms/step - loss: 11.8101 - accuracy: 0.2472 - val_loss: 213.3013 - val_accuracy: 0.1444\n","Epoch 48/50\n","26/26 [==============================] - 3s 104ms/step - loss: 25.1534 - accuracy: 0.2534 - val_loss: 210.6992 - val_accuracy: 0.1111\n","Epoch 49/50\n","26/26 [==============================] - 3s 100ms/step - loss: 11.9666 - accuracy: 0.2398 - val_loss: 213.7885 - val_accuracy: 0.1778\n","Epoch 50/50\n","26/26 [==============================] - 3s 103ms/step - loss: 11.5507 - accuracy: 0.2422 - val_loss: 212.6769 - val_accuracy: 0.1000\n","8/8 [==============================] - 0s 30ms/step\n","8/8 [==============================] - 0s 41ms/step - loss: 70.6740 - accuracy: 0.9244\n","Test Loss: 70.6740, Test accuracy : 0.9244\n","Epoch 1/50\n","11/11 [==============================] - 2s 130ms/step - loss: 244.0027 - accuracy: 0.2368 - val_loss: 127.2566 - val_accuracy: 0.4211\n","Epoch 2/50\n","11/11 [==============================] - 1s 105ms/step - loss: 142.5369 - accuracy: 0.2836 - val_loss: 128.2807 - val_accuracy: 0.3947\n","Epoch 3/50\n","11/11 [==============================] - 1s 112ms/step - loss: 113.0960 - accuracy: 0.3626 - val_loss: 157.0582 - val_accuracy: 0.3421\n","Epoch 4/50\n","11/11 [==============================] - 1s 104ms/step - loss: 96.2822 - accuracy: 0.3801 - val_loss: 147.6171 - val_accuracy: 0.3421\n","Epoch 5/50\n","11/11 [==============================] - 1s 104ms/step - loss: 84.0977 - accuracy: 0.4123 - val_loss: 161.2755 - val_accuracy: 0.3421\n","Epoch 6/50\n","11/11 [==============================] - 1s 99ms/step - loss: 73.5484 - accuracy: 0.4444 - val_loss: 129.0907 - val_accuracy: 0.3684\n","Epoch 7/50\n","11/11 [==============================] - 1s 125ms/step - loss: 65.1227 - accuracy: 0.4708 - val_loss: 137.2439 - val_accuracy: 0.3421\n","Epoch 8/50\n","11/11 [==============================] - 1s 136ms/step - loss: 58.7103 - accuracy: 0.4269 - val_loss: 125.3159 - val_accuracy: 0.3947\n","Epoch 9/50\n","11/11 [==============================] - 2s 149ms/step - loss: 52.9702 - accuracy: 0.4708 - val_loss: 128.8527 - val_accuracy: 0.3947\n","Epoch 10/50\n","11/11 [==============================] - 1s 136ms/step - loss: 49.1349 - accuracy: 0.4971 - val_loss: 128.0712 - val_accuracy: 0.3947\n","Epoch 11/50\n","11/11 [==============================] - 1s 102ms/step - loss: 45.2602 - accuracy: 0.4298 - val_loss: 131.9312 - val_accuracy: 0.4211\n","Epoch 12/50\n","11/11 [==============================] - 1s 98ms/step - loss: 43.6741 - accuracy: 0.5263 - val_loss: 125.0529 - val_accuracy: 0.4211\n","Epoch 13/50\n","11/11 [==============================] - 1s 101ms/step - loss: 40.6287 - accuracy: 0.5175 - val_loss: 133.8328 - val_accuracy: 0.4211\n","Epoch 14/50\n","11/11 [==============================] - 1s 100ms/step - loss: 39.0678 - accuracy: 0.4591 - val_loss: 120.6430 - val_accuracy: 0.3684\n","Epoch 15/50\n","11/11 [==============================] - 1s 96ms/step - loss: 36.3777 - accuracy: 0.4795 - val_loss: 129.6519 - val_accuracy: 0.3947\n","Epoch 16/50\n","11/11 [==============================] - 1s 98ms/step - loss: 35.2646 - accuracy: 0.5263 - val_loss: 127.7721 - val_accuracy: 0.3947\n","Epoch 17/50\n","11/11 [==============================] - 1s 105ms/step - loss: 31.9934 - accuracy: 0.5058 - val_loss: 126.4076 - val_accuracy: 0.3684\n","Epoch 18/50\n","11/11 [==============================] - 1s 103ms/step - loss: 29.5392 - accuracy: 0.4971 - val_loss: 129.6653 - val_accuracy: 0.3947\n","Epoch 19/50\n","11/11 [==============================] - 1s 108ms/step - loss: 27.9209 - accuracy: 0.5088 - val_loss: 127.6114 - val_accuracy: 0.3947\n","Epoch 20/50\n","11/11 [==============================] - 2s 146ms/step - loss: 26.1549 - accuracy: 0.5351 - val_loss: 126.6145 - val_accuracy: 0.3421\n","Epoch 21/50\n","11/11 [==============================] - 2s 150ms/step - loss: 24.4204 - accuracy: 0.5146 - val_loss: 129.1926 - val_accuracy: 0.3947\n","Epoch 22/50\n","11/11 [==============================] - 2s 142ms/step - loss: 23.3346 - accuracy: 0.5906 - val_loss: 126.2896 - val_accuracy: 0.3684\n","Epoch 23/50\n","11/11 [==============================] - 1s 104ms/step - loss: 22.5139 - accuracy: 0.5994 - val_loss: 132.3185 - val_accuracy: 0.3947\n","Epoch 24/50\n","11/11 [==============================] - 1s 95ms/step - loss: 21.0445 - accuracy: 0.5994 - val_loss: 126.6704 - val_accuracy: 0.3947\n","Epoch 25/50\n","11/11 [==============================] - 1s 99ms/step - loss: 20.2188 - accuracy: 0.5936 - val_loss: 127.6758 - val_accuracy: 0.3684\n","Epoch 26/50\n","11/11 [==============================] - 1s 105ms/step - loss: 19.4035 - accuracy: 0.5702 - val_loss: 129.1066 - val_accuracy: 0.3947\n","Epoch 27/50\n","11/11 [==============================] - 1s 100ms/step - loss: 18.1722 - accuracy: 0.6023 - val_loss: 127.9456 - val_accuracy: 0.3684\n","Epoch 28/50\n","11/11 [==============================] - 1s 101ms/step - loss: 17.6699 - accuracy: 0.6667 - val_loss: 130.3449 - val_accuracy: 0.4211\n","Epoch 29/50\n","11/11 [==============================] - 1s 98ms/step - loss: 17.0400 - accuracy: 0.5936 - val_loss: 126.7137 - val_accuracy: 0.3947\n","Epoch 30/50\n","11/11 [==============================] - 1s 99ms/step - loss: 17.2267 - accuracy: 0.6287 - val_loss: 130.8175 - val_accuracy: 0.3947\n","Epoch 31/50\n","11/11 [==============================] - 1s 104ms/step - loss: 17.7838 - accuracy: 0.6170 - val_loss: 130.3837 - val_accuracy: 0.3421\n","Epoch 32/50\n","11/11 [==============================] - 1s 137ms/step - loss: 16.8395 - accuracy: 0.6784 - val_loss: 132.6956 - val_accuracy: 0.3421\n","Epoch 33/50\n","11/11 [==============================] - 2s 140ms/step - loss: 16.4979 - accuracy: 0.6754 - val_loss: 132.3127 - val_accuracy: 0.3684\n","Epoch 34/50\n","11/11 [==============================] - 2s 138ms/step - loss: 16.6748 - accuracy: 0.6637 - val_loss: 133.1265 - val_accuracy: 0.3684\n","Epoch 35/50\n","11/11 [==============================] - 1s 132ms/step - loss: 16.8795 - accuracy: 0.7076 - val_loss: 130.9006 - val_accuracy: 0.3421\n","Epoch 36/50\n","11/11 [==============================] - 1s 117ms/step - loss: 17.1987 - accuracy: 0.6316 - val_loss: 142.7575 - val_accuracy: 0.3947\n","Epoch 37/50\n","11/11 [==============================] - 1s 101ms/step - loss: 16.1274 - accuracy: 0.6608 - val_loss: 140.8192 - val_accuracy: 0.3947\n","Epoch 38/50\n","11/11 [==============================] - 1s 103ms/step - loss: 16.7007 - accuracy: 0.6374 - val_loss: 130.7572 - val_accuracy: 0.3947\n","Epoch 39/50\n","11/11 [==============================] - 1s 99ms/step - loss: 19.2260 - accuracy: 0.7193 - val_loss: 134.4937 - val_accuracy: 0.3158\n","Epoch 40/50\n","11/11 [==============================] - 1s 103ms/step - loss: 16.1213 - accuracy: 0.6433 - val_loss: 134.4432 - val_accuracy: 0.3421\n","Epoch 41/50\n","11/11 [==============================] - 1s 104ms/step - loss: 16.6749 - accuracy: 0.6345 - val_loss: 151.4808 - val_accuracy: 0.3947\n","Epoch 42/50\n","11/11 [==============================] - 1s 105ms/step - loss: 18.2481 - accuracy: 0.6637 - val_loss: 132.8470 - val_accuracy: 0.3684\n","Epoch 43/50\n","11/11 [==============================] - 1s 100ms/step - loss: 16.0443 - accuracy: 0.6491 - val_loss: 134.5229 - val_accuracy: 0.3421\n","Epoch 44/50\n","11/11 [==============================] - 1s 100ms/step - loss: 15.4345 - accuracy: 0.6784 - val_loss: 140.4372 - val_accuracy: 0.3684\n","Epoch 45/50\n","11/11 [==============================] - 1s 129ms/step - loss: 14.9820 - accuracy: 0.6901 - val_loss: 141.6355 - val_accuracy: 0.3947\n","Epoch 46/50\n","11/11 [==============================] - 1s 138ms/step - loss: 14.7901 - accuracy: 0.7222 - val_loss: 135.7558 - val_accuracy: 0.3684\n","Epoch 47/50\n","11/11 [==============================] - 2s 141ms/step - loss: 14.9544 - accuracy: 0.6667 - val_loss: 137.6924 - val_accuracy: 0.3684\n","Epoch 48/50\n","11/11 [==============================] - 2s 153ms/step - loss: 14.2570 - accuracy: 0.6988 - val_loss: 133.9026 - val_accuracy: 0.3947\n","Epoch 49/50\n","11/11 [==============================] - 1s 103ms/step - loss: 13.6117 - accuracy: 0.6462 - val_loss: 133.8938 - val_accuracy: 0.3684\n","Epoch 50/50\n","11/11 [==============================] - 1s 98ms/step - loss: 13.3091 - accuracy: 0.6813 - val_loss: 131.3306 - val_accuracy: 0.3684\n","4/4 [==============================] - 0s 14ms/step\n","4/4 [==============================] - 0s 15ms/step - loss: 6029.3921 - accuracy: 0.9800\n","Test Loss: 6029.3921, Test accuracy : 0.9800\n","Epoch 1/50\n","8/8 [==============================] - 1s 121ms/step - loss: 228.8585 - accuracy: 0.3761 - val_loss: 176.6988 - val_accuracy: 0.1923\n","Epoch 2/50\n","8/8 [==============================] - 1s 145ms/step - loss: 118.5930 - accuracy: 0.4274 - val_loss: 119.6530 - val_accuracy: 0.8077\n","Epoch 3/50\n","8/8 [==============================] - 1s 136ms/step - loss: 74.5787 - accuracy: 0.3889 - val_loss: 91.1880 - val_accuracy: 0.6154\n","Epoch 4/50\n","8/8 [==============================] - 1s 138ms/step - loss: 44.1435 - accuracy: 0.5812 - val_loss: 86.5048 - val_accuracy: 0.6538\n","Epoch 5/50\n","8/8 [==============================] - 1s 128ms/step - loss: 36.0017 - accuracy: 0.3932 - val_loss: 100.3044 - val_accuracy: 0.6538\n","Epoch 6/50\n","8/8 [==============================] - 1s 145ms/step - loss: 27.3790 - accuracy: 0.5299 - val_loss: 87.7650 - val_accuracy: 0.6538\n","Epoch 7/50\n","8/8 [==============================] - 1s 98ms/step - loss: 21.9507 - accuracy: 0.4829 - val_loss: 86.6935 - val_accuracy: 0.6154\n","Epoch 8/50\n","8/8 [==============================] - 1s 100ms/step - loss: 18.1546 - accuracy: 0.4915 - val_loss: 90.4874 - val_accuracy: 0.6538\n","Epoch 9/50\n","8/8 [==============================] - 1s 97ms/step - loss: 15.2885 - accuracy: 0.4530 - val_loss: 95.6388 - val_accuracy: 0.7308\n","Epoch 10/50\n","8/8 [==============================] - 1s 99ms/step - loss: 13.8305 - accuracy: 0.5385 - val_loss: 91.8101 - val_accuracy: 0.6154\n","Epoch 11/50\n","8/8 [==============================] - 1s 98ms/step - loss: 11.7676 - accuracy: 0.5470 - val_loss: 93.4417 - val_accuracy: 0.6538\n","Epoch 12/50\n","8/8 [==============================] - 1s 95ms/step - loss: 11.6237 - accuracy: 0.4872 - val_loss: 97.5022 - val_accuracy: 0.7308\n","Epoch 13/50\n","8/8 [==============================] - 1s 94ms/step - loss: 11.9837 - accuracy: 0.5470 - val_loss: 93.0411 - val_accuracy: 0.6154\n","Epoch 14/50\n","8/8 [==============================] - 1s 92ms/step - loss: 9.4149 - accuracy: 0.5385 - val_loss: 92.8341 - val_accuracy: 0.6538\n","Epoch 15/50\n","8/8 [==============================] - 1s 94ms/step - loss: 8.1225 - accuracy: 0.5342 - val_loss: 93.2820 - val_accuracy: 0.6923\n","Epoch 16/50\n","8/8 [==============================] - 1s 97ms/step - loss: 7.0822 - accuracy: 0.5641 - val_loss: 97.0896 - val_accuracy: 0.6154\n","Epoch 17/50\n","8/8 [==============================] - 1s 94ms/step - loss: 6.2210 - accuracy: 0.5085 - val_loss: 93.6174 - val_accuracy: 0.6923\n","Epoch 18/50\n","8/8 [==============================] - 1s 91ms/step - loss: 7.6562 - accuracy: 0.5897 - val_loss: 95.5732 - val_accuracy: 0.6538\n","Epoch 19/50\n","8/8 [==============================] - 1s 95ms/step - loss: 5.1859 - accuracy: 0.6282 - val_loss: 95.7210 - val_accuracy: 0.6538\n","Epoch 20/50\n","8/8 [==============================] - 1s 129ms/step - loss: 4.8767 - accuracy: 0.5983 - val_loss: 94.0312 - val_accuracy: 0.6538\n","Epoch 21/50\n","8/8 [==============================] - 1s 136ms/step - loss: 4.5405 - accuracy: 0.6538 - val_loss: 93.9165 - val_accuracy: 0.6538\n","Epoch 22/50\n","8/8 [==============================] - 1s 123ms/step - loss: 4.3564 - accuracy: 0.6966 - val_loss: 93.4652 - val_accuracy: 0.6538\n","Epoch 23/50\n","8/8 [==============================] - 1s 132ms/step - loss: 6.0808 - accuracy: 0.5470 - val_loss: 92.7101 - val_accuracy: 0.5385\n","Epoch 24/50\n","8/8 [==============================] - 1s 134ms/step - loss: 7.0925 - accuracy: 0.5427 - val_loss: 94.8766 - val_accuracy: 0.6538\n","Epoch 25/50\n","8/8 [==============================] - 1s 118ms/step - loss: 5.5248 - accuracy: 0.6538 - val_loss: 94.3193 - val_accuracy: 0.6154\n","Epoch 26/50\n","8/8 [==============================] - 1s 96ms/step - loss: 4.9418 - accuracy: 0.6581 - val_loss: 99.0258 - val_accuracy: 0.6538\n","Epoch 27/50\n","8/8 [==============================] - 1s 99ms/step - loss: 4.5750 - accuracy: 0.7479 - val_loss: 92.5130 - val_accuracy: 0.4615\n","Epoch 28/50\n","8/8 [==============================] - 1s 99ms/step - loss: 4.7065 - accuracy: 0.5214 - val_loss: 94.1203 - val_accuracy: 0.6538\n","Epoch 29/50\n","8/8 [==============================] - 1s 108ms/step - loss: 4.6772 - accuracy: 0.6325 - val_loss: 94.6147 - val_accuracy: 0.5385\n","Epoch 30/50\n","8/8 [==============================] - 1s 105ms/step - loss: 7.7079 - accuracy: 0.7094 - val_loss: 130.2683 - val_accuracy: 0.1923\n","Epoch 31/50\n","8/8 [==============================] - 1s 101ms/step - loss: 8.1214 - accuracy: 0.6368 - val_loss: 100.3686 - val_accuracy: 0.5000\n","Epoch 32/50\n","8/8 [==============================] - 1s 95ms/step - loss: 22.9296 - accuracy: 0.5983 - val_loss: 108.2997 - val_accuracy: 0.2308\n","Epoch 33/50\n","8/8 [==============================] - 1s 99ms/step - loss: 9.2875 - accuracy: 0.6026 - val_loss: 99.2208 - val_accuracy: 0.3462\n","Epoch 34/50\n","8/8 [==============================] - 1s 99ms/step - loss: 11.3387 - accuracy: 0.6923 - val_loss: 114.9635 - val_accuracy: 0.1154\n","Epoch 35/50\n","8/8 [==============================] - 1s 100ms/step - loss: 9.7286 - accuracy: 0.7009 - val_loss: 105.1965 - val_accuracy: 0.4615\n","Epoch 36/50\n","8/8 [==============================] - 1s 104ms/step - loss: 8.2463 - accuracy: 0.5983 - val_loss: 119.4958 - val_accuracy: 0.2692\n","Epoch 37/50\n","8/8 [==============================] - 1s 103ms/step - loss: 8.8563 - accuracy: 0.6838 - val_loss: 106.3096 - val_accuracy: 0.3462\n","Epoch 38/50\n","8/8 [==============================] - 1s 149ms/step - loss: 7.8230 - accuracy: 0.6368 - val_loss: 114.3258 - val_accuracy: 0.2308\n","Epoch 39/50\n","8/8 [==============================] - 1s 132ms/step - loss: 6.9853 - accuracy: 0.7350 - val_loss: 108.9887 - val_accuracy: 0.4615\n","Epoch 40/50\n","8/8 [==============================] - 1s 162ms/step - loss: 6.7957 - accuracy: 0.5983 - val_loss: 112.8390 - val_accuracy: 0.2308\n","Epoch 41/50\n","8/8 [==============================] - 1s 153ms/step - loss: 7.5804 - accuracy: 0.5556 - val_loss: 109.0022 - val_accuracy: 0.3846\n","Epoch 42/50\n","8/8 [==============================] - 1s 127ms/step - loss: 7.3847 - accuracy: 0.6325 - val_loss: 105.8161 - val_accuracy: 0.2692\n","Epoch 43/50\n","8/8 [==============================] - 1s 93ms/step - loss: 6.7303 - accuracy: 0.5684 - val_loss: 113.0556 - val_accuracy: 0.3846\n","Epoch 44/50\n","8/8 [==============================] - 1s 100ms/step - loss: 6.6468 - accuracy: 0.6368 - val_loss: 114.5346 - val_accuracy: 0.1538\n","Epoch 45/50\n","8/8 [==============================] - 1s 104ms/step - loss: 7.9841 - accuracy: 0.6880 - val_loss: 103.4797 - val_accuracy: 0.4231\n","Epoch 46/50\n","8/8 [==============================] - 1s 99ms/step - loss: 6.8912 - accuracy: 0.5684 - val_loss: 115.0771 - val_accuracy: 0.2308\n","Epoch 47/50\n","8/8 [==============================] - 1s 111ms/step - loss: 5.9174 - accuracy: 0.6325 - val_loss: 106.6765 - val_accuracy: 0.2692\n","Epoch 48/50\n","8/8 [==============================] - 1s 102ms/step - loss: 4.4568 - accuracy: 0.6154 - val_loss: 114.8753 - val_accuracy: 0.2308\n","Epoch 49/50\n","8/8 [==============================] - 1s 105ms/step - loss: 3.7580 - accuracy: 0.7778 - val_loss: 102.0507 - val_accuracy: 0.2692\n","Epoch 50/50\n","8/8 [==============================] - 1s 98ms/step - loss: 3.8537 - accuracy: 0.7350 - val_loss: 126.2714 - val_accuracy: 0.3077\n","3/3 [==============================] - 0s 14ms/step\n","3/3 [==============================] - 0s 18ms/step - loss: 5.9837 - accuracy: 0.9286\n","Test Loss: 5.9837, Test accuracy : 0.9286\n"]}]},{"cell_type":"code","source":["def print_model_summary(loaded_model, tajweed_rule):\n","  print(f'******* Tajweed rule {tajweed_rule} model *******')\n","  loaded_model.summary()\n","  print('\\n')"],"metadata":{"id":"i4FV1w-iDDFU","executionInfo":{"status":"ok","timestamp":1717525954106,"user_tz":-60,"elapsed":31,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["for rule in max_Y.keys():\n","    model_filename = f'{rule}_tajweed_rule_model'\n","    model_path = os.path.join(export_dir, model_filename)\n","\n","    # Load the saved model\n","    loaded_model = tf.keras.models.load_model(model_path)\n","\n","    print_model_summary(loaded_model, rule)"],"metadata":{"id":"WbRKnuWnLZTc","executionInfo":{"status":"ok","timestamp":1717525961759,"user_tz":-60,"elapsed":7662,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd3693ad-856d-4e11-ac72-6b23328ff677"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["******* Tajweed rule madd_6_Lazim model *******\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten (Flatten)           (None, 104000)            0         \n","                                                                 \n"," dense (Dense)               (None, 64)                6656064   \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 6656194 (25.39 MB)\n","Trainable params: 6656194 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_246 model *******\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                6656064   \n","                                                                 \n"," dense_3 (Dense)             (None, 3)                 195       \n","                                                                 \n","=================================================================\n","Total params: 6656259 (25.39 MB)\n","Trainable params: 6656259 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_6 model *******\n","Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_2 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                6656064   \n","                                                                 \n"," dense_5 (Dense)             (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 6656454 (25.39 MB)\n","Trainable params: 6656454 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_2 model *******\n","Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_3 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                6656064   \n","                                                                 \n"," dense_7 (Dense)             (None, 5)                 325       \n","                                                                 \n","=================================================================\n","Total params: 6656389 (25.39 MB)\n","Trainable params: 6656389 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Ikhfaa model *******\n","Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_4 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_8 (Dense)             (None, 64)                6656064   \n","                                                                 \n"," dense_9 (Dense)             (None, 9)                 585       \n","                                                                 \n","=================================================================\n","Total params: 6656649 (25.39 MB)\n","Trainable params: 6656649 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Idgham model *******\n","Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_5 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_10 (Dense)            (None, 64)                6656064   \n","                                                                 \n"," dense_11 (Dense)            (None, 13)                845       \n","                                                                 \n","=================================================================\n","Total params: 6656909 (25.39 MB)\n","Trainable params: 6656909 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule tafkhim model *******\n","Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_6 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_12 (Dense)            (None, 64)                6656064   \n","                                                                 \n"," dense_13 (Dense)            (None, 24)                1560      \n","                                                                 \n","=================================================================\n","Total params: 6657624 (25.40 MB)\n","Trainable params: 6657624 (25.40 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule qalqala model *******\n","Model: \"model_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_7 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_14 (Dense)            (None, 64)                6656064   \n","                                                                 \n"," dense_15 (Dense)            (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 6656454 (25.39 MB)\n","Trainable params: 6656454 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule imala model *******\n","Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_9 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_8 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_16 (Dense)            (None, 64)                6656064   \n","                                                                 \n"," dense_17 (Dense)            (None, 7)                 455       \n","                                                                 \n","=================================================================\n","Total params: 6656519 (25.39 MB)\n","Trainable params: 6656519 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n"]}]},{"cell_type":"code","source":["# how data is splitted\n","columns1 = ['tajweed_rule', 'data_of', 'X_train_nb_samples', 'X_test_nb_samples', 'Y_train_nb_samples', 'X_test_nb_samples']\n","splitted_data_info = pd.DataFrame(data=splitted_data_info_np, columns=columns1)\n","\n","# save models information\n","columns2 = ['Model', 'Loss', 'Accuracy', 'Accuracy %', 'Path_to_the_model']\n","models_information = pd.DataFrame(data=models_information_np, columns=columns2)"],"metadata":{"id":"txrZx0e_4Zmw","executionInfo":{"status":"ok","timestamp":1717525961760,"user_tz":-60,"elapsed":60,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["splitted_data_info"],"metadata":{"id":"8D4mYXj0Rcqb","executionInfo":{"status":"ok","timestamp":1717525961761,"user_tz":-60,"elapsed":59,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ef99da6a-3a3f-4a33-e339-95d4826eee47"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    tajweed_rule            data_of X_train_nb_samples X_test_nb_samples  \\\n","0   madd_6_Lazim        Abdul Basit                  1                 1   \n","1   madd_6_Lazim  Yassin Al Jazaery                  1                 1   \n","2   madd_6_Lazim   Ibrahim_Aldosary                  1                 1   \n","3   madd_6_Lazim          Al husary                  1                 1   \n","4   madd_6_Lazim               safa                  1                 1   \n","5   madd_6_Lazim       all reciters                  5                 5   \n","6       madd_246        Abdul Basit                 62                16   \n","7       madd_246  Yassin Al Jazaery                 62                16   \n","8       madd_246   Ibrahim_Aldosary                 62                16   \n","9       madd_246          Al husary                 62                16   \n","10      madd_246               safa                 62                16   \n","11      madd_246       all reciters                310                80   \n","12        madd_6        Abdul Basit                 47                12   \n","13        madd_6  Yassin Al Jazaery                 47                12   \n","14        madd_6   Ibrahim_Aldosary                 47                12   \n","15        madd_6          Al husary                 47                12   \n","16        madd_6               safa                 47                12   \n","17        madd_6       all reciters                235                60   \n","18        madd_2        Abdul Basit                 79                20   \n","19        madd_2  Yassin Al Jazaery                 79                20   \n","20        madd_2   Ibrahim_Aldosary                 79                20   \n","21        madd_2          Al husary                 79                20   \n","22        madd_2               safa                 79                20   \n","23        madd_2       all reciters                395               100   \n","24        Ikhfaa        Abdul Basit                119                30   \n","25        Ikhfaa  Yassin Al Jazaery                119                30   \n","26        Ikhfaa   Ibrahim_Aldosary                119                30   \n","27        Ikhfaa          Al husary                119                30   \n","28        Ikhfaa               safa                119                30   \n","29        Ikhfaa       all reciters                595               150   \n","30        Idgham        Abdul Basit                114                29   \n","31        Idgham  Yassin Al Jazaery                114                29   \n","32        Idgham   Ibrahim_Aldosary                114                29   \n","33        Idgham          Al husary                114                29   \n","34        Idgham               safa                114                29   \n","35        Idgham       all reciters                570               145   \n","36       tafkhim        Abdul Basit                179                45   \n","37       tafkhim  Yassin Al Jazaery                179                45   \n","38       tafkhim   Ibrahim_Aldosary                179                45   \n","39       tafkhim          Al husary                179                45   \n","40       tafkhim               safa                179                45   \n","41       tafkhim       all reciters                895               225   \n","42       qalqala        Abdul Basit                 76                20   \n","43       qalqala  Yassin Al Jazaery                 76                20   \n","44       qalqala   Ibrahim_Aldosary                 76                20   \n","45       qalqala          Al husary                 76                20   \n","46       qalqala               safa                 76                20   \n","47       qalqala       all reciters                380               100   \n","48         imala        Abdul Basit                 52                14   \n","49         imala  Yassin Al Jazaery                 52                14   \n","50         imala   Ibrahim_Aldosary                 52                14   \n","51         imala          Al husary                 52                14   \n","52         imala               safa                 52                14   \n","53         imala       all reciters                260                70   \n","\n","   Y_train_nb_samples X_test_nb_samples  \n","0                   1                 1  \n","1                   1                 1  \n","2                   1                 1  \n","3                   1                 1  \n","4                   1                 1  \n","5                   5                 5  \n","6                  62                16  \n","7                  62                16  \n","8                  62                16  \n","9                  62                16  \n","10                 62                16  \n","11                310                80  \n","12                 47                12  \n","13                 47                12  \n","14                 47                12  \n","15                 47                12  \n","16                 47                12  \n","17                235                60  \n","18                 79                20  \n","19                 79                20  \n","20                 79                20  \n","21                 79                20  \n","22                 79                20  \n","23                395               100  \n","24                119                30  \n","25                119                30  \n","26                119                30  \n","27                119                30  \n","28                119                30  \n","29                595               150  \n","30                114                29  \n","31                114                29  \n","32                114                29  \n","33                114                29  \n","34                114                29  \n","35                570               145  \n","36                179                45  \n","37                179                45  \n","38                179                45  \n","39                179                45  \n","40                179                45  \n","41                895               225  \n","42                 76                20  \n","43                 76                20  \n","44                 76                20  \n","45                 76                20  \n","46                 76                20  \n","47                380               100  \n","48                 52                14  \n","49                 52                14  \n","50                 52                14  \n","51                 52                14  \n","52                 52                14  \n","53                260                70  "],"text/html":["\n","  <div id=\"df-165cfa4d-4eb8-4643-bc2a-62299b2c8377\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tajweed_rule</th>\n","      <th>data_of</th>\n","      <th>X_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","      <th>Y_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Abdul Basit</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Al husary</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>madd_6_Lazim</td>\n","      <td>safa</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>madd_6_Lazim</td>\n","      <td>all reciters</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>madd_246</td>\n","      <td>Abdul Basit</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>madd_246</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>madd_246</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>madd_246</td>\n","      <td>Al husary</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>madd_246</td>\n","      <td>safa</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>madd_246</td>\n","      <td>all reciters</td>\n","      <td>310</td>\n","      <td>80</td>\n","      <td>310</td>\n","      <td>80</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>madd_6</td>\n","      <td>Abdul Basit</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>madd_6</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>madd_6</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>madd_6</td>\n","      <td>Al husary</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>madd_6</td>\n","      <td>safa</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>madd_6</td>\n","      <td>all reciters</td>\n","      <td>235</td>\n","      <td>60</td>\n","      <td>235</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>madd_2</td>\n","      <td>Abdul Basit</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>madd_2</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>madd_2</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>madd_2</td>\n","      <td>Al husary</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>madd_2</td>\n","      <td>safa</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>madd_2</td>\n","      <td>all reciters</td>\n","      <td>395</td>\n","      <td>100</td>\n","      <td>395</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Ikhfaa</td>\n","      <td>Abdul Basit</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Ikhfaa</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Ikhfaa</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Ikhfaa</td>\n","      <td>Al husary</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Ikhfaa</td>\n","      <td>safa</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Ikhfaa</td>\n","      <td>all reciters</td>\n","      <td>595</td>\n","      <td>150</td>\n","      <td>595</td>\n","      <td>150</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Idgham</td>\n","      <td>Abdul Basit</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Idgham</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Idgham</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>Idgham</td>\n","      <td>Al husary</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Idgham</td>\n","      <td>safa</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>Idgham</td>\n","      <td>all reciters</td>\n","      <td>570</td>\n","      <td>145</td>\n","      <td>570</td>\n","      <td>145</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>tafkhim</td>\n","      <td>Abdul Basit</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>tafkhim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>tafkhim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>tafkhim</td>\n","      <td>Al husary</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>tafkhim</td>\n","      <td>safa</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>tafkhim</td>\n","      <td>all reciters</td>\n","      <td>895</td>\n","      <td>225</td>\n","      <td>895</td>\n","      <td>225</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>qalqala</td>\n","      <td>Abdul Basit</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>qalqala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>qalqala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>qalqala</td>\n","      <td>Al husary</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>qalqala</td>\n","      <td>safa</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>qalqala</td>\n","      <td>all reciters</td>\n","      <td>380</td>\n","      <td>100</td>\n","      <td>380</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>imala</td>\n","      <td>Abdul Basit</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>imala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>imala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>imala</td>\n","      <td>Al husary</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>imala</td>\n","      <td>safa</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>imala</td>\n","      <td>all reciters</td>\n","      <td>260</td>\n","      <td>70</td>\n","      <td>260</td>\n","      <td>70</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-165cfa4d-4eb8-4643-bc2a-62299b2c8377')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-165cfa4d-4eb8-4643-bc2a-62299b2c8377 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-165cfa4d-4eb8-4643-bc2a-62299b2c8377');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-05ca8d88-bdd1-41fc-8712-fddb6aea8ace\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05ca8d88-bdd1-41fc-8712-fddb6aea8ace')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-05ca8d88-bdd1-41fc-8712-fddb6aea8ace button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"splitted_data_info","summary":"{\n  \"name\": \"splitted_data_info\",\n  \"rows\": 54,\n  \"fields\": [\n    {\n      \"column\": \"tajweed_rule\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala\",\n          \"madd_246\",\n          \"Idgham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_of\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Abdul Basit\",\n          \"Yassin Al Jazaery\",\n          \"all reciters\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"1\",\n          \"5\",\n          \"119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"1\",\n          \"5\",\n          \"60\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"1\",\n          \"5\",\n          \"119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"1\",\n          \"5\",\n          \"60\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["models_information"],"metadata":{"id":"h3kOCPqVuemS","executionInfo":{"status":"ok","timestamp":1717525961761,"user_tz":-60,"elapsed":18,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":331},"outputId":"3d521ee8-a13d-43f0-9fb3-e439c0882e37"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             Model       Loss Accuracy Accuracy %  \\\n","0  madd_6_Lazim_tajweed_rule_model    89.8238   1.0000     100.00   \n","1      madd_246_tajweed_rule_model    28.1466   0.9875      98.75   \n","2        madd_6_tajweed_rule_model   201.7663   0.9333      93.33   \n","3        madd_2_tajweed_rule_model     4.9547   1.0000     100.00   \n","4        Ikhfaa_tajweed_rule_model     1.7859   0.9333      93.33   \n","5        Idgham_tajweed_rule_model     0.9408   0.9172      91.72   \n","6       tafkhim_tajweed_rule_model    70.6740   0.9244      92.44   \n","7       qalqala_tajweed_rule_model  6029.3921   0.9800      98.00   \n","8         imala_tajweed_rule_model     5.9837   0.9286      92.86   \n","\n","                                   Path_to_the_model  \n","0  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","1  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","2  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","3  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","4  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","5  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","6  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","7  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","8  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  "],"text/html":["\n","  <div id=\"df-c548384e-80d9-4eec-bf00-e908a559fa68\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Loss</th>\n","      <th>Accuracy</th>\n","      <th>Accuracy %</th>\n","      <th>Path_to_the_model</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim_tajweed_rule_model</td>\n","      <td>89.8238</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_246_tajweed_rule_model</td>\n","      <td>28.1466</td>\n","      <td>0.9875</td>\n","      <td>98.75</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_tajweed_rule_model</td>\n","      <td>201.7663</td>\n","      <td>0.9333</td>\n","      <td>93.33</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_2_tajweed_rule_model</td>\n","      <td>4.9547</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Ikhfaa_tajweed_rule_model</td>\n","      <td>1.7859</td>\n","      <td>0.9333</td>\n","      <td>93.33</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Idgham_tajweed_rule_model</td>\n","      <td>0.9408</td>\n","      <td>0.9172</td>\n","      <td>91.72</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>tafkhim_tajweed_rule_model</td>\n","      <td>70.6740</td>\n","      <td>0.9244</td>\n","      <td>92.44</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>qalqala_tajweed_rule_model</td>\n","      <td>6029.3921</td>\n","      <td>0.9800</td>\n","      <td>98.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>imala_tajweed_rule_model</td>\n","      <td>5.9837</td>\n","      <td>0.9286</td>\n","      <td>92.86</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c548384e-80d9-4eec-bf00-e908a559fa68')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c548384e-80d9-4eec-bf00-e908a559fa68 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c548384e-80d9-4eec-bf00-e908a559fa68');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-dd9535ea-c21d-47de-bcf9-4e8c7d404da9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd9535ea-c21d-47de-bcf9-4e8c7d404da9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-dd9535ea-c21d-47de-bcf9-4e8c7d404da9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"models_information","summary":"{\n  \"name\": \"models_information\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala_tajweed_rule_model\",\n          \"madd_246_tajweed_rule_model\",\n          \"Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Loss\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"6029.3921\",\n          \"28.1466\",\n          \"0.9408\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"1.0000\",\n          \"0.9875\",\n          \"0.9800\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy %\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"100.00\",\n          \"98.75\",\n          \"98.00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Path_to_the_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"/content/drive/My Drive/M2 GL/PFE/new Tajweed rule model/AI models/v5/qalqala_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/new Tajweed rule model/AI models/v5/madd_246_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/new Tajweed rule model/AI models/v5/Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":[],"metadata":{"id":"Us2vxwO_s4-g"},"execution_count":null,"outputs":[]}]}