{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOynkB4TPnyRcOf+ixg6Ick"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWO1vAVp7HkG","executionInfo":{"status":"ok","timestamp":1717518251856,"user_tz":-60,"elapsed":31340,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"b124e72a-6e3f-4ab1-8536-0f76a40886fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.layers import Input, Flatten, Dense\n","from tensorflow.keras.models import Model"],"metadata":{"id":"6I2s5Q0iDpDE","executionInfo":{"status":"ok","timestamp":1717518276838,"user_tz":-60,"elapsed":4174,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load data\n","data = pd.read_csv('/content/drive/My Drive/M2 GL/PFE/Data/hisb_60_and_Al_fatihah_audio_with_transcript_and_MFCC_and_ahkam_indexing_v3.csv')"],"metadata":{"id":"WtJVQemz7klg","executionInfo":{"status":"ok","timestamp":1717518289392,"user_tz":-60,"elapsed":12557,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["export_dir = '/content/drive/My Drive/M2 GL/PFE/new Tajweed rule model/AI models/v2'"],"metadata":{"id":"7A9PSizPHQos","executionInfo":{"status":"ok","timestamp":1717518289392,"user_tz":-60,"elapsed":22,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["abdul_basit = data[data['recitor_en'] == 'Abdul Basit']\n","yassin_aljazaery = data[data['recitor_en'] == 'Yassin Al Jazaery']\n","ibrahim_aldosary = data[data['recitor_en'] == 'Ibrahim_Aldosary']\n","al_husary = data[data['recitor_en'] == 'Al husary']"],"metadata":{"id":"KoKbTBQr7nY8","executionInfo":{"status":"ok","timestamp":1717518289393,"user_tz":-60,"elapsed":22,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["splitted_data_info_np = np.empty((0, 6))\n","models_information_np = np.empty((0, 5))"],"metadata":{"id":"_CenkKQf-AXc","executionInfo":{"status":"ok","timestamp":1717518289393,"user_tz":-60,"elapsed":19,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["max_Y = {'madd_6_Lazim': 2, 'madd_246': 3, 'madd_6': 6, 'madd_2': 5, 'Ikhfaa': 9, 'Idgham': 13, 'tafkhim': 24, 'qalqala': 6, 'imala': 7}\n","max_X = 8000"],"metadata":{"id":"H950tSVTMxlL","executionInfo":{"status":"ok","timestamp":1717518289393,"user_tz":-60,"elapsed":13,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def data_preparation(reciter_data, tajweed_rule):\n","  # Extract 'mfcc' and tajweed_rule columns as lists of strings\n","  X_raw = reciter_data['mfcc'].astype(str).tolist()\n","  Y_raw = reciter_data[tajweed_rule].astype(str).tolist()\n","\n","  # Preprocess the input data (X)\n","  X = [tf.constant(eval(x)) for x in X_raw]\n","  Y = [tf.constant(eval(x)) for x in Y_raw]\n","\n","  # Pad sequences in Y and X to ensure all have the same length\n","  Y_padded = tf.keras.preprocessing.sequence.pad_sequences(Y, maxlen=max_Y[tajweed_rule], padding='post', dtype='int32', value=-1)\n","  X_padded = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_X, padding='post', dtype='float32')\n","\n","  # Split the data into training and testing sets\n","  X_train, X_test, Y_train, Y_test = train_test_split(X_padded, Y_padded, test_size=0.2, random_state=10)\n","  return X_train, X_test, Y_train, Y_test"],"metadata":{"id":"pVbn5z76-K4O","executionInfo":{"status":"ok","timestamp":1717518374889,"user_tz":-60,"elapsed":323,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def tajweed_rule_model(reciter1, reciter2, reciter3, reciter4, tajweed_rule):\n","  global splitted_data_info_np, models_information_np, data\n","  # data preparation\n","  reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test = data_preparation(reciter1, tajweed_rule)\n","  reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test = data_preparation(reciter2, tajweed_rule)\n","  reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test = data_preparation(reciter3, tajweed_rule)\n","  reciter4_X_train, reciter4_X_test, reciter4_Y_train, reciter4_Y_test = data_preparation(reciter4, tajweed_rule)\n","\n","  # Update splitted_data_info with information about each reciter\n","  for reciter_X_train, reciter_X_test, reciter_Y_train, reciter_Y_test, reciter_data in [\n","      (reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test, reciter1),\n","      (reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test, reciter2),\n","      (reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test, reciter3),\n","      (reciter4_X_train, reciter4_X_test, reciter4_Y_train, reciter4_Y_test, reciter4)]:\n","\n","      splitted_data_info_np = np.append(splitted_data_info_np, [[\n","              tajweed_rule,\n","              reciter_data.iloc[0]['recitor_en'],\n","              len(reciter_X_train),\n","              len(reciter_X_test),\n","              len(reciter_Y_train),\n","              len(reciter_Y_test)\n","              ]], axis=0)\n","\n","  # concatenate data\n","  # training data\n","  X_train = np.concatenate([reciter1_X_train, reciter2_X_train, reciter3_X_train, reciter4_X_train], axis=0)\n","  Y_train = np.concatenate([reciter1_Y_train, reciter2_Y_train, reciter3_Y_train, reciter4_Y_train], axis=0)\n","\n","  # testing data\n","  X_test = np.concatenate([reciter1_X_test, reciter2_X_test, reciter3_X_test, reciter4_X_test], axis=0)\n","  Y_test = np.concatenate([reciter1_Y_test, reciter2_Y_test, reciter3_Y_test, reciter4_Y_test], axis=0)\n","\n","  splitted_data_info_np = np.append(splitted_data_info_np, [[\n","          tajweed_rule,\n","          'all reciters',\n","          len(X_train),\n","          len(X_test),\n","          len(Y_train),\n","          len(Y_test)\n","          ]], axis=0)\n","\n","  # Normalize input data by scaling each sequence individually\n","  scaler = StandardScaler()\n","  X_train_scaled = np.array([scaler.fit_transform(seq) for seq in X_train])\n","  X_test_scaled = np.array([scaler.transform(seq) for seq in X_test])\n","\n","  # Define a simple neural network model\n","  input_shape = X_train_scaled[0].shape  # Shape of each mfcc sequence\n","  output_shape = Y_train.shape[1]  # Dimension of output (number of units in output layer)\n","\n","  input_layer = Input(shape=input_shape)\n","  flatten_layer = Flatten()(input_layer)  # Flatten the sequence to a 1D vector\n","  hidden_layer = Dense(64, activation='relu')(flatten_layer)\n","  output_layer = Dense(output_shape, activation='linear')(hidden_layer)  # Define the output layer with the correct units\n","\n","  model = Model(inputs=input_layer, outputs=output_layer)\n","\n","  # Compile the model\n","  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","\n","  # Train the model\n","  model.fit(X_train_scaled, Y_train, epochs=50, batch_size=32, validation_split=0.1)\n","\n","  #export the model\n","  model_filename = f'{tajweed_rule}_tajweed_rule_model'\n","  model_path = os.path.join(export_dir, model_filename)\n","  keras.models.save_model(model, model_path)\n","\n","  # Make predictions on test data\n","  predictions = model.predict(X_test_scaled)\n","\n","  # Evaluate the model with adjusted predictions\n","  predictions[predictions < 0] = -1\n","  predictions = np.round(predictions).astype('int32')\n","  loss, accuracy = model.evaluate(X_test_scaled, predictions)\n","\n","  print(f\"Test Loss: {loss:.4f}, Test accuracy : {accuracy:.4f}\")\n","  models_information_np = np.append(models_information_np, [[\n","          model_filename,\n","          \"{:.4f}\".format(loss),\n","          \"{:.4f}\".format(accuracy),\n","          \"{:.2f}\".format(accuracy*100),\n","          model_path]], axis=0)"],"metadata":{"id":"n3ycP8uz8zp8","executionInfo":{"status":"ok","timestamp":1717518375234,"user_tz":-60,"elapsed":3,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["for rule in max_Y.keys():\n","  tajweed_rule_model(abdul_basit, yassin_aljazaery, ibrahim_aldosary, al_husary, rule)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n6qxa6hWLAeZ","executionInfo":{"status":"ok","timestamp":1717520329313,"user_tz":-60,"elapsed":1953767,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"99d3812c-a172-4b58-f264-f4b580781c77"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","27/27 [==============================] - 4s 129ms/step - loss: 153.0115 - accuracy: 0.1659 - val_loss: 6.4930 - val_accuracy: 0.4688\n","Epoch 2/50\n","27/27 [==============================] - 2s 85ms/step - loss: 12.0393 - accuracy: 0.0421 - val_loss: 4.4242 - val_accuracy: 0.1354\n","Epoch 3/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.8205 - accuracy: 0.0129 - val_loss: 3.4431 - val_accuracy: 0.0625\n","Epoch 4/50\n","27/27 [==============================] - 2s 79ms/step - loss: 11.7290 - accuracy: 0.0105 - val_loss: 3.3928 - val_accuracy: 0.0625\n","Epoch 5/50\n","27/27 [==============================] - 2s 87ms/step - loss: 11.7215 - accuracy: 0.0093 - val_loss: 3.3729 - val_accuracy: 0.0625\n","Epoch 6/50\n","27/27 [==============================] - 4s 142ms/step - loss: 11.7075 - accuracy: 0.0093 - val_loss: 3.3559 - val_accuracy: 0.0521\n","Epoch 7/50\n","27/27 [==============================] - 3s 120ms/step - loss: 11.6924 - accuracy: 0.0093 - val_loss: 3.3426 - val_accuracy: 0.0521\n","Epoch 8/50\n","27/27 [==============================] - 2s 85ms/step - loss: 11.6802 - accuracy: 0.0093 - val_loss: 3.3301 - val_accuracy: 0.0521\n","Epoch 9/50\n","27/27 [==============================] - 2s 83ms/step - loss: 11.6695 - accuracy: 0.0082 - val_loss: 3.3161 - val_accuracy: 0.0521\n","Epoch 10/50\n","27/27 [==============================] - 2s 88ms/step - loss: 11.6572 - accuracy: 0.0082 - val_loss: 3.3020 - val_accuracy: 0.0521\n","Epoch 11/50\n","27/27 [==============================] - 2s 86ms/step - loss: 11.6471 - accuracy: 0.0082 - val_loss: 3.2874 - val_accuracy: 0.0521\n","Epoch 12/50\n","27/27 [==============================] - 3s 115ms/step - loss: 11.6363 - accuracy: 0.0082 - val_loss: 3.2738 - val_accuracy: 0.0521\n","Epoch 13/50\n","27/27 [==============================] - 4s 137ms/step - loss: 11.6232 - accuracy: 0.0082 - val_loss: 3.2616 - val_accuracy: 0.0521\n","Epoch 14/50\n","27/27 [==============================] - 4s 136ms/step - loss: 11.6121 - accuracy: 0.0082 - val_loss: 3.2455 - val_accuracy: 0.0521\n","Epoch 15/50\n","27/27 [==============================] - 2s 84ms/step - loss: 11.6009 - accuracy: 0.0082 - val_loss: 3.2328 - val_accuracy: 0.0521\n","Epoch 16/50\n","27/27 [==============================] - 2s 86ms/step - loss: 11.5896 - accuracy: 0.0082 - val_loss: 3.2189 - val_accuracy: 0.0521\n","Epoch 17/50\n","27/27 [==============================] - 3s 115ms/step - loss: 11.5807 - accuracy: 0.0082 - val_loss: 3.2053 - val_accuracy: 0.0521\n","Epoch 18/50\n","27/27 [==============================] - 3s 117ms/step - loss: 11.5681 - accuracy: 0.0082 - val_loss: 3.1917 - val_accuracy: 0.0521\n","Epoch 19/50\n","27/27 [==============================] - 2s 92ms/step - loss: 11.5590 - accuracy: 0.0082 - val_loss: 3.1765 - val_accuracy: 0.0521\n","Epoch 20/50\n","27/27 [==============================] - 2s 89ms/step - loss: 11.5474 - accuracy: 0.0082 - val_loss: 3.1634 - val_accuracy: 0.0521\n","Epoch 21/50\n","27/27 [==============================] - 2s 86ms/step - loss: 11.5373 - accuracy: 0.0082 - val_loss: 3.1493 - val_accuracy: 0.0521\n","Epoch 22/50\n","27/27 [==============================] - 2s 89ms/step - loss: 11.5271 - accuracy: 0.0082 - val_loss: 3.1358 - val_accuracy: 0.0521\n","Epoch 23/50\n","27/27 [==============================] - 3s 120ms/step - loss: 11.5174 - accuracy: 0.0082 - val_loss: 3.1225 - val_accuracy: 0.0521\n","Epoch 24/50\n","27/27 [==============================] - 3s 108ms/step - loss: 11.5085 - accuracy: 0.0082 - val_loss: 3.1080 - val_accuracy: 0.0521\n","Epoch 25/50\n","27/27 [==============================] - 2s 87ms/step - loss: 11.4990 - accuracy: 0.0082 - val_loss: 3.0958 - val_accuracy: 0.0521\n","Epoch 26/50\n","27/27 [==============================] - 2s 82ms/step - loss: 11.4899 - accuracy: 0.0082 - val_loss: 3.0843 - val_accuracy: 0.0521\n","Epoch 27/50\n","27/27 [==============================] - 2s 82ms/step - loss: 11.4817 - accuracy: 0.0082 - val_loss: 3.0706 - val_accuracy: 0.0521\n","Epoch 28/50\n","27/27 [==============================] - 2s 88ms/step - loss: 11.4731 - accuracy: 0.0082 - val_loss: 3.0576 - val_accuracy: 0.0521\n","Epoch 29/50\n","27/27 [==============================] - 3s 123ms/step - loss: 11.4647 - accuracy: 0.0082 - val_loss: 3.0450 - val_accuracy: 0.0521\n","Epoch 30/50\n","27/27 [==============================] - 3s 103ms/step - loss: 11.4566 - accuracy: 0.0082 - val_loss: 3.0324 - val_accuracy: 0.0521\n","Epoch 31/50\n","27/27 [==============================] - 2s 88ms/step - loss: 11.4484 - accuracy: 0.0082 - val_loss: 3.0208 - val_accuracy: 0.0521\n","Epoch 32/50\n","27/27 [==============================] - 2s 84ms/step - loss: 11.4408 - accuracy: 0.0082 - val_loss: 3.0090 - val_accuracy: 0.0521\n","Epoch 33/50\n","27/27 [==============================] - 2s 83ms/step - loss: 11.4334 - accuracy: 0.0082 - val_loss: 2.9976 - val_accuracy: 0.0521\n","Epoch 34/50\n","27/27 [==============================] - 2s 86ms/step - loss: 11.4257 - accuracy: 0.0082 - val_loss: 2.9873 - val_accuracy: 0.0521\n","Epoch 35/50\n","27/27 [==============================] - 3s 124ms/step - loss: 11.4191 - accuracy: 0.0082 - val_loss: 2.9745 - val_accuracy: 0.0521\n","Epoch 36/50\n","27/27 [==============================] - 2s 89ms/step - loss: 11.4113 - accuracy: 0.0082 - val_loss: 2.9639 - val_accuracy: 0.0521\n","Epoch 37/50\n","27/27 [==============================] - 2s 79ms/step - loss: 11.4045 - accuracy: 0.0082 - val_loss: 2.9533 - val_accuracy: 0.0521\n","Epoch 38/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.3983 - accuracy: 0.0082 - val_loss: 2.9412 - val_accuracy: 0.0521\n","Epoch 39/50\n","27/27 [==============================] - 2s 80ms/step - loss: 11.3910 - accuracy: 0.0082 - val_loss: 2.9322 - val_accuracy: 0.0521\n","Epoch 40/50\n","27/27 [==============================] - 2s 80ms/step - loss: 11.3848 - accuracy: 0.0082 - val_loss: 2.9221 - val_accuracy: 0.0521\n","Epoch 41/50\n","27/27 [==============================] - 3s 109ms/step - loss: 11.3786 - accuracy: 0.0082 - val_loss: 2.9119 - val_accuracy: 0.0521\n","Epoch 42/50\n","27/27 [==============================] - 3s 113ms/step - loss: 11.3723 - accuracy: 0.0082 - val_loss: 2.9026 - val_accuracy: 0.0521\n","Epoch 43/50\n","27/27 [==============================] - 2s 78ms/step - loss: 11.3672 - accuracy: 0.0082 - val_loss: 2.8913 - val_accuracy: 0.0521\n","Epoch 44/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.3604 - accuracy: 0.0082 - val_loss: 2.8839 - val_accuracy: 0.0521\n","Epoch 45/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.3551 - accuracy: 0.0082 - val_loss: 2.8750 - val_accuracy: 0.0521\n","Epoch 46/50\n","27/27 [==============================] - 2s 84ms/step - loss: 11.3498 - accuracy: 0.0082 - val_loss: 2.8650 - val_accuracy: 0.0521\n","Epoch 47/50\n","27/27 [==============================] - 3s 97ms/step - loss: 11.3445 - accuracy: 0.0082 - val_loss: 2.8561 - val_accuracy: 0.0521\n","Epoch 48/50\n","27/27 [==============================] - 3s 118ms/step - loss: 11.3394 - accuracy: 0.0082 - val_loss: 2.8487 - val_accuracy: 0.0521\n","Epoch 49/50\n","27/27 [==============================] - 2s 84ms/step - loss: 11.3348 - accuracy: 0.0082 - val_loss: 2.8402 - val_accuracy: 0.0521\n","Epoch 50/50\n","27/27 [==============================] - 2s 79ms/step - loss: 11.3297 - accuracy: 0.0082 - val_loss: 2.8327 - val_accuracy: 0.0521\n","8/8 [==============================] - 0s 14ms/step\n","8/8 [==============================] - 0s 18ms/step - loss: 134.8659 - accuracy: 0.0458\n","Test Loss: 134.8659, Test accuracy : 0.0458\n","Epoch 1/50\n","27/27 [==============================] - 3s 85ms/step - loss: 239.8962 - accuracy: 0.3201 - val_loss: 103.7301 - val_accuracy: 0.1562\n","Epoch 2/50\n","27/27 [==============================] - 2s 83ms/step - loss: 103.3130 - accuracy: 0.4638 - val_loss: 97.9160 - val_accuracy: 0.3542\n","Epoch 3/50\n","27/27 [==============================] - 3s 103ms/step - loss: 82.5603 - accuracy: 0.4112 - val_loss: 94.8202 - val_accuracy: 0.2917\n","Epoch 4/50\n","27/27 [==============================] - 3s 121ms/step - loss: 75.4138 - accuracy: 0.5093 - val_loss: 92.8837 - val_accuracy: 0.7188\n","Epoch 5/50\n","27/27 [==============================] - 2s 77ms/step - loss: 67.8187 - accuracy: 0.8785 - val_loss: 90.2541 - val_accuracy: 0.8854\n","Epoch 6/50\n","27/27 [==============================] - 2s 82ms/step - loss: 60.7090 - accuracy: 0.8820 - val_loss: 88.7209 - val_accuracy: 0.9062\n","Epoch 7/50\n","27/27 [==============================] - 2s 84ms/step - loss: 54.7710 - accuracy: 0.8762 - val_loss: 87.8927 - val_accuracy: 0.9167\n","Epoch 8/50\n","27/27 [==============================] - 2s 82ms/step - loss: 48.3581 - accuracy: 0.8949 - val_loss: 85.6775 - val_accuracy: 0.9062\n","Epoch 9/50\n","27/27 [==============================] - 3s 99ms/step - loss: 45.0095 - accuracy: 0.8797 - val_loss: 86.1349 - val_accuracy: 0.9167\n","Epoch 10/50\n","27/27 [==============================] - 3s 119ms/step - loss: 42.5922 - accuracy: 0.8657 - val_loss: 85.8889 - val_accuracy: 0.9167\n","Epoch 11/50\n","27/27 [==============================] - 2s 84ms/step - loss: 36.4490 - accuracy: 0.8657 - val_loss: 85.4272 - val_accuracy: 0.9271\n","Epoch 12/50\n","27/27 [==============================] - 2s 80ms/step - loss: 32.9349 - accuracy: 0.8727 - val_loss: 91.0436 - val_accuracy: 0.9167\n","Epoch 13/50\n","27/27 [==============================] - 2s 81ms/step - loss: 31.3472 - accuracy: 0.8680 - val_loss: 91.0606 - val_accuracy: 0.9167\n","Epoch 14/50\n","27/27 [==============================] - 2s 85ms/step - loss: 29.5477 - accuracy: 0.8680 - val_loss: 90.3717 - val_accuracy: 0.9167\n","Epoch 15/50\n","27/27 [==============================] - 2s 91ms/step - loss: 27.4575 - accuracy: 0.8621 - val_loss: 91.6644 - val_accuracy: 0.9167\n","Epoch 16/50\n","27/27 [==============================] - 3s 124ms/step - loss: 23.8645 - accuracy: 0.8657 - val_loss: 97.7068 - val_accuracy: 0.9062\n","Epoch 17/50\n","27/27 [==============================] - 2s 87ms/step - loss: 21.3754 - accuracy: 0.8598 - val_loss: 95.6144 - val_accuracy: 0.9167\n","Epoch 18/50\n","27/27 [==============================] - 2s 78ms/step - loss: 21.0544 - accuracy: 0.8516 - val_loss: 98.2262 - val_accuracy: 0.9062\n","Epoch 19/50\n","27/27 [==============================] - 2s 77ms/step - loss: 19.3232 - accuracy: 0.8668 - val_loss: 102.4792 - val_accuracy: 0.9062\n","Epoch 20/50\n","27/27 [==============================] - 2s 83ms/step - loss: 17.1746 - accuracy: 0.8657 - val_loss: 99.9455 - val_accuracy: 0.9062\n","Epoch 21/50\n","27/27 [==============================] - 2s 89ms/step - loss: 16.2222 - accuracy: 0.8645 - val_loss: 106.9552 - val_accuracy: 0.9062\n","Epoch 22/50\n","27/27 [==============================] - 3s 114ms/step - loss: 16.5160 - accuracy: 0.8528 - val_loss: 100.0010 - val_accuracy: 0.8958\n","Epoch 23/50\n","27/27 [==============================] - 3s 104ms/step - loss: 16.8288 - accuracy: 0.8738 - val_loss: 101.2924 - val_accuracy: 0.9062\n","Epoch 24/50\n","27/27 [==============================] - 2s 81ms/step - loss: 16.9076 - accuracy: 0.8703 - val_loss: 103.9887 - val_accuracy: 0.8958\n","Epoch 25/50\n","27/27 [==============================] - 2s 82ms/step - loss: 16.8414 - accuracy: 0.8925 - val_loss: 102.8834 - val_accuracy: 0.9167\n","Epoch 26/50\n","27/27 [==============================] - 2s 83ms/step - loss: 17.9379 - accuracy: 0.8808 - val_loss: 104.2344 - val_accuracy: 0.8958\n","Epoch 27/50\n","27/27 [==============================] - 2s 80ms/step - loss: 19.2699 - accuracy: 0.8598 - val_loss: 104.5292 - val_accuracy: 0.8958\n","Epoch 28/50\n","27/27 [==============================] - 3s 116ms/step - loss: 20.9747 - accuracy: 0.9171 - val_loss: 103.1144 - val_accuracy: 0.9062\n","Epoch 29/50\n","27/27 [==============================] - 3s 105ms/step - loss: 19.4118 - accuracy: 0.9673 - val_loss: 104.1577 - val_accuracy: 0.9167\n","Epoch 30/50\n","27/27 [==============================] - 2s 81ms/step - loss: 15.6706 - accuracy: 0.9381 - val_loss: 103.5186 - val_accuracy: 0.8958\n","Epoch 31/50\n","27/27 [==============================] - 2s 81ms/step - loss: 14.3172 - accuracy: 0.9544 - val_loss: 104.9312 - val_accuracy: 0.9062\n","Epoch 32/50\n","27/27 [==============================] - 2s 84ms/step - loss: 13.2875 - accuracy: 0.9638 - val_loss: 105.4674 - val_accuracy: 0.8958\n","Epoch 33/50\n","27/27 [==============================] - 2s 79ms/step - loss: 12.8343 - accuracy: 0.9498 - val_loss: 105.9148 - val_accuracy: 0.8958\n","Epoch 34/50\n","27/27 [==============================] - 3s 105ms/step - loss: 12.5431 - accuracy: 0.9463 - val_loss: 105.3499 - val_accuracy: 0.8958\n","Epoch 35/50\n","27/27 [==============================] - 3s 122ms/step - loss: 12.4061 - accuracy: 0.9486 - val_loss: 106.2301 - val_accuracy: 0.9062\n","Epoch 36/50\n","27/27 [==============================] - 2s 83ms/step - loss: 12.2037 - accuracy: 0.9393 - val_loss: 106.0638 - val_accuracy: 0.8958\n","Epoch 37/50\n","27/27 [==============================] - 2s 81ms/step - loss: 12.1004 - accuracy: 0.9393 - val_loss: 107.2369 - val_accuracy: 0.8958\n","Epoch 38/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.9949 - accuracy: 0.9404 - val_loss: 106.6843 - val_accuracy: 0.8958\n","Epoch 39/50\n","27/27 [==============================] - 2s 80ms/step - loss: 11.9290 - accuracy: 0.9404 - val_loss: 106.0437 - val_accuracy: 0.8958\n","Epoch 40/50\n","27/27 [==============================] - 3s 99ms/step - loss: 11.9171 - accuracy: 0.9404 - val_loss: 106.9774 - val_accuracy: 0.8958\n","Epoch 41/50\n","27/27 [==============================] - 3s 115ms/step - loss: 11.9437 - accuracy: 0.9346 - val_loss: 106.5086 - val_accuracy: 0.9062\n","Epoch 42/50\n","27/27 [==============================] - 2s 83ms/step - loss: 11.8963 - accuracy: 0.9404 - val_loss: 105.6660 - val_accuracy: 0.8958\n","Epoch 43/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.8707 - accuracy: 0.9416 - val_loss: 104.7737 - val_accuracy: 0.9062\n","Epoch 44/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.9544 - accuracy: 0.9381 - val_loss: 107.8871 - val_accuracy: 0.9062\n","Epoch 45/50\n","27/27 [==============================] - 2s 82ms/step - loss: 12.1907 - accuracy: 0.9393 - val_loss: 103.4851 - val_accuracy: 0.9062\n","Epoch 46/50\n","27/27 [==============================] - 3s 99ms/step - loss: 12.6424 - accuracy: 0.9346 - val_loss: 108.4138 - val_accuracy: 0.9062\n","Epoch 47/50\n","27/27 [==============================] - 3s 108ms/step - loss: 12.0331 - accuracy: 0.9357 - val_loss: 104.7894 - val_accuracy: 0.8854\n","Epoch 48/50\n","27/27 [==============================] - 3s 99ms/step - loss: 12.1621 - accuracy: 0.9463 - val_loss: 106.0200 - val_accuracy: 0.8854\n","Epoch 49/50\n","27/27 [==============================] - 2s 80ms/step - loss: 12.2318 - accuracy: 0.9463 - val_loss: 106.7496 - val_accuracy: 0.8958\n","Epoch 50/50\n","27/27 [==============================] - 2s 83ms/step - loss: 12.4059 - accuracy: 0.9474 - val_loss: 109.0935 - val_accuracy: 0.8958\n","8/8 [==============================] - 0s 15ms/step\n","8/8 [==============================] - 0s 15ms/step - loss: 351.7010 - accuracy: 1.0000\n","Test Loss: 351.7010, Test accuracy : 1.0000\n","Epoch 1/50\n","27/27 [==============================] - 3s 89ms/step - loss: 85.4972 - accuracy: 0.1519 - val_loss: 22.9173 - val_accuracy: 0.8229\n","Epoch 2/50\n","27/27 [==============================] - 2s 87ms/step - loss: 29.4121 - accuracy: 0.7652 - val_loss: 21.7310 - val_accuracy: 0.7292\n","Epoch 3/50\n","27/27 [==============================] - 3s 115ms/step - loss: 25.5956 - accuracy: 0.8119 - val_loss: 22.5838 - val_accuracy: 0.6771\n","Epoch 4/50\n","27/27 [==============================] - 3s 96ms/step - loss: 22.7557 - accuracy: 0.8119 - val_loss: 21.5424 - val_accuracy: 0.6667\n","Epoch 5/50\n","27/27 [==============================] - 2s 81ms/step - loss: 21.0569 - accuracy: 0.8329 - val_loss: 20.5372 - val_accuracy: 0.7812\n","Epoch 6/50\n","27/27 [==============================] - 2s 83ms/step - loss: 19.6428 - accuracy: 0.8107 - val_loss: 20.2370 - val_accuracy: 0.7812\n","Epoch 7/50\n","27/27 [==============================] - 2s 81ms/step - loss: 18.4130 - accuracy: 0.8481 - val_loss: 19.3438 - val_accuracy: 0.7188\n","Epoch 8/50\n","27/27 [==============================] - 2s 80ms/step - loss: 17.2699 - accuracy: 0.8388 - val_loss: 19.1303 - val_accuracy: 0.6979\n","Epoch 9/50\n","27/27 [==============================] - 3s 115ms/step - loss: 16.7004 - accuracy: 0.8563 - val_loss: 19.8322 - val_accuracy: 0.7292\n","Epoch 10/50\n","27/27 [==============================] - 3s 107ms/step - loss: 16.2360 - accuracy: 0.8516 - val_loss: 18.9723 - val_accuracy: 0.6354\n","Epoch 11/50\n","27/27 [==============================] - 2s 85ms/step - loss: 15.3064 - accuracy: 0.8727 - val_loss: 22.0840 - val_accuracy: 0.7396\n","Epoch 12/50\n","27/27 [==============================] - 2s 81ms/step - loss: 17.6326 - accuracy: 0.8435 - val_loss: 18.3653 - val_accuracy: 0.6042\n","Epoch 13/50\n","27/27 [==============================] - 2s 82ms/step - loss: 16.5521 - accuracy: 0.8411 - val_loss: 17.9554 - val_accuracy: 0.6250\n","Epoch 14/50\n","27/27 [==============================] - 2s 81ms/step - loss: 16.5318 - accuracy: 0.8621 - val_loss: 18.9601 - val_accuracy: 0.7500\n","Epoch 15/50\n","27/27 [==============================] - 3s 104ms/step - loss: 14.8602 - accuracy: 0.8738 - val_loss: 18.2638 - val_accuracy: 0.5729\n","Epoch 16/50\n","27/27 [==============================] - 3s 112ms/step - loss: 13.9742 - accuracy: 0.8598 - val_loss: 18.9106 - val_accuracy: 0.7812\n","Epoch 17/50\n","27/27 [==============================] - 2s 85ms/step - loss: 13.1721 - accuracy: 0.9030 - val_loss: 17.9819 - val_accuracy: 0.7604\n","Epoch 18/50\n","27/27 [==============================] - 2s 79ms/step - loss: 12.8167 - accuracy: 0.9042 - val_loss: 18.2393 - val_accuracy: 0.7500\n","Epoch 19/50\n","27/27 [==============================] - 2s 81ms/step - loss: 13.2824 - accuracy: 0.9054 - val_loss: 18.6794 - val_accuracy: 0.7604\n","Epoch 20/50\n","27/27 [==============================] - 2s 78ms/step - loss: 11.7587 - accuracy: 0.9042 - val_loss: 18.0320 - val_accuracy: 0.7604\n","Epoch 21/50\n","27/27 [==============================] - 2s 92ms/step - loss: 11.4840 - accuracy: 0.9100 - val_loss: 17.9905 - val_accuracy: 0.7812\n","Epoch 22/50\n","27/27 [==============================] - 3s 113ms/step - loss: 10.9292 - accuracy: 0.9030 - val_loss: 18.1551 - val_accuracy: 0.7812\n","Epoch 23/50\n","27/27 [==============================] - 2s 90ms/step - loss: 10.8766 - accuracy: 0.9007 - val_loss: 18.3379 - val_accuracy: 0.7812\n","Epoch 24/50\n","27/27 [==============================] - 2s 80ms/step - loss: 10.2333 - accuracy: 0.9065 - val_loss: 17.7282 - val_accuracy: 0.7812\n","Epoch 25/50\n","27/27 [==============================] - 2s 82ms/step - loss: 9.4537 - accuracy: 0.9077 - val_loss: 18.4619 - val_accuracy: 0.7708\n","Epoch 26/50\n","27/27 [==============================] - 2s 82ms/step - loss: 8.6768 - accuracy: 0.9065 - val_loss: 18.1043 - val_accuracy: 0.8125\n","Epoch 27/50\n","27/27 [==============================] - 2s 90ms/step - loss: 7.8076 - accuracy: 0.9007 - val_loss: 18.8866 - val_accuracy: 0.8021\n","Epoch 28/50\n","27/27 [==============================] - 3s 109ms/step - loss: 7.1448 - accuracy: 0.9100 - val_loss: 19.1642 - val_accuracy: 0.8021\n","Epoch 29/50\n","27/27 [==============================] - 3s 103ms/step - loss: 6.5433 - accuracy: 0.9042 - val_loss: 18.6661 - val_accuracy: 0.8021\n","Epoch 30/50\n","27/27 [==============================] - 2s 82ms/step - loss: 5.9205 - accuracy: 0.9019 - val_loss: 19.1479 - val_accuracy: 0.7917\n","Epoch 31/50\n","27/27 [==============================] - 2s 81ms/step - loss: 5.6123 - accuracy: 0.9007 - val_loss: 19.5440 - val_accuracy: 0.8125\n","Epoch 32/50\n","27/27 [==============================] - 2s 82ms/step - loss: 5.4994 - accuracy: 0.9100 - val_loss: 19.1236 - val_accuracy: 0.8021\n","Epoch 33/50\n","27/27 [==============================] - 2s 82ms/step - loss: 5.3102 - accuracy: 0.9042 - val_loss: 19.6462 - val_accuracy: 0.8125\n","Epoch 34/50\n","27/27 [==============================] - 3s 115ms/step - loss: 5.7207 - accuracy: 0.8914 - val_loss: 20.0142 - val_accuracy: 0.8125\n","Epoch 35/50\n","27/27 [==============================] - 3s 109ms/step - loss: 5.9350 - accuracy: 0.8960 - val_loss: 19.4704 - val_accuracy: 0.7917\n","Epoch 36/50\n","27/27 [==============================] - 2s 81ms/step - loss: 7.6431 - accuracy: 0.8832 - val_loss: 20.0121 - val_accuracy: 0.7708\n","Epoch 37/50\n","27/27 [==============================] - 2s 80ms/step - loss: 7.8029 - accuracy: 0.8820 - val_loss: 20.7360 - val_accuracy: 0.7604\n","Epoch 38/50\n","27/27 [==============================] - 2s 79ms/step - loss: 7.0551 - accuracy: 0.8621 - val_loss: 20.5861 - val_accuracy: 0.8021\n","Epoch 39/50\n","27/27 [==============================] - 2s 78ms/step - loss: 7.0042 - accuracy: 0.8505 - val_loss: 20.5778 - val_accuracy: 0.7708\n","Epoch 40/50\n","27/27 [==============================] - 3s 98ms/step - loss: 5.9826 - accuracy: 0.8715 - val_loss: 19.3775 - val_accuracy: 0.7917\n","Epoch 41/50\n","27/27 [==============================] - 3s 110ms/step - loss: 5.3391 - accuracy: 0.8843 - val_loss: 18.7115 - val_accuracy: 0.7708\n","Epoch 42/50\n","27/27 [==============================] - 2s 85ms/step - loss: 5.0328 - accuracy: 0.9112 - val_loss: 18.5377 - val_accuracy: 0.7812\n","Epoch 43/50\n","27/27 [==============================] - 2s 81ms/step - loss: 4.4054 - accuracy: 0.9194 - val_loss: 19.1452 - val_accuracy: 0.8021\n","Epoch 44/50\n","27/27 [==============================] - 2s 82ms/step - loss: 4.4283 - accuracy: 0.9147 - val_loss: 18.5018 - val_accuracy: 0.8021\n","Epoch 45/50\n","27/27 [==============================] - 2s 82ms/step - loss: 3.7285 - accuracy: 0.9299 - val_loss: 19.5039 - val_accuracy: 0.8021\n","Epoch 46/50\n","27/27 [==============================] - 2s 93ms/step - loss: 3.4470 - accuracy: 0.9229 - val_loss: 18.3360 - val_accuracy: 0.7812\n","Epoch 47/50\n","27/27 [==============================] - 3s 113ms/step - loss: 3.1207 - accuracy: 0.8984 - val_loss: 19.3908 - val_accuracy: 0.8021\n","Epoch 48/50\n","27/27 [==============================] - 2s 92ms/step - loss: 3.0153 - accuracy: 0.9054 - val_loss: 18.4485 - val_accuracy: 0.7812\n","Epoch 49/50\n","27/27 [==============================] - 2s 80ms/step - loss: 2.8814 - accuracy: 0.9136 - val_loss: 18.8510 - val_accuracy: 0.7917\n","Epoch 50/50\n","27/27 [==============================] - 2s 80ms/step - loss: 2.8619 - accuracy: 0.9229 - val_loss: 18.7264 - val_accuracy: 0.8021\n","8/8 [==============================] - 0s 14ms/step\n","8/8 [==============================] - 0s 15ms/step - loss: 506.4740 - accuracy: 0.9417\n","Test Loss: 506.4740, Test accuracy : 0.9417\n","Epoch 1/50\n","27/27 [==============================] - 4s 128ms/step - loss: 123.0906 - accuracy: 0.3832 - val_loss: 92.0636 - val_accuracy: 0.7500\n","Epoch 2/50\n","27/27 [==============================] - 2s 84ms/step - loss: 51.0124 - accuracy: 0.8411 - val_loss: 59.6679 - val_accuracy: 0.9896\n","Epoch 3/50\n","27/27 [==============================] - 2s 89ms/step - loss: 47.7175 - accuracy: 0.9077 - val_loss: 55.6895 - val_accuracy: 0.9792\n","Epoch 4/50\n","27/27 [==============================] - 2s 84ms/step - loss: 43.8996 - accuracy: 0.9322 - val_loss: 64.9481 - val_accuracy: 0.9583\n","Epoch 5/50\n","27/27 [==============================] - 2s 83ms/step - loss: 41.9041 - accuracy: 0.9171 - val_loss: 45.4313 - val_accuracy: 0.9271\n","Epoch 6/50\n","27/27 [==============================] - 3s 123ms/step - loss: 40.9628 - accuracy: 0.9100 - val_loss: 82.5485 - val_accuracy: 0.9479\n","Epoch 7/50\n","27/27 [==============================] - 3s 111ms/step - loss: 40.4121 - accuracy: 0.8937 - val_loss: 44.6532 - val_accuracy: 0.9792\n","Epoch 8/50\n","27/27 [==============================] - 2s 83ms/step - loss: 37.9110 - accuracy: 0.9171 - val_loss: 42.6754 - val_accuracy: 0.9167\n","Epoch 9/50\n","27/27 [==============================] - 2s 84ms/step - loss: 34.7949 - accuracy: 0.9264 - val_loss: 44.7754 - val_accuracy: 0.9792\n","Epoch 10/50\n","27/27 [==============================] - 2s 89ms/step - loss: 31.1505 - accuracy: 0.9042 - val_loss: 42.9576 - val_accuracy: 0.9583\n","Epoch 11/50\n","27/27 [==============================] - 3s 104ms/step - loss: 28.1570 - accuracy: 0.9369 - val_loss: 44.2181 - val_accuracy: 0.9688\n","Epoch 12/50\n","27/27 [==============================] - 4s 147ms/step - loss: 25.8909 - accuracy: 0.9322 - val_loss: 45.3161 - val_accuracy: 0.9479\n","Epoch 13/50\n","27/27 [==============================] - 4s 158ms/step - loss: 25.3165 - accuracy: 0.9311 - val_loss: 48.9511 - val_accuracy: 0.9688\n","Epoch 14/50\n","27/27 [==============================] - 2s 85ms/step - loss: 24.6508 - accuracy: 0.9439 - val_loss: 48.7817 - val_accuracy: 0.9479\n","Epoch 15/50\n","27/27 [==============================] - 2s 87ms/step - loss: 23.2376 - accuracy: 0.9533 - val_loss: 49.7040 - val_accuracy: 0.9479\n","Epoch 16/50\n","27/27 [==============================] - 2s 85ms/step - loss: 22.9690 - accuracy: 0.9614 - val_loss: 44.6970 - val_accuracy: 0.9583\n","Epoch 17/50\n","27/27 [==============================] - 2s 88ms/step - loss: 22.2931 - accuracy: 0.9626 - val_loss: 49.5124 - val_accuracy: 0.9375\n","Epoch 18/50\n","27/27 [==============================] - 3s 119ms/step - loss: 21.8060 - accuracy: 0.9650 - val_loss: 47.5097 - val_accuracy: 0.9688\n","Epoch 19/50\n","27/27 [==============================] - 3s 120ms/step - loss: 23.4969 - accuracy: 0.9614 - val_loss: 47.7848 - val_accuracy: 0.9792\n","Epoch 20/50\n","27/27 [==============================] - 2s 84ms/step - loss: 18.2827 - accuracy: 0.9743 - val_loss: 47.0526 - val_accuracy: 0.9271\n","Epoch 21/50\n","27/27 [==============================] - 2s 85ms/step - loss: 17.8794 - accuracy: 0.9685 - val_loss: 56.6998 - val_accuracy: 0.9688\n","Epoch 22/50\n","27/27 [==============================] - 2s 89ms/step - loss: 18.7935 - accuracy: 0.9685 - val_loss: 55.6754 - val_accuracy: 0.9271\n","Epoch 23/50\n","27/27 [==============================] - 2s 86ms/step - loss: 16.6430 - accuracy: 0.9685 - val_loss: 47.1607 - val_accuracy: 0.9583\n","Epoch 24/50\n","27/27 [==============================] - 3s 123ms/step - loss: 16.0971 - accuracy: 0.9755 - val_loss: 54.0588 - val_accuracy: 0.9062\n","Epoch 25/50\n","27/27 [==============================] - 3s 112ms/step - loss: 15.1565 - accuracy: 0.9544 - val_loss: 46.0780 - val_accuracy: 0.9583\n","Epoch 26/50\n","27/27 [==============================] - 2s 86ms/step - loss: 16.2013 - accuracy: 0.9568 - val_loss: 44.2591 - val_accuracy: 0.8333\n","Epoch 27/50\n","27/27 [==============================] - 2s 85ms/step - loss: 15.1442 - accuracy: 0.9638 - val_loss: 49.2031 - val_accuracy: 0.9583\n","Epoch 28/50\n","27/27 [==============================] - 2s 88ms/step - loss: 15.7773 - accuracy: 0.9579 - val_loss: 45.0521 - val_accuracy: 0.9896\n","Epoch 29/50\n","27/27 [==============================] - 2s 91ms/step - loss: 14.3175 - accuracy: 0.9661 - val_loss: 44.4309 - val_accuracy: 0.9792\n","Epoch 30/50\n","27/27 [==============================] - 3s 116ms/step - loss: 13.8636 - accuracy: 0.9731 - val_loss: 44.6502 - val_accuracy: 0.9792\n","Epoch 31/50\n","27/27 [==============================] - 3s 113ms/step - loss: 13.1083 - accuracy: 0.9755 - val_loss: 44.1435 - val_accuracy: 0.9896\n","Epoch 32/50\n","27/27 [==============================] - 2s 88ms/step - loss: 12.8953 - accuracy: 0.9755 - val_loss: 44.3499 - val_accuracy: 0.9792\n","Epoch 33/50\n","27/27 [==============================] - 2s 87ms/step - loss: 12.8119 - accuracy: 0.9720 - val_loss: 45.1242 - val_accuracy: 0.9792\n","Epoch 34/50\n","27/27 [==============================] - 2s 88ms/step - loss: 13.2725 - accuracy: 0.9708 - val_loss: 47.2671 - val_accuracy: 0.9688\n","Epoch 35/50\n","27/27 [==============================] - 3s 100ms/step - loss: 13.6288 - accuracy: 0.9766 - val_loss: 43.2837 - val_accuracy: 0.9792\n","Epoch 36/50\n","27/27 [==============================] - 3s 126ms/step - loss: 13.5124 - accuracy: 0.9521 - val_loss: 46.2545 - val_accuracy: 0.9792\n","Epoch 37/50\n","27/27 [==============================] - 3s 91ms/step - loss: 12.8019 - accuracy: 0.9720 - val_loss: 45.0531 - val_accuracy: 0.9792\n","Epoch 38/50\n","27/27 [==============================] - 2s 88ms/step - loss: 12.4406 - accuracy: 0.9755 - val_loss: 43.3169 - val_accuracy: 0.9792\n","Epoch 39/50\n","27/27 [==============================] - 2s 84ms/step - loss: 12.0729 - accuracy: 0.9766 - val_loss: 45.1459 - val_accuracy: 0.9688\n","Epoch 40/50\n","27/27 [==============================] - 2s 86ms/step - loss: 11.9964 - accuracy: 0.9766 - val_loss: 43.7218 - val_accuracy: 0.9792\n","Epoch 41/50\n","27/27 [==============================] - 3s 103ms/step - loss: 12.1875 - accuracy: 0.9743 - val_loss: 45.2910 - val_accuracy: 0.9792\n","Epoch 42/50\n","27/27 [==============================] - 3s 119ms/step - loss: 12.0336 - accuracy: 0.9778 - val_loss: 44.4403 - val_accuracy: 0.9792\n","Epoch 43/50\n","27/27 [==============================] - 2s 87ms/step - loss: 11.8652 - accuracy: 0.9790 - val_loss: 47.2960 - val_accuracy: 0.9688\n","Epoch 44/50\n","27/27 [==============================] - 2s 88ms/step - loss: 11.8038 - accuracy: 0.9790 - val_loss: 47.7803 - val_accuracy: 0.9896\n","Epoch 45/50\n","27/27 [==============================] - 2s 85ms/step - loss: 11.8464 - accuracy: 0.9766 - val_loss: 47.4029 - val_accuracy: 0.9792\n","Epoch 46/50\n","27/27 [==============================] - 2s 82ms/step - loss: 12.0317 - accuracy: 0.9778 - val_loss: 45.0217 - val_accuracy: 0.9792\n","Epoch 47/50\n","27/27 [==============================] - 3s 115ms/step - loss: 12.1542 - accuracy: 0.9743 - val_loss: 44.1227 - val_accuracy: 0.9896\n","Epoch 48/50\n","27/27 [==============================] - 3s 123ms/step - loss: 12.3009 - accuracy: 0.9790 - val_loss: 45.7720 - val_accuracy: 0.9792\n","Epoch 49/50\n","27/27 [==============================] - 2s 85ms/step - loss: 11.9768 - accuracy: 0.9778 - val_loss: 47.0364 - val_accuracy: 0.9688\n","Epoch 50/50\n","27/27 [==============================] - 2s 86ms/step - loss: 11.7336 - accuracy: 0.9778 - val_loss: 49.0750 - val_accuracy: 0.9896\n","8/8 [==============================] - 0s 15ms/step\n","8/8 [==============================] - 0s 17ms/step - loss: 528.2846 - accuracy: 1.0000\n","Test Loss: 528.2846, Test accuracy : 1.0000\n","Epoch 1/50\n","27/27 [==============================] - 4s 101ms/step - loss: 100.0971 - accuracy: 0.1554 - val_loss: 64.4431 - val_accuracy: 0.2083\n","Epoch 2/50\n","27/27 [==============================] - 2s 79ms/step - loss: 60.4456 - accuracy: 0.1157 - val_loss: 60.2730 - val_accuracy: 0.5833\n","Epoch 3/50\n","27/27 [==============================] - 2s 81ms/step - loss: 57.4232 - accuracy: 0.6227 - val_loss: 60.4687 - val_accuracy: 0.6146\n","Epoch 4/50\n","27/27 [==============================] - 2s 80ms/step - loss: 55.6106 - accuracy: 0.6133 - val_loss: 59.3542 - val_accuracy: 0.6250\n","Epoch 5/50\n","27/27 [==============================] - 2s 90ms/step - loss: 54.1451 - accuracy: 0.6121 - val_loss: 58.0023 - val_accuracy: 0.5104\n","Epoch 6/50\n","27/27 [==============================] - 3s 105ms/step - loss: 49.5759 - accuracy: 0.6250 - val_loss: 54.2829 - val_accuracy: 0.6042\n","Epoch 7/50\n","27/27 [==============================] - 2s 89ms/step - loss: 43.9866 - accuracy: 0.5864 - val_loss: 53.0443 - val_accuracy: 0.5208\n","Epoch 8/50\n","27/27 [==============================] - 2s 81ms/step - loss: 37.8416 - accuracy: 0.5748 - val_loss: 53.6870 - val_accuracy: 0.4583\n","Epoch 9/50\n","27/27 [==============================] - 2s 83ms/step - loss: 33.2520 - accuracy: 0.5678 - val_loss: 50.7064 - val_accuracy: 0.6146\n","Epoch 10/50\n","27/27 [==============================] - 2s 78ms/step - loss: 28.7884 - accuracy: 0.6086 - val_loss: 57.5103 - val_accuracy: 0.5000\n","Epoch 11/50\n","27/27 [==============================] - 2s 79ms/step - loss: 25.6604 - accuracy: 0.6308 - val_loss: 54.1143 - val_accuracy: 0.5625\n","Epoch 12/50\n","27/27 [==============================] - 3s 108ms/step - loss: 22.7107 - accuracy: 0.6005 - val_loss: 55.8875 - val_accuracy: 0.5521\n","Epoch 13/50\n","27/27 [==============================] - 3s 106ms/step - loss: 22.0931 - accuracy: 0.6168 - val_loss: 55.7773 - val_accuracy: 0.5625\n","Epoch 14/50\n","27/27 [==============================] - 2s 80ms/step - loss: 18.8166 - accuracy: 0.6203 - val_loss: 52.7720 - val_accuracy: 0.6042\n","Epoch 15/50\n","27/27 [==============================] - 2s 79ms/step - loss: 17.1918 - accuracy: 0.6402 - val_loss: 55.5383 - val_accuracy: 0.6146\n","Epoch 16/50\n","27/27 [==============================] - 2s 82ms/step - loss: 16.7734 - accuracy: 0.6530 - val_loss: 53.6055 - val_accuracy: 0.6250\n","Epoch 17/50\n","27/27 [==============================] - 2s 83ms/step - loss: 16.4130 - accuracy: 0.6495 - val_loss: 54.1865 - val_accuracy: 0.6146\n","Epoch 18/50\n","27/27 [==============================] - 3s 98ms/step - loss: 16.7766 - accuracy: 0.6484 - val_loss: 57.2671 - val_accuracy: 0.5729\n","Epoch 19/50\n","27/27 [==============================] - 3s 116ms/step - loss: 15.3563 - accuracy: 0.6600 - val_loss: 53.6243 - val_accuracy: 0.6250\n","Epoch 20/50\n","27/27 [==============================] - 2s 85ms/step - loss: 15.1209 - accuracy: 0.6577 - val_loss: 54.5303 - val_accuracy: 0.6146\n","Epoch 21/50\n","27/27 [==============================] - 2s 81ms/step - loss: 14.3941 - accuracy: 0.6717 - val_loss: 55.7057 - val_accuracy: 0.6042\n","Epoch 22/50\n","27/27 [==============================] - 2s 81ms/step - loss: 13.6054 - accuracy: 0.6636 - val_loss: 55.0154 - val_accuracy: 0.6042\n","Epoch 23/50\n","27/27 [==============================] - 2s 83ms/step - loss: 13.5687 - accuracy: 0.6717 - val_loss: 55.5734 - val_accuracy: 0.6250\n","Epoch 24/50\n","27/27 [==============================] - 3s 93ms/step - loss: 13.5314 - accuracy: 0.6776 - val_loss: 55.9375 - val_accuracy: 0.5938\n","Epoch 25/50\n","27/27 [==============================] - 3s 106ms/step - loss: 13.1618 - accuracy: 0.6717 - val_loss: 55.4922 - val_accuracy: 0.6250\n","Epoch 26/50\n","27/27 [==============================] - 3s 99ms/step - loss: 13.1256 - accuracy: 0.6799 - val_loss: 56.7329 - val_accuracy: 0.5938\n","Epoch 27/50\n","27/27 [==============================] - 2s 80ms/step - loss: 12.7609 - accuracy: 0.6776 - val_loss: 54.4923 - val_accuracy: 0.6042\n","Epoch 28/50\n","27/27 [==============================] - 2s 80ms/step - loss: 12.1842 - accuracy: 0.6729 - val_loss: 55.3691 - val_accuracy: 0.5729\n","Epoch 29/50\n","27/27 [==============================] - 2s 79ms/step - loss: 11.9372 - accuracy: 0.6857 - val_loss: 55.1723 - val_accuracy: 0.5417\n","Epoch 30/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.5699 - accuracy: 0.6846 - val_loss: 55.7557 - val_accuracy: 0.4792\n","Epoch 31/50\n","27/27 [==============================] - 3s 112ms/step - loss: 11.3890 - accuracy: 0.6752 - val_loss: 55.5627 - val_accuracy: 0.4792\n","Epoch 32/50\n","27/27 [==============================] - 3s 108ms/step - loss: 11.4519 - accuracy: 0.6647 - val_loss: 55.9288 - val_accuracy: 0.4896\n","Epoch 33/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.3065 - accuracy: 0.6612 - val_loss: 57.0399 - val_accuracy: 0.4583\n","Epoch 34/50\n","27/27 [==============================] - 2s 79ms/step - loss: 11.3569 - accuracy: 0.6636 - val_loss: 55.5066 - val_accuracy: 0.4583\n","Epoch 35/50\n","27/27 [==============================] - 2s 79ms/step - loss: 11.3699 - accuracy: 0.6612 - val_loss: 56.5850 - val_accuracy: 0.4583\n","Epoch 36/50\n","27/27 [==============================] - 2s 80ms/step - loss: 11.9130 - accuracy: 0.6554 - val_loss: 56.6102 - val_accuracy: 0.4583\n","Epoch 37/50\n","27/27 [==============================] - 2s 91ms/step - loss: 12.5949 - accuracy: 0.6565 - val_loss: 56.4078 - val_accuracy: 0.4688\n","Epoch 38/50\n","27/27 [==============================] - 3s 104ms/step - loss: 13.0456 - accuracy: 0.6542 - val_loss: 55.9948 - val_accuracy: 0.4479\n","Epoch 39/50\n","27/27 [==============================] - 3s 102ms/step - loss: 13.0584 - accuracy: 0.6484 - val_loss: 57.8836 - val_accuracy: 0.4375\n","Epoch 40/50\n","27/27 [==============================] - 2s 81ms/step - loss: 13.1723 - accuracy: 0.6507 - val_loss: 58.1710 - val_accuracy: 0.4479\n","Epoch 41/50\n","27/27 [==============================] - 2s 80ms/step - loss: 13.4968 - accuracy: 0.6624 - val_loss: 58.3005 - val_accuracy: 0.4479\n","Epoch 42/50\n","27/27 [==============================] - 2s 78ms/step - loss: 13.4313 - accuracy: 0.6565 - val_loss: 56.1129 - val_accuracy: 0.4896\n","Epoch 43/50\n","27/27 [==============================] - 2s 80ms/step - loss: 12.9176 - accuracy: 0.6449 - val_loss: 58.9799 - val_accuracy: 0.4583\n","Epoch 44/50\n","27/27 [==============================] - 3s 102ms/step - loss: 12.9704 - accuracy: 0.6682 - val_loss: 56.0998 - val_accuracy: 0.4375\n","Epoch 45/50\n","27/27 [==============================] - 3s 115ms/step - loss: 13.3565 - accuracy: 0.6495 - val_loss: 58.3246 - val_accuracy: 0.4167\n","Epoch 46/50\n","27/27 [==============================] - 3s 114ms/step - loss: 13.6484 - accuracy: 0.6519 - val_loss: 56.3062 - val_accuracy: 0.4896\n","Epoch 47/50\n","27/27 [==============================] - 3s 105ms/step - loss: 13.5740 - accuracy: 0.6507 - val_loss: 58.9344 - val_accuracy: 0.4375\n","Epoch 48/50\n","27/27 [==============================] - 2s 80ms/step - loss: 13.2791 - accuracy: 0.6507 - val_loss: 60.3586 - val_accuracy: 0.4792\n","Epoch 49/50\n","27/27 [==============================] - 2s 81ms/step - loss: 12.7796 - accuracy: 0.6799 - val_loss: 59.7015 - val_accuracy: 0.4375\n","Epoch 50/50\n","27/27 [==============================] - 3s 108ms/step - loss: 12.4073 - accuracy: 0.6542 - val_loss: 58.7242 - val_accuracy: 0.4792\n","8/8 [==============================] - 0s 14ms/step\n","8/8 [==============================] - 0s 15ms/step - loss: 386.9288 - accuracy: 0.8542\n","Test Loss: 386.9288, Test accuracy : 0.8542\n","Epoch 1/50\n","27/27 [==============================] - 3s 89ms/step - loss: 55.9547 - accuracy: 0.1297 - val_loss: 45.3467 - val_accuracy: 0.1562\n","Epoch 2/50\n","27/27 [==============================] - 3s 107ms/step - loss: 38.3855 - accuracy: 0.1332 - val_loss: 44.1465 - val_accuracy: 0.1562\n","Epoch 3/50\n","27/27 [==============================] - 3s 115ms/step - loss: 37.5364 - accuracy: 0.1425 - val_loss: 42.8008 - val_accuracy: 0.1250\n","Epoch 4/50\n","27/27 [==============================] - 2s 81ms/step - loss: 36.6400 - accuracy: 0.1402 - val_loss: 42.8909 - val_accuracy: 0.0938\n","Epoch 5/50\n","27/27 [==============================] - 2s 81ms/step - loss: 35.7909 - accuracy: 0.1402 - val_loss: 41.4980 - val_accuracy: 0.1354\n","Epoch 6/50\n","27/27 [==============================] - 2s 81ms/step - loss: 34.6633 - accuracy: 0.2699 - val_loss: 41.1138 - val_accuracy: 0.7917\n","Epoch 7/50\n","27/27 [==============================] - 2s 82ms/step - loss: 33.7388 - accuracy: 0.7629 - val_loss: 42.2075 - val_accuracy: 0.6562\n","Epoch 8/50\n","27/27 [==============================] - 3s 100ms/step - loss: 33.0645 - accuracy: 0.7582 - val_loss: 41.6743 - val_accuracy: 0.7500\n","Epoch 9/50\n","27/27 [==============================] - 3s 120ms/step - loss: 32.7453 - accuracy: 0.7699 - val_loss: 43.3281 - val_accuracy: 0.4896\n","Epoch 10/50\n","27/27 [==============================] - 2s 86ms/step - loss: 30.6082 - accuracy: 0.7488 - val_loss: 42.5150 - val_accuracy: 0.6771\n","Epoch 11/50\n","27/27 [==============================] - 2s 80ms/step - loss: 29.5096 - accuracy: 0.7512 - val_loss: 41.9453 - val_accuracy: 0.5521\n","Epoch 12/50\n","27/27 [==============================] - 2s 80ms/step - loss: 28.7704 - accuracy: 0.7348 - val_loss: 41.8677 - val_accuracy: 0.5729\n","Epoch 13/50\n","27/27 [==============================] - 2s 81ms/step - loss: 27.9111 - accuracy: 0.7407 - val_loss: 40.1058 - val_accuracy: 0.6458\n","Epoch 14/50\n","27/27 [==============================] - 3s 100ms/step - loss: 27.6595 - accuracy: 0.7220 - val_loss: 40.1093 - val_accuracy: 0.6667\n","Epoch 15/50\n","27/27 [==============================] - 3s 118ms/step - loss: 27.0356 - accuracy: 0.7278 - val_loss: 41.9620 - val_accuracy: 0.5417\n","Epoch 16/50\n","27/27 [==============================] - 2s 86ms/step - loss: 26.3479 - accuracy: 0.7442 - val_loss: 42.8014 - val_accuracy: 0.5208\n","Epoch 17/50\n","27/27 [==============================] - 2s 81ms/step - loss: 25.3209 - accuracy: 0.7395 - val_loss: 42.5669 - val_accuracy: 0.5417\n","Epoch 18/50\n","27/27 [==============================] - 2s 81ms/step - loss: 24.5717 - accuracy: 0.7407 - val_loss: 42.8514 - val_accuracy: 0.5000\n","Epoch 19/50\n","27/27 [==============================] - 2s 84ms/step - loss: 24.8478 - accuracy: 0.7395 - val_loss: 41.4863 - val_accuracy: 0.5625\n","Epoch 20/50\n","27/27 [==============================] - 3s 102ms/step - loss: 24.6804 - accuracy: 0.7500 - val_loss: 41.4843 - val_accuracy: 0.5417\n","Epoch 21/50\n","27/27 [==============================] - 3s 112ms/step - loss: 24.5616 - accuracy: 0.7430 - val_loss: 43.2128 - val_accuracy: 0.4271\n","Epoch 22/50\n","27/27 [==============================] - 2s 88ms/step - loss: 24.0845 - accuracy: 0.7465 - val_loss: 42.9428 - val_accuracy: 0.4583\n","Epoch 23/50\n","27/27 [==============================] - 2s 81ms/step - loss: 23.8715 - accuracy: 0.7570 - val_loss: 42.1032 - val_accuracy: 0.5208\n","Epoch 24/50\n","27/27 [==============================] - 2s 82ms/step - loss: 24.0357 - accuracy: 0.7605 - val_loss: 46.9860 - val_accuracy: 0.4062\n","Epoch 25/50\n","27/27 [==============================] - 2s 82ms/step - loss: 24.5764 - accuracy: 0.7582 - val_loss: 42.8905 - val_accuracy: 0.4479\n","Epoch 26/50\n","27/27 [==============================] - 2s 87ms/step - loss: 24.6785 - accuracy: 0.7687 - val_loss: 40.4280 - val_accuracy: 0.5521\n","Epoch 27/50\n","27/27 [==============================] - 3s 127ms/step - loss: 23.6256 - accuracy: 0.7757 - val_loss: 40.8917 - val_accuracy: 0.5625\n","Epoch 28/50\n","27/27 [==============================] - 3s 98ms/step - loss: 23.5596 - accuracy: 0.7629 - val_loss: 40.6378 - val_accuracy: 0.5938\n","Epoch 29/50\n","27/27 [==============================] - 2s 84ms/step - loss: 23.4202 - accuracy: 0.7874 - val_loss: 42.9946 - val_accuracy: 0.5208\n","Epoch 30/50\n","27/27 [==============================] - 2s 84ms/step - loss: 23.1231 - accuracy: 0.7850 - val_loss: 40.5994 - val_accuracy: 0.5938\n","Epoch 31/50\n","27/27 [==============================] - 2s 80ms/step - loss: 22.9165 - accuracy: 0.7967 - val_loss: 40.0029 - val_accuracy: 0.6354\n","Epoch 32/50\n","27/27 [==============================] - 2s 83ms/step - loss: 22.9389 - accuracy: 0.7897 - val_loss: 40.6156 - val_accuracy: 0.5938\n","Epoch 33/50\n","27/27 [==============================] - 3s 110ms/step - loss: 23.1473 - accuracy: 0.7956 - val_loss: 41.9733 - val_accuracy: 0.5729\n","Epoch 34/50\n","27/27 [==============================] - 3s 113ms/step - loss: 23.0789 - accuracy: 0.7944 - val_loss: 39.8972 - val_accuracy: 0.6562\n","Epoch 35/50\n","27/27 [==============================] - 2s 81ms/step - loss: 23.1138 - accuracy: 0.8107 - val_loss: 39.2712 - val_accuracy: 0.7604\n","Epoch 36/50\n","27/27 [==============================] - 2s 82ms/step - loss: 22.9566 - accuracy: 0.8119 - val_loss: 41.0719 - val_accuracy: 0.7917\n","Epoch 37/50\n","27/27 [==============================] - 2s 83ms/step - loss: 23.0169 - accuracy: 0.8143 - val_loss: 39.9593 - val_accuracy: 0.7708\n","Epoch 38/50\n","27/27 [==============================] - 2s 83ms/step - loss: 22.8289 - accuracy: 0.7944 - val_loss: 39.7204 - val_accuracy: 0.8229\n","Epoch 39/50\n","27/27 [==============================] - 3s 102ms/step - loss: 22.5898 - accuracy: 0.8084 - val_loss: 41.1396 - val_accuracy: 0.7917\n","Epoch 40/50\n","27/27 [==============================] - 3s 119ms/step - loss: 23.2083 - accuracy: 0.8026 - val_loss: 41.8099 - val_accuracy: 0.8229\n","Epoch 41/50\n","27/27 [==============================] - 2s 81ms/step - loss: 23.5565 - accuracy: 0.7932 - val_loss: 40.9200 - val_accuracy: 0.8229\n","Epoch 42/50\n","27/27 [==============================] - 2s 79ms/step - loss: 22.9620 - accuracy: 0.7944 - val_loss: 40.8851 - val_accuracy: 0.8229\n","Epoch 43/50\n","27/27 [==============================] - 2s 82ms/step - loss: 22.1983 - accuracy: 0.7932 - val_loss: 38.3297 - val_accuracy: 0.8229\n","Epoch 44/50\n","27/27 [==============================] - 2s 81ms/step - loss: 23.5528 - accuracy: 0.7944 - val_loss: 39.5802 - val_accuracy: 0.8229\n","Epoch 45/50\n","27/27 [==============================] - 2s 90ms/step - loss: 21.8201 - accuracy: 0.7944 - val_loss: 40.7873 - val_accuracy: 0.8229\n","Epoch 46/50\n","27/27 [==============================] - 3s 115ms/step - loss: 21.6874 - accuracy: 0.7944 - val_loss: 40.7269 - val_accuracy: 0.8229\n","Epoch 47/50\n","27/27 [==============================] - 3s 97ms/step - loss: 22.1364 - accuracy: 0.7932 - val_loss: 37.8263 - val_accuracy: 0.8229\n","Epoch 48/50\n","27/27 [==============================] - 2s 82ms/step - loss: 22.1861 - accuracy: 0.7944 - val_loss: 41.2511 - val_accuracy: 0.8229\n","Epoch 49/50\n","27/27 [==============================] - 2s 85ms/step - loss: 22.3942 - accuracy: 0.7944 - val_loss: 41.4013 - val_accuracy: 0.8229\n","Epoch 50/50\n","27/27 [==============================] - 2s 82ms/step - loss: 21.8159 - accuracy: 0.7932 - val_loss: 41.0767 - val_accuracy: 0.8229\n","8/8 [==============================] - 0s 15ms/step\n","8/8 [==============================] - 0s 17ms/step - loss: 421.5266 - accuracy: 1.0000\n","Test Loss: 421.5266, Test accuracy : 1.0000\n","Epoch 1/50\n","27/27 [==============================] - 4s 124ms/step - loss: 75.7618 - accuracy: 0.2138 - val_loss: 57.8735 - val_accuracy: 0.1979\n","Epoch 2/50\n","27/27 [==============================] - 3s 110ms/step - loss: 58.5893 - accuracy: 0.2173 - val_loss: 57.1514 - val_accuracy: 0.2812\n","Epoch 3/50\n","27/27 [==============================] - 3s 105ms/step - loss: 51.7056 - accuracy: 0.1846 - val_loss: 55.0092 - val_accuracy: 0.0729\n","Epoch 4/50\n","27/27 [==============================] - 3s 123ms/step - loss: 44.3708 - accuracy: 0.1741 - val_loss: 54.8890 - val_accuracy: 0.1667\n","Epoch 5/50\n","27/27 [==============================] - 3s 127ms/step - loss: 38.7609 - accuracy: 0.2126 - val_loss: 53.0236 - val_accuracy: 0.2083\n","Epoch 6/50\n","27/27 [==============================] - 3s 93ms/step - loss: 35.6945 - accuracy: 0.2231 - val_loss: 51.5998 - val_accuracy: 0.1354\n","Epoch 7/50\n","27/27 [==============================] - 2s 85ms/step - loss: 30.9767 - accuracy: 0.2699 - val_loss: 51.8273 - val_accuracy: 0.2083\n","Epoch 8/50\n","27/27 [==============================] - 2s 82ms/step - loss: 28.6094 - accuracy: 0.3213 - val_loss: 51.8034 - val_accuracy: 0.2708\n","Epoch 9/50\n","27/27 [==============================] - 2s 87ms/step - loss: 25.7596 - accuracy: 0.3470 - val_loss: 52.4290 - val_accuracy: 0.2396\n","Epoch 10/50\n","27/27 [==============================] - 3s 107ms/step - loss: 23.7812 - accuracy: 0.3446 - val_loss: 51.8389 - val_accuracy: 0.2188\n","Epoch 11/50\n","27/27 [==============================] - 3s 121ms/step - loss: 22.4081 - accuracy: 0.3435 - val_loss: 53.3866 - val_accuracy: 0.2708\n","Epoch 12/50\n","27/27 [==============================] - 2s 90ms/step - loss: 20.2113 - accuracy: 0.3353 - val_loss: 52.8841 - val_accuracy: 0.2396\n","Epoch 13/50\n","27/27 [==============================] - 2s 85ms/step - loss: 18.9634 - accuracy: 0.3294 - val_loss: 55.4198 - val_accuracy: 0.2604\n","Epoch 14/50\n","27/27 [==============================] - 2s 84ms/step - loss: 17.9111 - accuracy: 0.3248 - val_loss: 53.5324 - val_accuracy: 0.2604\n","Epoch 15/50\n","27/27 [==============================] - 2s 88ms/step - loss: 16.9627 - accuracy: 0.3329 - val_loss: 54.3731 - val_accuracy: 0.2604\n","Epoch 16/50\n","27/27 [==============================] - 3s 107ms/step - loss: 16.5561 - accuracy: 0.3259 - val_loss: 54.9100 - val_accuracy: 0.2812\n","Epoch 17/50\n","27/27 [==============================] - 3s 124ms/step - loss: 16.6568 - accuracy: 0.3259 - val_loss: 54.5154 - val_accuracy: 0.2604\n","Epoch 18/50\n","27/27 [==============================] - 3s 92ms/step - loss: 16.8476 - accuracy: 0.3213 - val_loss: 56.6163 - val_accuracy: 0.2500\n","Epoch 19/50\n","27/27 [==============================] - 2s 85ms/step - loss: 17.9233 - accuracy: 0.2862 - val_loss: 55.4662 - val_accuracy: 0.2292\n","Epoch 20/50\n","27/27 [==============================] - 2s 83ms/step - loss: 18.5138 - accuracy: 0.2734 - val_loss: 52.1925 - val_accuracy: 0.2604\n","Epoch 21/50\n","27/27 [==============================] - 2s 88ms/step - loss: 16.9532 - accuracy: 0.2640 - val_loss: 53.9735 - val_accuracy: 0.2292\n","Epoch 22/50\n","27/27 [==============================] - 3s 101ms/step - loss: 16.2132 - accuracy: 0.2769 - val_loss: 54.3814 - val_accuracy: 0.1875\n","Epoch 23/50\n","27/27 [==============================] - 3s 123ms/step - loss: 15.6341 - accuracy: 0.2664 - val_loss: 53.5377 - val_accuracy: 0.2292\n","Epoch 24/50\n","27/27 [==============================] - 3s 94ms/step - loss: 15.4434 - accuracy: 0.2722 - val_loss: 53.6312 - val_accuracy: 0.1979\n","Epoch 25/50\n","27/27 [==============================] - 2s 89ms/step - loss: 15.4757 - accuracy: 0.2582 - val_loss: 53.8287 - val_accuracy: 0.1667\n","Epoch 26/50\n","27/27 [==============================] - 2s 85ms/step - loss: 15.5484 - accuracy: 0.2792 - val_loss: 53.3410 - val_accuracy: 0.2292\n","Epoch 27/50\n","27/27 [==============================] - 2s 92ms/step - loss: 14.9718 - accuracy: 0.2792 - val_loss: 54.1876 - val_accuracy: 0.2500\n","Epoch 28/50\n","27/27 [==============================] - 3s 127ms/step - loss: 15.0210 - accuracy: 0.2804 - val_loss: 54.2842 - val_accuracy: 0.2083\n","Epoch 29/50\n","27/27 [==============================] - 3s 127ms/step - loss: 14.6974 - accuracy: 0.2734 - val_loss: 54.4734 - val_accuracy: 0.2188\n","Epoch 30/50\n","27/27 [==============================] - 3s 97ms/step - loss: 14.1731 - accuracy: 0.2804 - val_loss: 54.1732 - val_accuracy: 0.2292\n","Epoch 31/50\n","27/27 [==============================] - 3s 98ms/step - loss: 14.2065 - accuracy: 0.2792 - val_loss: 53.0010 - val_accuracy: 0.2188\n","Epoch 32/50\n","27/27 [==============================] - 3s 98ms/step - loss: 14.6413 - accuracy: 0.2897 - val_loss: 52.9646 - val_accuracy: 0.2500\n","Epoch 33/50\n","27/27 [==============================] - 3s 129ms/step - loss: 14.3402 - accuracy: 0.2815 - val_loss: 55.2281 - val_accuracy: 0.2083\n","Epoch 34/50\n","27/27 [==============================] - 4s 131ms/step - loss: 14.3420 - accuracy: 0.2862 - val_loss: 54.4067 - val_accuracy: 0.2188\n","Epoch 35/50\n","27/27 [==============================] - 2s 89ms/step - loss: 14.0737 - accuracy: 0.2815 - val_loss: 53.8375 - val_accuracy: 0.2292\n","Epoch 36/50\n","27/27 [==============================] - 3s 121ms/step - loss: 13.8277 - accuracy: 0.2827 - val_loss: 53.5689 - val_accuracy: 0.1979\n","Epoch 37/50\n","27/27 [==============================] - 3s 107ms/step - loss: 13.6864 - accuracy: 0.2897 - val_loss: 54.5287 - val_accuracy: 0.2188\n","Epoch 38/50\n","27/27 [==============================] - 3s 109ms/step - loss: 13.7505 - accuracy: 0.2862 - val_loss: 55.8473 - val_accuracy: 0.2083\n","Epoch 39/50\n","27/27 [==============================] - 4s 143ms/step - loss: 14.0466 - accuracy: 0.2862 - val_loss: 55.3683 - val_accuracy: 0.2292\n","Epoch 40/50\n","27/27 [==============================] - 3s 102ms/step - loss: 13.9968 - accuracy: 0.2874 - val_loss: 53.5990 - val_accuracy: 0.2292\n","Epoch 41/50\n","27/27 [==============================] - 3s 94ms/step - loss: 13.7243 - accuracy: 0.2909 - val_loss: 55.5235 - val_accuracy: 0.1979\n","Epoch 42/50\n","27/27 [==============================] - 2s 91ms/step - loss: 13.5887 - accuracy: 0.3037 - val_loss: 53.9739 - val_accuracy: 0.2188\n","Epoch 43/50\n","27/27 [==============================] - 2s 86ms/step - loss: 13.5995 - accuracy: 0.3002 - val_loss: 54.0783 - val_accuracy: 0.2292\n","Epoch 44/50\n","27/27 [==============================] - 3s 117ms/step - loss: 13.8412 - accuracy: 0.3014 - val_loss: 54.3360 - val_accuracy: 0.1875\n","Epoch 45/50\n","27/27 [==============================] - 4s 134ms/step - loss: 14.2424 - accuracy: 0.2862 - val_loss: 54.4300 - val_accuracy: 0.2500\n","Epoch 46/50\n","27/27 [==============================] - 3s 102ms/step - loss: 14.0941 - accuracy: 0.2967 - val_loss: 53.7938 - val_accuracy: 0.2500\n","Epoch 47/50\n","27/27 [==============================] - 3s 121ms/step - loss: 13.8289 - accuracy: 0.2909 - val_loss: 55.5000 - val_accuracy: 0.2396\n","Epoch 48/50\n","27/27 [==============================] - 3s 93ms/step - loss: 13.6093 - accuracy: 0.3014 - val_loss: 52.7168 - val_accuracy: 0.2188\n","Epoch 49/50\n","27/27 [==============================] - 4s 141ms/step - loss: 13.6091 - accuracy: 0.3002 - val_loss: 55.1596 - val_accuracy: 0.2396\n","Epoch 50/50\n","27/27 [==============================] - 4s 131ms/step - loss: 13.5663 - accuracy: 0.2956 - val_loss: 52.6121 - val_accuracy: 0.2292\n","8/8 [==============================] - 0s 31ms/step\n","8/8 [==============================] - 0s 31ms/step - loss: 190.9882 - accuracy: 0.8625\n","Test Loss: 190.9882, Test accuracy : 0.8625\n","Epoch 1/50\n","27/27 [==============================] - 4s 107ms/step - loss: 132.6747 - accuracy: 0.2710 - val_loss: 91.2177 - val_accuracy: 0.6667\n","Epoch 2/50\n","27/27 [==============================] - 3s 127ms/step - loss: 68.4187 - accuracy: 0.6519 - val_loss: 78.5470 - val_accuracy: 0.7812\n","Epoch 3/50\n","27/27 [==============================] - 3s 116ms/step - loss: 66.3223 - accuracy: 0.6028 - val_loss: 95.3473 - val_accuracy: 0.5000\n","Epoch 4/50\n","27/27 [==============================] - 2s 90ms/step - loss: 62.8678 - accuracy: 0.6729 - val_loss: 82.5962 - val_accuracy: 0.6562\n","Epoch 5/50\n","27/27 [==============================] - 2s 91ms/step - loss: 60.9912 - accuracy: 0.6706 - val_loss: 90.4482 - val_accuracy: 0.2604\n","Epoch 6/50\n","27/27 [==============================] - 2s 91ms/step - loss: 57.7426 - accuracy: 0.6343 - val_loss: 76.9815 - val_accuracy: 0.4583\n","Epoch 7/50\n","27/27 [==============================] - 2s 90ms/step - loss: 54.3254 - accuracy: 0.5514 - val_loss: 86.8345 - val_accuracy: 0.3958\n","Epoch 8/50\n","27/27 [==============================] - 3s 121ms/step - loss: 48.5666 - accuracy: 0.5397 - val_loss: 81.1137 - val_accuracy: 0.4375\n","Epoch 9/50\n","27/27 [==============================] - 3s 128ms/step - loss: 43.8310 - accuracy: 0.5911 - val_loss: 77.6722 - val_accuracy: 0.6042\n","Epoch 10/50\n","27/27 [==============================] - 2s 92ms/step - loss: 39.1188 - accuracy: 0.6308 - val_loss: 86.3665 - val_accuracy: 0.5833\n","Epoch 11/50\n","27/27 [==============================] - 3s 109ms/step - loss: 37.2890 - accuracy: 0.5946 - val_loss: 85.1218 - val_accuracy: 0.6771\n","Epoch 12/50\n","27/27 [==============================] - 2s 90ms/step - loss: 33.4603 - accuracy: 0.6005 - val_loss: 91.4107 - val_accuracy: 0.5729\n","Epoch 13/50\n","27/27 [==============================] - 3s 119ms/step - loss: 31.5432 - accuracy: 0.6636 - val_loss: 88.5709 - val_accuracy: 0.6250\n","Epoch 14/50\n","27/27 [==============================] - 4s 133ms/step - loss: 29.5112 - accuracy: 0.7103 - val_loss: 86.1130 - val_accuracy: 0.7188\n","Epoch 15/50\n","27/27 [==============================] - 3s 109ms/step - loss: 27.7126 - accuracy: 0.7336 - val_loss: 86.6843 - val_accuracy: 0.7083\n","Epoch 16/50\n","27/27 [==============================] - 3s 93ms/step - loss: 26.7608 - accuracy: 0.7710 - val_loss: 86.5345 - val_accuracy: 0.7708\n","Epoch 17/50\n","27/27 [==============================] - 3s 109ms/step - loss: 25.4847 - accuracy: 0.8014 - val_loss: 83.4244 - val_accuracy: 0.8125\n","Epoch 18/50\n","27/27 [==============================] - 3s 108ms/step - loss: 24.7107 - accuracy: 0.7944 - val_loss: 86.2738 - val_accuracy: 0.8125\n","Epoch 19/50\n","27/27 [==============================] - 4s 144ms/step - loss: 24.0814 - accuracy: 0.7862 - val_loss: 82.2649 - val_accuracy: 0.8125\n","Epoch 20/50\n","27/27 [==============================] - 3s 107ms/step - loss: 23.8002 - accuracy: 0.7815 - val_loss: 86.7232 - val_accuracy: 0.8125\n","Epoch 21/50\n","27/27 [==============================] - 3s 92ms/step - loss: 23.4502 - accuracy: 0.7827 - val_loss: 79.6030 - val_accuracy: 0.8021\n","Epoch 22/50\n","27/27 [==============================] - 3s 98ms/step - loss: 23.1235 - accuracy: 0.7827 - val_loss: 83.3934 - val_accuracy: 0.8021\n","Epoch 23/50\n","27/27 [==============================] - 3s 113ms/step - loss: 22.8022 - accuracy: 0.7897 - val_loss: 82.8184 - val_accuracy: 0.8021\n","Epoch 24/50\n","27/27 [==============================] - 4s 148ms/step - loss: 22.6197 - accuracy: 0.7815 - val_loss: 83.4553 - val_accuracy: 0.8021\n","Epoch 25/50\n","27/27 [==============================] - 3s 127ms/step - loss: 22.4377 - accuracy: 0.7839 - val_loss: 81.0021 - val_accuracy: 0.7917\n","Epoch 26/50\n","27/27 [==============================] - 3s 104ms/step - loss: 22.2843 - accuracy: 0.7804 - val_loss: 79.3403 - val_accuracy: 0.7917\n","Epoch 27/50\n","27/27 [==============================] - 3s 111ms/step - loss: 22.1558 - accuracy: 0.7722 - val_loss: 82.0769 - val_accuracy: 0.8021\n","Epoch 28/50\n","27/27 [==============================] - 4s 136ms/step - loss: 21.9279 - accuracy: 0.7862 - val_loss: 81.1953 - val_accuracy: 0.7917\n","Epoch 29/50\n","27/27 [==============================] - 4s 143ms/step - loss: 22.2385 - accuracy: 0.7815 - val_loss: 79.2806 - val_accuracy: 0.7917\n","Epoch 30/50\n","27/27 [==============================] - 4s 130ms/step - loss: 22.8592 - accuracy: 0.7850 - val_loss: 83.0294 - val_accuracy: 0.7917\n","Epoch 31/50\n","27/27 [==============================] - 3s 123ms/step - loss: 23.0935 - accuracy: 0.7886 - val_loss: 72.2826 - val_accuracy: 0.7917\n","Epoch 32/50\n","27/27 [==============================] - 3s 109ms/step - loss: 23.4740 - accuracy: 0.7932 - val_loss: 81.7195 - val_accuracy: 0.8021\n","Epoch 33/50\n","27/27 [==============================] - 4s 135ms/step - loss: 22.3481 - accuracy: 0.7827 - val_loss: 75.2104 - val_accuracy: 0.7917\n","Epoch 34/50\n","27/27 [==============================] - 3s 123ms/step - loss: 22.0093 - accuracy: 0.7850 - val_loss: 78.5656 - val_accuracy: 0.7917\n","Epoch 35/50\n","27/27 [==============================] - 3s 114ms/step - loss: 21.5344 - accuracy: 0.7897 - val_loss: 77.0331 - val_accuracy: 0.7917\n","Epoch 36/50\n","27/27 [==============================] - 3s 122ms/step - loss: 21.4288 - accuracy: 0.7944 - val_loss: 76.5192 - val_accuracy: 0.7917\n","Epoch 37/50\n","27/27 [==============================] - 3s 128ms/step - loss: 21.2958 - accuracy: 0.8014 - val_loss: 78.4236 - val_accuracy: 0.7917\n","Epoch 38/50\n","27/27 [==============================] - 4s 140ms/step - loss: 21.2324 - accuracy: 0.7944 - val_loss: 83.2408 - val_accuracy: 0.7917\n","Epoch 39/50\n","27/27 [==============================] - 3s 118ms/step - loss: 21.1125 - accuracy: 0.7967 - val_loss: 72.7448 - val_accuracy: 0.7917\n","Epoch 40/50\n","27/27 [==============================] - 4s 132ms/step - loss: 21.1042 - accuracy: 0.7979 - val_loss: 79.2070 - val_accuracy: 0.8021\n","Epoch 41/50\n","27/27 [==============================] - 3s 124ms/step - loss: 20.9056 - accuracy: 0.8014 - val_loss: 72.5256 - val_accuracy: 0.7917\n","Epoch 42/50\n","27/27 [==============================] - 3s 106ms/step - loss: 21.0198 - accuracy: 0.7956 - val_loss: 74.0121 - val_accuracy: 0.8021\n","Epoch 43/50\n","27/27 [==============================] - 4s 159ms/step - loss: 21.7048 - accuracy: 0.7909 - val_loss: 76.2505 - val_accuracy: 0.7917\n","Epoch 44/50\n","27/27 [==============================] - 3s 110ms/step - loss: 22.1992 - accuracy: 0.7710 - val_loss: 76.1676 - val_accuracy: 0.8021\n","Epoch 45/50\n","27/27 [==============================] - 3s 117ms/step - loss: 22.1432 - accuracy: 0.7850 - val_loss: 66.7737 - val_accuracy: 0.7917\n","Epoch 46/50\n","27/27 [==============================] - 3s 104ms/step - loss: 21.6629 - accuracy: 0.7874 - val_loss: 71.1361 - val_accuracy: 0.8021\n","Epoch 47/50\n","27/27 [==============================] - 3s 105ms/step - loss: 21.3409 - accuracy: 0.7886 - val_loss: 75.0224 - val_accuracy: 0.7917\n","Epoch 48/50\n","27/27 [==============================] - 4s 145ms/step - loss: 21.3477 - accuracy: 0.7886 - val_loss: 71.6409 - val_accuracy: 0.8021\n","Epoch 49/50\n","27/27 [==============================] - 5s 188ms/step - loss: 22.0771 - accuracy: 0.7932 - val_loss: 74.3132 - val_accuracy: 0.8021\n","Epoch 50/50\n","27/27 [==============================] - 5s 201ms/step - loss: 22.0258 - accuracy: 0.7932 - val_loss: 71.6792 - val_accuracy: 0.8021\n","8/8 [==============================] - 1s 51ms/step\n","8/8 [==============================] - 1s 44ms/step - loss: 34.8145 - accuracy: 0.9958\n","Test Loss: 34.8145, Test accuracy : 0.9958\n","Epoch 1/50\n","27/27 [==============================] - 4s 139ms/step - loss: 79.1791 - accuracy: 0.1694 - val_loss: 78.2479 - val_accuracy: 0.1354\n","Epoch 2/50\n","27/27 [==============================] - 4s 151ms/step - loss: 51.3664 - accuracy: 0.1460 - val_loss: 73.3826 - val_accuracy: 0.1667\n","Epoch 3/50\n","27/27 [==============================] - 5s 178ms/step - loss: 48.2489 - accuracy: 0.1530 - val_loss: 72.8762 - val_accuracy: 0.1771\n","Epoch 4/50\n","27/27 [==============================] - 3s 128ms/step - loss: 46.0671 - accuracy: 0.1671 - val_loss: 72.2734 - val_accuracy: 0.2500\n","Epoch 5/50\n","27/27 [==============================] - 3s 101ms/step - loss: 43.6345 - accuracy: 0.2021 - val_loss: 70.3847 - val_accuracy: 0.4896\n","Epoch 6/50\n","27/27 [==============================] - 3s 129ms/step - loss: 42.3195 - accuracy: 0.4287 - val_loss: 69.8948 - val_accuracy: 0.6875\n","Epoch 7/50\n","27/27 [==============================] - 5s 199ms/step - loss: 41.4423 - accuracy: 0.7558 - val_loss: 69.1110 - val_accuracy: 0.6875\n","Epoch 8/50\n","27/27 [==============================] - 3s 100ms/step - loss: 40.6853 - accuracy: 0.7336 - val_loss: 70.1910 - val_accuracy: 0.7396\n","Epoch 9/50\n","27/27 [==============================] - 2s 88ms/step - loss: 39.4757 - accuracy: 0.7605 - val_loss: 68.7485 - val_accuracy: 0.6979\n","Epoch 10/50\n","27/27 [==============================] - 3s 115ms/step - loss: 34.8195 - accuracy: 0.7617 - val_loss: 71.7914 - val_accuracy: 0.6667\n","Epoch 11/50\n","27/27 [==============================] - 4s 133ms/step - loss: 28.8990 - accuracy: 0.7675 - val_loss: 65.7229 - val_accuracy: 0.7396\n","Epoch 12/50\n","27/27 [==============================] - 4s 132ms/step - loss: 23.6875 - accuracy: 0.7792 - val_loss: 71.3279 - val_accuracy: 0.7083\n","Epoch 13/50\n","27/27 [==============================] - 3s 110ms/step - loss: 19.2859 - accuracy: 0.8049 - val_loss: 66.4917 - val_accuracy: 0.7396\n","Epoch 14/50\n","27/27 [==============================] - 2s 91ms/step - loss: 16.4643 - accuracy: 0.8096 - val_loss: 67.6591 - val_accuracy: 0.7188\n","Epoch 15/50\n","27/27 [==============================] - 3s 104ms/step - loss: 14.4658 - accuracy: 0.7313 - val_loss: 67.4713 - val_accuracy: 0.3021\n","Epoch 16/50\n","27/27 [==============================] - 3s 121ms/step - loss: 13.4367 - accuracy: 0.1741 - val_loss: 67.9824 - val_accuracy: 0.2083\n","Epoch 17/50\n","27/27 [==============================] - 4s 155ms/step - loss: 13.2648 - accuracy: 0.1706 - val_loss: 70.7253 - val_accuracy: 0.1979\n","Epoch 18/50\n","27/27 [==============================] - 4s 132ms/step - loss: 12.9894 - accuracy: 0.1647 - val_loss: 68.3288 - val_accuracy: 0.1979\n","Epoch 19/50\n","27/27 [==============================] - 3s 103ms/step - loss: 12.9081 - accuracy: 0.1577 - val_loss: 69.0402 - val_accuracy: 0.1875\n","Epoch 20/50\n","27/27 [==============================] - 3s 102ms/step - loss: 13.0509 - accuracy: 0.1659 - val_loss: 67.2936 - val_accuracy: 0.2396\n","Epoch 21/50\n","27/27 [==============================] - 4s 147ms/step - loss: 12.7247 - accuracy: 0.1776 - val_loss: 68.7149 - val_accuracy: 0.1875\n","Epoch 22/50\n","27/27 [==============================] - 4s 136ms/step - loss: 11.7609 - accuracy: 0.1600 - val_loss: 67.2718 - val_accuracy: 0.2396\n","Epoch 23/50\n","27/27 [==============================] - 3s 99ms/step - loss: 11.2117 - accuracy: 0.1554 - val_loss: 69.6156 - val_accuracy: 0.1667\n","Epoch 24/50\n","27/27 [==============================] - 3s 96ms/step - loss: 11.3370 - accuracy: 0.1554 - val_loss: 66.5162 - val_accuracy: 0.2292\n","Epoch 25/50\n","27/27 [==============================] - 3s 116ms/step - loss: 11.2148 - accuracy: 0.1589 - val_loss: 70.4050 - val_accuracy: 0.1354\n","Epoch 26/50\n","27/27 [==============================] - 3s 105ms/step - loss: 10.6179 - accuracy: 0.1554 - val_loss: 67.4614 - val_accuracy: 0.2083\n","Epoch 27/50\n","27/27 [==============================] - 4s 132ms/step - loss: 10.8069 - accuracy: 0.1542 - val_loss: 70.9958 - val_accuracy: 0.1354\n","Epoch 28/50\n","27/27 [==============================] - 3s 96ms/step - loss: 10.9553 - accuracy: 0.1600 - val_loss: 69.2325 - val_accuracy: 0.1875\n","Epoch 29/50\n","27/27 [==============================] - 3s 95ms/step - loss: 11.9240 - accuracy: 0.1554 - val_loss: 71.7813 - val_accuracy: 0.1771\n","Epoch 30/50\n","27/27 [==============================] - 3s 124ms/step - loss: 11.7413 - accuracy: 0.1577 - val_loss: 69.4397 - val_accuracy: 0.1771\n","Epoch 31/50\n","27/27 [==============================] - 4s 131ms/step - loss: 11.6635 - accuracy: 0.1530 - val_loss: 70.3285 - val_accuracy: 0.1771\n","Epoch 32/50\n","27/27 [==============================] - 5s 167ms/step - loss: 11.7651 - accuracy: 0.1542 - val_loss: 68.6120 - val_accuracy: 0.1771\n","Epoch 33/50\n","27/27 [==============================] - 3s 127ms/step - loss: 11.8468 - accuracy: 0.1577 - val_loss: 76.6898 - val_accuracy: 0.1562\n","Epoch 34/50\n","27/27 [==============================] - 3s 119ms/step - loss: 11.9291 - accuracy: 0.1554 - val_loss: 68.5860 - val_accuracy: 0.1771\n","Epoch 35/50\n","27/27 [==============================] - 3s 100ms/step - loss: 11.5436 - accuracy: 0.1554 - val_loss: 71.1531 - val_accuracy: 0.1771\n","Epoch 36/50\n","27/27 [==============================] - 3s 131ms/step - loss: 11.3089 - accuracy: 0.1565 - val_loss: 68.3744 - val_accuracy: 0.1771\n","Epoch 37/50\n","27/27 [==============================] - 4s 148ms/step - loss: 11.1927 - accuracy: 0.1554 - val_loss: 70.3819 - val_accuracy: 0.1667\n","Epoch 38/50\n","27/27 [==============================] - 3s 100ms/step - loss: 11.1048 - accuracy: 0.1565 - val_loss: 67.4608 - val_accuracy: 0.1771\n","Epoch 39/50\n","27/27 [==============================] - 3s 94ms/step - loss: 11.1725 - accuracy: 0.1542 - val_loss: 72.0746 - val_accuracy: 0.1771\n","Epoch 40/50\n","27/27 [==============================] - 3s 111ms/step - loss: 11.3150 - accuracy: 0.1565 - val_loss: 68.7542 - val_accuracy: 0.1667\n","Epoch 41/50\n","27/27 [==============================] - 4s 147ms/step - loss: 11.3773 - accuracy: 0.1600 - val_loss: 70.8756 - val_accuracy: 0.1771\n","Epoch 42/50\n","27/27 [==============================] - 4s 159ms/step - loss: 11.4291 - accuracy: 0.1577 - val_loss: 68.8163 - val_accuracy: 0.1667\n","Epoch 43/50\n","27/27 [==============================] - 3s 107ms/step - loss: 11.4405 - accuracy: 0.1612 - val_loss: 70.7293 - val_accuracy: 0.1667\n","Epoch 44/50\n","27/27 [==============================] - 3s 120ms/step - loss: 11.6891 - accuracy: 0.1577 - val_loss: 68.0144 - val_accuracy: 0.1771\n","Epoch 45/50\n","27/27 [==============================] - 3s 125ms/step - loss: 13.0827 - accuracy: 0.1589 - val_loss: 73.7446 - val_accuracy: 0.1667\n","Epoch 46/50\n","27/27 [==============================] - 4s 133ms/step - loss: 12.3723 - accuracy: 0.1542 - val_loss: 66.4213 - val_accuracy: 0.1771\n","Epoch 47/50\n","27/27 [==============================] - 3s 127ms/step - loss: 12.5479 - accuracy: 0.1577 - val_loss: 70.6330 - val_accuracy: 0.1667\n","Epoch 48/50\n","27/27 [==============================] - 3s 120ms/step - loss: 11.4618 - accuracy: 0.1600 - val_loss: 66.0657 - val_accuracy: 0.1771\n","Epoch 49/50\n","27/27 [==============================] - 3s 126ms/step - loss: 11.8709 - accuracy: 0.1577 - val_loss: 71.9681 - val_accuracy: 0.1667\n","Epoch 50/50\n","27/27 [==============================] - 3s 112ms/step - loss: 11.7415 - accuracy: 0.1554 - val_loss: 67.1177 - val_accuracy: 0.1771\n","8/8 [==============================] - 0s 17ms/step\n","8/8 [==============================] - 0s 17ms/step - loss: 1437.6967 - accuracy: 0.0750\n","Test Loss: 1437.6967, Test accuracy : 0.0750\n"]}]},{"cell_type":"code","source":["def print_model_summary(loaded_model, tajweed_rule):\n","  print(f'******* Tajweed rule {tajweed_rule} model *******')\n","  loaded_model.summary()\n","  print('\\n')"],"metadata":{"id":"i4FV1w-iDDFU","executionInfo":{"status":"ok","timestamp":1717520329314,"user_tz":-60,"elapsed":5,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["for rule in max_Y.keys():\n","    model_filename = f'{rule}_tajweed_rule_model'\n","    model_path = os.path.join(export_dir, model_filename)\n","\n","    # Load the saved model\n","    loaded_model = tf.keras.models.load_model(model_path)\n","\n","    print_model_summary(loaded_model, rule)"],"metadata":{"id":"WbRKnuWnLZTc","executionInfo":{"status":"ok","timestamp":1717520335715,"user_tz":-60,"elapsed":6406,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"78ad5066-8279-48e2-d0d8-1853b852ccd3"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["******* Tajweed rule madd_6_Lazim model *******\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten (Flatten)           (None, 104000)            0         \n","                                                                 \n"," dense (Dense)               (None, 64)                6656064   \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 6656194 (25.39 MB)\n","Trainable params: 6656194 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_246 model *******\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                6656064   \n","                                                                 \n"," dense_3 (Dense)             (None, 3)                 195       \n","                                                                 \n","=================================================================\n","Total params: 6656259 (25.39 MB)\n","Trainable params: 6656259 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_6 model *******\n","Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_2 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                6656064   \n","                                                                 \n"," dense_5 (Dense)             (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 6656454 (25.39 MB)\n","Trainable params: 6656454 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_2 model *******\n","Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_3 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                6656064   \n","                                                                 \n"," dense_7 (Dense)             (None, 5)                 325       \n","                                                                 \n","=================================================================\n","Total params: 6656389 (25.39 MB)\n","Trainable params: 6656389 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Ikhfaa model *******\n","Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_4 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_8 (Dense)             (None, 64)                6656064   \n","                                                                 \n"," dense_9 (Dense)             (None, 9)                 585       \n","                                                                 \n","=================================================================\n","Total params: 6656649 (25.39 MB)\n","Trainable params: 6656649 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Idgham model *******\n","Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_5 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_10 (Dense)            (None, 64)                6656064   \n","                                                                 \n"," dense_11 (Dense)            (None, 13)                845       \n","                                                                 \n","=================================================================\n","Total params: 6656909 (25.39 MB)\n","Trainable params: 6656909 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule tafkhim model *******\n","Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_6 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_12 (Dense)            (None, 64)                6656064   \n","                                                                 \n"," dense_13 (Dense)            (None, 24)                1560      \n","                                                                 \n","=================================================================\n","Total params: 6657624 (25.40 MB)\n","Trainable params: 6657624 (25.40 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule qalqala model *******\n","Model: \"model_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_7 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_14 (Dense)            (None, 64)                6656064   \n","                                                                 \n"," dense_15 (Dense)            (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 6656454 (25.39 MB)\n","Trainable params: 6656454 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule imala model *******\n","Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_9 (InputLayer)        [(None, 8000, 13)]        0         \n","                                                                 \n"," flatten_8 (Flatten)         (None, 104000)            0         \n","                                                                 \n"," dense_16 (Dense)            (None, 64)                6656064   \n","                                                                 \n"," dense_17 (Dense)            (None, 7)                 455       \n","                                                                 \n","=================================================================\n","Total params: 6656519 (25.39 MB)\n","Trainable params: 6656519 (25.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n"]}]},{"cell_type":"code","source":["# how data is splitted\n","columns1 = ['tajweed_rule', 'data_of', 'X_train_nb_samples', 'X_test_nb_samples', 'Y_train_nb_samples', 'X_test_nb_samples']\n","splitted_data_info = pd.DataFrame(data=splitted_data_info_np, columns=columns1)\n","\n","# save models information\n","columns2 = ['Model', 'Loss', 'Accuracy', 'Accuracy %', 'Path_to_the_model']\n","models_information = pd.DataFrame(data=models_information_np, columns=columns2)"],"metadata":{"id":"txrZx0e_4Zmw","executionInfo":{"status":"ok","timestamp":1717520335716,"user_tz":-60,"elapsed":30,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["splitted_data_info"],"metadata":{"id":"8D4mYXj0Rcqb","executionInfo":{"status":"ok","timestamp":1717520335716,"user_tz":-60,"elapsed":27,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ecfd2498-e04d-43f3-8549-1c13bc2e6c12"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    tajweed_rule            data_of X_train_nb_samples X_test_nb_samples  \\\n","0   madd_6_Lazim        Abdul Basit                238                60   \n","1   madd_6_Lazim  Yassin Al Jazaery                238                60   \n","2   madd_6_Lazim   Ibrahim_Aldosary                238                60   \n","3   madd_6_Lazim          Al husary                238                60   \n","4   madd_6_Lazim       all reciters                952               240   \n","5       madd_246        Abdul Basit                238                60   \n","6       madd_246  Yassin Al Jazaery                238                60   \n","7       madd_246   Ibrahim_Aldosary                238                60   \n","8       madd_246          Al husary                238                60   \n","9       madd_246       all reciters                952               240   \n","10        madd_6        Abdul Basit                238                60   \n","11        madd_6  Yassin Al Jazaery                238                60   \n","12        madd_6   Ibrahim_Aldosary                238                60   \n","13        madd_6          Al husary                238                60   \n","14        madd_6       all reciters                952               240   \n","15        madd_2        Abdul Basit                238                60   \n","16        madd_2  Yassin Al Jazaery                238                60   \n","17        madd_2   Ibrahim_Aldosary                238                60   \n","18        madd_2          Al husary                238                60   \n","19        madd_2       all reciters                952               240   \n","20        Ikhfaa        Abdul Basit                238                60   \n","21        Ikhfaa  Yassin Al Jazaery                238                60   \n","22        Ikhfaa   Ibrahim_Aldosary                238                60   \n","23        Ikhfaa          Al husary                238                60   \n","24        Ikhfaa       all reciters                952               240   \n","25        Idgham        Abdul Basit                238                60   \n","26        Idgham  Yassin Al Jazaery                238                60   \n","27        Idgham   Ibrahim_Aldosary                238                60   \n","28        Idgham          Al husary                238                60   \n","29        Idgham       all reciters                952               240   \n","30       tafkhim        Abdul Basit                238                60   \n","31       tafkhim  Yassin Al Jazaery                238                60   \n","32       tafkhim   Ibrahim_Aldosary                238                60   \n","33       tafkhim          Al husary                238                60   \n","34       tafkhim       all reciters                952               240   \n","35       qalqala        Abdul Basit                238                60   \n","36       qalqala  Yassin Al Jazaery                238                60   \n","37       qalqala   Ibrahim_Aldosary                238                60   \n","38       qalqala          Al husary                238                60   \n","39       qalqala       all reciters                952               240   \n","40         imala        Abdul Basit                238                60   \n","41         imala  Yassin Al Jazaery                238                60   \n","42         imala   Ibrahim_Aldosary                238                60   \n","43         imala          Al husary                238                60   \n","44         imala       all reciters                952               240   \n","\n","   Y_train_nb_samples X_test_nb_samples  \n","0                 238                60  \n","1                 238                60  \n","2                 238                60  \n","3                 238                60  \n","4                 952               240  \n","5                 238                60  \n","6                 238                60  \n","7                 238                60  \n","8                 238                60  \n","9                 952               240  \n","10                238                60  \n","11                238                60  \n","12                238                60  \n","13                238                60  \n","14                952               240  \n","15                238                60  \n","16                238                60  \n","17                238                60  \n","18                238                60  \n","19                952               240  \n","20                238                60  \n","21                238                60  \n","22                238                60  \n","23                238                60  \n","24                952               240  \n","25                238                60  \n","26                238                60  \n","27                238                60  \n","28                238                60  \n","29                952               240  \n","30                238                60  \n","31                238                60  \n","32                238                60  \n","33                238                60  \n","34                952               240  \n","35                238                60  \n","36                238                60  \n","37                238                60  \n","38                238                60  \n","39                952               240  \n","40                238                60  \n","41                238                60  \n","42                238                60  \n","43                238                60  \n","44                952               240  "],"text/html":["\n","  <div id=\"df-48128a59-c430-4ba9-b1f3-781e53d50da5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tajweed_rule</th>\n","      <th>data_of</th>\n","      <th>X_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","      <th>Y_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Al husary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>madd_6_Lazim</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>madd_246</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>madd_246</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>madd_246</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>madd_246</td>\n","      <td>Al husary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>madd_246</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>madd_6</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>madd_6</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>madd_6</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>madd_6</td>\n","      <td>Al husary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>madd_6</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>madd_2</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>madd_2</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>madd_2</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>madd_2</td>\n","      <td>Al husary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>madd_2</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Ikhfaa</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Ikhfaa</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Ikhfaa</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Ikhfaa</td>\n","      <td>Al husary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Ikhfaa</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Idgham</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Idgham</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Idgham</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Idgham</td>\n","      <td>Al husary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Idgham</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>tafkhim</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>tafkhim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>tafkhim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>tafkhim</td>\n","      <td>Al husary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>tafkhim</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>qalqala</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>qalqala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>qalqala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>qalqala</td>\n","      <td>Al husary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>qalqala</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>imala</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>imala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>imala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>imala</td>\n","      <td>Al husary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>imala</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48128a59-c430-4ba9-b1f3-781e53d50da5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-48128a59-c430-4ba9-b1f3-781e53d50da5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-48128a59-c430-4ba9-b1f3-781e53d50da5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-63d2371c-5931-4750-bae1-e657a14475d6\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63d2371c-5931-4750-bae1-e657a14475d6')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-63d2371c-5931-4750-bae1-e657a14475d6 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"splitted_data_info","summary":"{\n  \"name\": \"splitted_data_info\",\n  \"rows\": 45,\n  \"fields\": [\n    {\n      \"column\": \"tajweed_rule\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala\",\n          \"madd_246\",\n          \"Idgham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_of\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Yassin Al Jazaery\",\n          \"all reciters\",\n          \"Ibrahim_Aldosary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"952\",\n          \"238\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"240\",\n          \"60\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"952\",\n          \"238\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"240\",\n          \"60\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["models_information"],"metadata":{"id":"h3kOCPqVuemS","executionInfo":{"status":"ok","timestamp":1717520335717,"user_tz":-60,"elapsed":15,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":837},"outputId":"97e9179b-7518-439f-a828-c3fe31d70a94"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             Model       Loss Accuracy Accuracy %  \\\n","0  madd_6_Lazim_tajweed_rule_model   134.8659   0.0458       4.58   \n","1      madd_246_tajweed_rule_model   351.7010   1.0000     100.00   \n","2        madd_6_tajweed_rule_model   506.4740   0.9417      94.17   \n","3        madd_2_tajweed_rule_model   528.2846   1.0000     100.00   \n","4        Ikhfaa_tajweed_rule_model   386.9288   0.8542      85.42   \n","5        Idgham_tajweed_rule_model   421.5266   1.0000     100.00   \n","6       tafkhim_tajweed_rule_model   190.9882   0.8625      86.25   \n","7       qalqala_tajweed_rule_model    34.8145   0.9958      99.58   \n","8         imala_tajweed_rule_model  1437.6967   0.0750       7.50   \n","\n","                                   Path_to_the_model  \n","0  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","1  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","2  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","3  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","4  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","5  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","6  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","7  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  \n","8  /content/drive/My Drive/M2 GL/PFE/new Tajweed ...  "],"text/html":["\n","  <div id=\"df-c1dfbe9e-2aa5-4029-aeb1-b908fe154f96\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Loss</th>\n","      <th>Accuracy</th>\n","      <th>Accuracy %</th>\n","      <th>Path_to_the_model</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim_tajweed_rule_model</td>\n","      <td>134.8659</td>\n","      <td>0.0458</td>\n","      <td>4.58</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_246_tajweed_rule_model</td>\n","      <td>351.7010</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_tajweed_rule_model</td>\n","      <td>506.4740</td>\n","      <td>0.9417</td>\n","      <td>94.17</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_2_tajweed_rule_model</td>\n","      <td>528.2846</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Ikhfaa_tajweed_rule_model</td>\n","      <td>386.9288</td>\n","      <td>0.8542</td>\n","      <td>85.42</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Idgham_tajweed_rule_model</td>\n","      <td>421.5266</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>tafkhim_tajweed_rule_model</td>\n","      <td>190.9882</td>\n","      <td>0.8625</td>\n","      <td>86.25</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>qalqala_tajweed_rule_model</td>\n","      <td>34.8145</td>\n","      <td>0.9958</td>\n","      <td>99.58</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>imala_tajweed_rule_model</td>\n","      <td>1437.6967</td>\n","      <td>0.0750</td>\n","      <td>7.50</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/new Tajweed ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1dfbe9e-2aa5-4029-aeb1-b908fe154f96')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c1dfbe9e-2aa5-4029-aeb1-b908fe154f96 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c1dfbe9e-2aa5-4029-aeb1-b908fe154f96');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9a4191cc-4b18-4408-8d33-0a10ac362bf2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a4191cc-4b18-4408-8d33-0a10ac362bf2')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9a4191cc-4b18-4408-8d33-0a10ac362bf2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"models_information","summary":"{\n  \"name\": \"models_information\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala_tajweed_rule_model\",\n          \"madd_246_tajweed_rule_model\",\n          \"Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Loss\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"34.8145\",\n          \"351.7010\",\n          \"421.5266\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"0.0458\",\n          \"1.0000\",\n          \"0.9958\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy %\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"4.58\",\n          \"100.00\",\n          \"99.58\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Path_to_the_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"/content/drive/My Drive/M2 GL/PFE/new Tajweed rule model/AI models/v2/qalqala_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/new Tajweed rule model/AI models/v2/madd_246_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/new Tajweed rule model/AI models/v2/Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":[],"metadata":{"id":"npA_L1F-EUjU"},"execution_count":null,"outputs":[]}]}